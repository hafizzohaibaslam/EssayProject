<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2019-10-04T09:59+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Review of Relational Machine Learning for Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Nickel</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Tresp</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
						</author>
						<title level="a" type="main">A Review of Relational Machine Learning for Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/JPROC.2015.2483592</idno>
					<note>I N V I T E D P A P E R</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>| Graph-based models</term>
					<term>knowledge extraction</term>
					<term>knowledge graphs</term>
					<term>latent feature models</term>
					<term>statistical relational learning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper reviews how statistical models can be &apos;&apos;trained&apos;&apos; on large knowledge graphs and then used to predict new facts about the world. ABSTRACT | Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be &apos;&apos;trained&apos;&apos; on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google&apos;s knowledge vault project as an example of such combination.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>''I am convinced that the crux of the problem of learning is recognizing relationships and being able to use them''VChristopher Strachey in a letter to Alan <ref type="bibr">Turing, 1954.</ref> Traditional machine learning algorithms take as input a feature vector, which represents an object in terms of numeric or categorical attributes. The main learning task is to learn a mapping from this feature vector to an output prediction of some form. This could be class labels, a regression score, or an unsupervised cluster id or latent vector (embedding). In statistical relational learning (SRL), the representation of an object can contain its relationships to other objects. Thus the data is in the form of a graph, consisting of nodes (entities) and labeled edges (relationships between entities). The main goals of SRL include prediction of missing edges, prediction of properties of nodes, and clustering nodes based on their connectivity patterns. These tasks arise in many settings such as analysis of social networks and biological pathways. For further information on SRL, see <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>.</p><p>In this paper, we review a variety of techniques from the SRL community and explain how they can be applied to large-scale knowledge graphs (KGs), i.e., graph structured knowledge bases (KBs) that store factual information in form of relationships between entities. Recently, a large number of knowledge graphs have been created, including YAGO <ref type="bibr" target="#b3">[4]</ref>, DBpedia <ref type="bibr" target="#b4">[5]</ref>, NELL <ref type="bibr" target="#b5">[6]</ref>, Freebase <ref type="bibr" target="#b6">[7]</ref>, and the Google Knowledge Graph <ref type="bibr" target="#b7">[8]</ref>. As we discuss in Section II, these graphs contain millions of nodes and billions of edges. This causes us to focus on scalable SRL techniques, which take time that is (at most) linear in the size of the graph.</p><p>We can apply SRL methods to existing KGs to learn a model that can predict new facts (edges) given existing facts. We can then combine this approach with information extraction methods that extract ''noisy'' facts from the Web (see, e.g., <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b9">[10]</ref>). For example, suppose an information extraction method returns a fact claiming that Barack Obama was born in Kenya, and suppose (for illustration purposes) that the true place of birth of Obama was not already stored in the knowledge graph. An SRL model can use related facts about Obama (such as his profession being U.S. President) to infer that this new fact is unlikely to be true and should be discarded. This provides us a way to ''grow'' a KG automatically, as we explain in more detail in Section IX.</p><p>The remainder of this paper is structured as follows. In Section II, we introduce knowledge graphs and some of their properties. Section III discusses SRL and how it can be applied to knowledge graphs. There are two main classes of SRL techniques: those that capture the correlation between the nodes/edges using latent variables, and those that capture the correlation directly using statistical models based on the observable properties of the graph. We discuss these two families in Sections IV and V, respectively. Section VI describes methods for combining these two approaches, in order to get the best of both worlds. Section VII discusses how such models can be trained on KGs. In Section VIII we discuss relational learning using Markov Random Fields. In Section IX, we describe how SRL can be used in automated knowledge base construction projects. In Section X, we discuss extensions of the presented methods, and Section XI presents our conclusions.</p><p>can be expressed via the following set of SPO triples:</p><p>We can combine all the SPO triples together to form a multigraph, where nodes represent entities (all subjects and objects), and directed edges represent relationships. The direction of an edge indicates whether entities occur as subjects or objects, i.e., an edge points from the subject to the object. Different relations are represented via different types of edges (also called edge labels). This construction is called a knowledge graph (KG), or sometimes a heterogeneous information network <ref type="bibr" target="#b20">[21]</ref>.) See <ref type="figure" target="#fig_0">Fig. 1</ref> for an example.</p><p>In addition to being a collection of facts, knowledge graphs often provide type hierarchies (Leonard Nimoy is an actor, which is a person, which is a living thing) and type constraints (e.g., a person can only marry another person, not a thing).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. KNOWLEDGE GRAPHS</head><p>In this section, we introduce knowledge graphs, and discuss how they are represented, constructed, and used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Knowledge Representation</head><p>Knowledge graphs model information in the form of entities and relationships between them. This kind of relational knowledge representation has a long history in logic and artificial intelligence <ref type="bibr" target="#b10">[11]</ref>, for example, in semantic networks <ref type="bibr" target="#b11">[12]</ref> and frames <ref type="bibr" target="#b12">[13]</ref>. More recently, it has been used in the Semantic Web community with the purpose of creating a ''web of data'' that is readable by machines <ref type="bibr" target="#b13">[14]</ref>. While this vision of the Semantic Web remains to be fully realized, parts of it have been achieved. In particular, the concept of linked data <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> has gained traction, as it facilitates publishing and interlinking data on the Web in relational form using the W3C Resource Description Framework (RDF) <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. (For an introduction to knowledge representation, see, e.g., <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b18">[19]</ref>, and <ref type="bibr" target="#b19">[20]</ref>.)</p><p>In this paper, we will loosely follow the RDF standard and represent facts in the form of binary relationships, in particular (subject, predicate, object) (SPO) triples, where subject and object are entities and predicate is the relation between them. (We discuss how to represent higher arity relations in Section X-A.) The existence of a particular SPO triple indicates an existing fact, i.e., that the respective entities are in a relationship of the given type. For instance, the information</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Open Versus Closed World Assumption</head><p>While existing triples always encode known true relationships (facts), there are different paradigms for the interpretation of nonexisting triples.</p><p>? Under the closed world assumption (CWA), nonexisting triples indicate false relationships. For example, the fact that in <ref type="figure" target="#fig_0">Fig. 1</ref> there is no starredIn edge from Leonard Nimoy to Star Wars is interpreted to mean that Nimoy definitely did not star in this movie.</p><p>? Under the open world assumption (OWA), a nonexisting triple is interpreted as unknown, i.e., the corresponding relationship can be either true or false. Continuing with the above example, the missing edge is not interpreted to mean that Nimoy did not star in Star Wars. This more cautious approach is justified, since KGs are known ''Leonard Nimoy was an actor who played the character Spock in the science-fiction movie Star Trek'' to be very incomplete. For example, sometimes just the main actors in a movie are listed, not the complete cast. As another example, note that even the place of birth attribute, which you might think would be typically known, is missing for 71% of all people included in Freebase <ref type="bibr" target="#b21">[22]</ref>. RDF and the Semantic Web make the open-world assumption. In Section VII-B we also discuss the local closed world assumption (LCWA), which is often used for training relational models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Knowledge Base Construction</head><p>Completeness, accuracy, and data quality are important parameters that determine the usefulness of knowledge bases and are influenced by the way knowledge bases are constructed. We can classify KB construction methods into four main groups:</p><p>? in curated approaches, triples are created manually by a closed group of experts; ? in collaborative approaches, triples are created manually by an open group of volunteers; ? in automated semistructured approaches, triples are extracted automatically from semistructured text (e.g., infoboxes in Wikipedia) via hand-crafted rules, learned rules, or regular expressions; ? in automated unstructured approaches, triples are extracted automatically from unstructured text via machine learning and natural language processing techniques (see, e.g., <ref type="bibr" target="#b8">[9]</ref> for a review). Construction of curated knowledge bases typically leads to highly accurate results, but this technique does not scale well due to its dependence on human experts. Collaborative knowledge base construction, which was used to build Wikipedia and Freebase, scales better but still has some limitations. For instance, as mentioned previously, the place of birth attribute is missing for 71% of all people included in Freebase, even though this is a mandatory property of the schema <ref type="bibr" target="#b21">[22]</ref>. Also, a recent study <ref type="bibr" target="#b35">[35]</ref> found that the growth of Wikipedia has been slowing down. Consequently, automatic knowledge base construction methods have been gaining more attention.</p><p>Such methods can be grouped into two main approaches. The first approach exploits semistructured data, such as Wikipedia infoboxes, which has led to large, highly accurate knowledge graphs such as YAGO <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b26">[27]</ref> and DBpedia <ref type="bibr" target="#b4">[5]</ref>. The accuracy (trustworthiness) of facts in such automatically created KGs is often still very high. For instance, the accuracy of YAGO2 has been estimated 1 to be over 95% through manual inspection of sample facts <ref type="bibr" target="#b36">[36]</ref>, and the accuracy of Freebase <ref type="bibr" target="#b6">[7]</ref> was estimated to be 99%. fraction of the information stored on the Web, and completeness (or coverage) is another important aspect of KGs. Hence the second approach tries to ''read the Web,'' extracting facts from the natural language text of Web pages. Example projects in this category include NELL <ref type="bibr" target="#b5">[6]</ref> and the knowledge vault <ref type="bibr" target="#b27">[28]</ref>. In Section IX, we show how we can reduce the level of ''noise'' in such automatically extracted facts by using the knowledge from existing, highquality repositories.</p><p>KGs, and more generally KBs, can also be classified based on whether they employ a fixed or open lexicon of entities and relations. In particular, we distinguish two main types of KBs.</p><p>? In schema-based approaches, entities, and relations are represented via globally unique identifiers and all possible relations are predefined in a fixed vocabulary. For example, Freebase might represent the fact that Barack Obama was born in Hawaii using the triple (/m/02mjmr,/people/ person/born-in,/m/03gh4), where /m/02mjmr is the unique machine ID for Barack Obama.</p><p>? In schema-free approaches, entities and relations are identified using open information extraction (OpenIE) techniques <ref type="bibr" target="#b37">[37]</ref>, and represented via normalized but not disambiguated strings (also referred to as surface names). For example, an OpenIE system may contain triples such as (''Obama,'' ''born in,'' ''Hawaii''), (''Barack Obama,'' ''place of birth,'' ''Honolulu''), etc. Note that it is not clear from this representation whether the first triple refers to the same person as the second triple, nor whether ''born in'' means the same thing as ''place of birth.'' This is the main disadvantage of OpenIE systems. <ref type="table" target="#tab_0">Table 1</ref> lists current knowledge base construction projects classified by their creation method and data schema. In this paper, we will only focus on schema-based KBs. <ref type="table" target="#tab_1">Table 2</ref> shows a selection of such KBs and their sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Uses of Knowledge Graphs</head><p>Knowledge graphs provide semantically structured information that is interpretable by computersVa However, semistructured text still covers only a small Knowledge graphs are also used in several specialized domains. For instance, Bio2RDF <ref type="bibr" target="#b41">[41]</ref>, Neurocommons <ref type="bibr" target="#b42">[42]</ref>, and LinkedLifeData <ref type="bibr" target="#b43">[43]</ref> are knowledge graphs that integrate multiple sources of biomedical information. These have been used for question answering and decision support in the life sciences. property that is regarded as an important ingredient to build more intelligent machines <ref type="bibr" target="#b38">[38]</ref>. Consequently, knowledge graphs are already powering multiple ''Big Data'' applications in a variety of commercial and scientific domains. A prime example is the integration of Google's Knowledge Graph, which currently stores 18 billion facts about 570 million entities, into the results of Google's search engine <ref type="bibr" target="#b7">[8]</ref>. The Google Knowledge Graph is used to identify and disambiguate entities in text, to enrich search results with semantically structured summaries, and to provide links to related entities in exploratory search. (Microsoft has a similar KB, called Satori, integrated with its Bing search engine <ref type="bibr" target="#b39">[39]</ref>.)</p><p>Enhancing search results with semantic information from knowledge graphs can be seen as an important step to transform text-based search engines into semantically aware question answering services. Another prominent example demonstrating the value of knowledge graphs is IBM's question answering system Watson, which was able to beat human experts in the game of Jeopardy!. Among others, this system used YAGO, DBpedia, and Freebase as its sources of information <ref type="bibr" target="#b40">[40]</ref>. Repositories of structured knowledge are also an indispensable component of digital assistants such as Siri, Cortana, or Google Now.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Main Tasks in Knowledge Graph Construction and Curation</head><p>In this section, we review a number of typical KG tasks. Link prediction is concerned with predicting the existence (or probability of correctness) of (typed) edges in the graph (i.e., triples). This is important since existing knowledge graphs are often missing many facts, and some of the edges they contain are incorrect <ref type="bibr" target="#b44">[44]</ref>. In the context of knowledge graphs, link prediction is also referred to as knowledge graph completion. For example, in <ref type="figure" target="#fig_0">Fig. 1</ref>, suppose the characterIn edge from Obi-Wan Kenobi to Star Wars were missing; we might be able to predict this missing edge, based on the structural similarity between this part of the graph and the part involving Spock and Star Trek. It has been shown that relational models that take the relationships of entities into account can significantly outperform nonrelational machine learning methods for this task (e.g., see <ref type="bibr" target="#b45">[45]</ref> and <ref type="bibr" target="#b46">[46]</ref>).</p><p>Entity resolution (also known as record linkage <ref type="bibr" target="#b47">[47]</ref>, object identification <ref type="bibr" target="#b48">[48]</ref>, instance matching <ref type="bibr" target="#b49">[49]</ref>, and deduplication <ref type="bibr" target="#b50">[50]</ref>) is the problem of identifying which objects in relational data refer to the same underlying entities. See <ref type="figure">Fig. 2</ref> for a small example. In a relational setting, the decisions about which objects are assumed to be identical can propagate through the graph, so that matching decisions are made collectively for all objects in a domain rather than independently for each object pair (see, for example, <ref type="bibr" target="#b51">[51]</ref>- <ref type="bibr" target="#b54">[53]</ref>). In schema-based automated knowledge base construction, entity resolution can be used to match the extracted surface names to entities stored in the knowledge graph. <ref type="figure">Fig. 2</ref>. Example of entity resolution in a toy knowledge graph. In this example, nodes 1 and 3 refer to the identical entity, the actor Alec Guinness.</p><p>Node 2, on the other hand, refers to Arthur Guinness, the founder of the Guinness brewery. The surface name of node 2 (''A. Guinness'') alone would not be sufficient to perform a correct matching as it could refer to both Alec Guinness and Arthur Guinness. However, since links in the graph reveal the occupations of the persons, a relational approach can perform the correct matching.</p><p>Link-based clustering extends feature-based clustering to a relational learning setting and groups entities in relational data based on their similarity. However, in linkbased clustering, entities are not only grouped by the similarity of their features but also by the similarity of their links. As in entity resolution, the similarity of entities can propagate through the knowledge graph, such that relational modeling can add important information for this task. In social network analysis, link-based clustering is also known as community detection <ref type="bibr" target="#b55">[54]</ref>.</p><p>knowledge graph. We model each possible triple x ijk ? ?e i ; r k ; e j ? over this set of entities and relations as a binary random variable y ijk 2 f0; 1g that indicates its existence. All possible triples in E ? R ? E can be grouped naturally in a third-order tensor (three-way array) Y 2 f0; 1g N e ?N e ?N r , whose entries are set such that &amp; y ijk ? 1; if the triple ?e i ; r k ; e j ? exists 0; otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. STATISTICAL RELATIONAL LEARNING FOR KNOWLEDGE GRAPHS</head><p>Statistical relational learning is concerned with the creation of statistical models for relational data. In the following sections we discuss how statistical relational learning can be applied to knowledge graphs. We will assume that all the entities and (types of) relations in a knowledge graph are known. (We discuss extensions of this assumption in Section X-C). However, triples are assumed to be incomplete and noisy; entities and relation types may contain duplicates.</p><p>Notation: Before proceeding, let us define our mathematical notation. (Variable names will be introduced later in the appropriate sections.) We denote scalars by lower case letters, such as a; column vectors (of size N) by bold lower case letters, such as a; matrices (of size N 1 ? N 2 ) by bold upper case letters, such as A; and tensors (of size N 1 ? N 2 ? N 3 ) by bold upper case letters with an underscore, such as A. We denote the k'th ''frontal slice'' of a tensor A by A k (which is a matrix of size N 1 ? N 2 ), and the ?i; j; k?th element by a ijk (which is a scalar). We use ?a; b? to denote the vertical stacking of vectors a and b, i.e.,</p><formula xml:id="formula_0">?a; b? ? a b ? ?</formula><p>. We can convert a matrix A of size N 1 ? N 2 into a vector a of size N 1 N 2 by stacking all columns of A, denoted a ? vec?A?. The inner (scalar) product of two vectors (both of size N) is defined by a &gt; b ? P N i?1 a i b i . The tensor (Kronecker) product of two vectors (of size N 1 and N 2 ) is a vector of size N 1 N 2 with entries 0 1</p><p>We will refer to this construction as an adjacency tensor (cf., <ref type="figure" target="#fig_1">Fig. 3</ref>). Each possible realization of Y can be interpreted as a possible world. To derive a model for the entire knowledge graph, we are then interested in estimating the joint distribution P?Y?, from a subset D E ? R ? E ? f0; 1g of observed triples. In doing so, we are estimating a probability distribution over possible worlds, which allows us to predict the probability of triples based on the state of the entire knowledge graph. While y ijk ? 1 in adjacency tensors indicates the existence of a triple, the interpretation of y ijk ? 0 depends on whether the open world, closed world, or local-closed world assumption is made. For details, see Section VII-B.</p><p>Note that the size of Y can be enormous for large knowledge graphs. For instance, in the case of Freebase, which currently consists of over 40 million entities and 35 000 relations, the number of possible triples jE ? R ? Ej exceeds 10 19 elements. Of course, type constraints reduce this number considerably.</p><p>Even amongst the syntactically valid triples, only a tiny fraction are likely to be true. For example, there are over 450 000 thousands actors and over 250 000 movies stored in Freebase. But each actor stars only in a small number of movies. Therefore, an important issue for SRL on knowledge graphs is how to deal with the large number of possible relationships while efficiently exploiting the sparsity of relationships. Ideally, a relational model for large-scale knowledge graphs should scale at most linearly with the data size, i.e., linearly in the number of entities </p><formula xml:id="formula_1">a b ? a 1 b . . . B @ C A.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Probabilistic Knowledge Graphs</head><p>We now introduce some mathematical background so we can more formally define statistical models for knowledge graphs.</p><p>Let E ? fe 1 ; . . . ; e N e g be the set of all entities and R ? fr 1 ; . . . ; r N r g be the set of all relation types in a   e , linearly in the number of relations N r , and linearly in the number of observed triples jDj ? N d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Statistical Properties of Knowledge Graphs</head><p>Knowledge graphs typically adhere to some deterministic rules, such as type constraints and transitivity (e.g., if Leonard Nimoy was born in Boston, and Boston is located in the United States, then we can infer that Leonard Nimoy was born in the United States). However, KGs have typically also various ''softer'' statistical patterns or regularities, which are not universally true but nevertheless have useful predictive power.</p><p>One example of such statistical pattern is known as homophily, that is, the tendency of entities to be related to other entities with similar characteristics. This has been widely observed in various social networks <ref type="bibr" target="#b56">[55]</ref>, <ref type="bibr" target="#b57">[56]</ref>. For example, U.S.-born actors are more likely to star in U.S.-made movies. For multirelational data (graphs with more than one kind of link), homophily has also been referred to as autocorrelation <ref type="bibr" target="#b58">[57]</ref>.</p><p>Another statistical pattern is known as block structure. This refers to the property where entities can be divided into distinct groups (blocks), such that all the members of a group have similar relationships to members of other groups <ref type="bibr" target="#b59">[58]</ref>- <ref type="bibr" target="#b61">[60]</ref>. For example, we can group some actors, such as Leonard Nimoy and Alec Guinness, into a science fiction actor block, and some movies, such as Star Trek and Star Wars, into a science fiction movie block, since there is a high density of links from the scifi actor block to the scifi movie block.</p><p>Graphs can also exhibit global and long-range statistical dependencies, i.e., dependencies that can span over chains of triples and involve different types of relations. For example, the citizenship of Leonard Nimoy (USA) depends statistically on the city where he was born (Boston), and this dependency involves a path over multiple entities (Leonard Nimoy, Boston, USA) and relations (bornIn, locatedIn, citizenOf). A distinctive feature of relational learning is that it is able to exploit such patterns to create richer and more accurate models of relational domains.</p><p>When applying statistical models to incomplete knowledge graphs, it should be noted that the distribution of facts in such KGs can be skewed. For instance, KGs that are derived from Wikipedia will inherit the skew that exists in distribution of facts in Wikipedia itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Types of SRL Models</head><p>As we discussed, the presence or absence of certain triples in relational data is correlated with (i.e., predictive of) the presence or absence of certain other triples. In other words, the random variables y ijk are correlated with each other. We will discuss three main ways to model these correlations.</p><p>1) Assume all y ijk are conditionally independent given latent features associated with subject, object and relation type and additional parameters (latent feature models). 2) Assume all y ijk are conditionally independent given observed graph features and additional parameters (graph feature models). 3) Assume all y ijk have local interactions (Markov random fields). In what follows we will mainly focus on M1 and M2 and their combination; M3 will be the topic of Section VIII.</p><p>The model classes M1 and M2 predict the existence of a triple x ijk via a score function f ?x ijk ; 0? which represents the model's confidence that a triple exists given the parameters 0. The conditional independence assumptions of M1 and M2 allow the probability model to be written as follows:</p><formula xml:id="formula_2">P?YjD; 0? ? Y N e Y N e Y N r Ber y ijk j f ?x ijk ; 0? ? ? ? ? (1) i?1 j?1 k?1</formula><p>where ?u? ? 1=?1 ? e ?u ? is the sigmoid (logistic) function, and</p><formula xml:id="formula_3">&amp; Ber?yjp? ? p; if y ? 1 1 ? p; if y ? 0 (2) 8</formula><p>Statistical models as discussed in the following sections can be affected by such biases in the input data and need to be interpreted accordingly.</p><p>is the Bernoulli distribution.</p><p>We will refer to models of the form <ref type="formula">(1)</ref> as probabilistic models. In addition to probabilistic models, we will also discuss models which optimize f ??? under other criteria, for instance models which maximize the margin between existing and nonexisting triples. We will refer to such models as score-based models. If desired, we can derive probabilities for score-based models via Platt scaling <ref type="bibr" target="#b62">[61]</ref>.</p><p>There are many different methods for defining f ???. In Sections IV-VI and VIII, we will discuss different options for all model classes. In Section VII, we will furthermore discuss aspects of how to train these models on knowledge graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. LATENT FEATURE MODELS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8</head><p>In this section, we assume that the variables y ijk are conditionally independent given a set of global latent features and parameters, as in (1). We discuss various</p><p>As an example, there are currently 10306 male and 7586 female American actors listed in Wikipedia, while there are only 1268 male and 1354 female Indian, and 77 male and no female Nigerian actors. India and Nigeria, however, are the largest and second largest film industries in the world.</p><p>possible forms for the score function f ?x; 0? below. What all models have in common is that they explain triples via latent features of entities (This is justified via various theoretical arguments <ref type="bibr" target="#b63">[62]</ref>). For instance, a possible explanation for the fact that Alec Guinness received the Academy Award is that he is a good actor. This explanation uses latent features of entities (being a good actor) to explain observable facts (Guinness receiving the Academy Award). We call these features ''latent'' because they are not directly observed in the data. One task of all latent feature models is therefore to infer these features automatically from the data.</p><p>In the following, we will denote the latent feature representation of an entity e i by the vector e i 2 R H e where H e denotes the number of latent features in the model. For instance, we could model that Alec Guinness is a good actor and that the Academy Award is a prestigious award via the vectors </p><formula xml:id="formula_4">! ; e AcademyAward ? 0:2 0:8</formula><p>where the component e i1 corresponds to the latent feature Good Actor and e i2 correspond to Prestigious Award. (Note that, unlike this example, the latent features that are inferred by the following models are typically hard to interpret.)</p><p>The key intuition behind relational latent feature models is that the relationships between entities can be derived from interactions of their latent features. However, there are many possible ways to model these interactions, and many ways to derive the existence of a relationship from them. We discuss several possibilities below. See <ref type="table" target="#tab_4">Table 3</ref> for a summary of the notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. RESCAL: A Bilinear Model</head><formula xml:id="formula_5">RESCAL [63]-[65]</formula><p>is a relational latent feature model which explains triples via pairwise interactions of latent features. In particular, we model the score of a triple x ijk as In general, we can model block structure patterns via the magnitude of entries in W k , while we can model homophily patterns via the magnitude of its diagonal entries. Anticorrelations in these patterns can be modeled via negative entries in W k .</p><p>Hence, in (3) we compute the score of a triple x ijk via the weighted sum of all pairwise interactions between the latent features of the entities e i and e j . The parameters of the model are 0</p><formula xml:id="formula_6">? ffe i g N e N r i?1 ; fW k g f RESCAL ijk :? e &gt; X H e X H e i W k e j ? w abk e ia e jb (3) a?1 b?1</formula><p>k?1 g. During training we jointly learn the latent representations of entities and how the latent features interact for particular relation types.</p><p>In the following, we will discuss further important properties of the model for learning from knowledge graphs.</p><p>where W k 2 R H e ?H e is a weight matrix whose entries w abk specify how much the latent features a and b interact in the kth relation. We call this a bilinear model, since it captures the interactions between the two entity vectors using multiplicative terms. For instance, we could model the pattern that good actors are likely to receive prestigious awards via a weight matrix such as Relational Learning Via Shared Representations: In (3), entities have the same latent representation regardless of whether they occur as subjects or objects in a relationship. Furthermore, they have the same representation over all different relation types. For instance, the ith entity occurs in the triple x ijk as the subject of a relationship of type k, while it occurs in the triple x piq as the object of a relationship of type q. However, the predictions f ijk ? e representations permit to propagate information between triples via the latent representations of entities and the weights of relations. This allows the model to capture global dependencies in the data.</p><p>Semantic Embeddings: The shared entity representations in RESCAL capture also the similarity of entities in the relational domain, i.e., that entities are similar if they are connected to similar entities via similar relations <ref type="bibr" target="#b66">[65]</ref>. For instance, if the representations of e i and e p are similar, the predictions f ijk and f pjk will have similar values. In return, entities with many similar observed relationships will have similar latent representations. This property can be exploited for entity resolution and has also enabled large-scale hierarchical clustering on relational data <ref type="bibr" target="#b64">[63]</ref>, <ref type="bibr" target="#b65">[64]</ref>. Moreover, since relational similarity is expressed via the similarity of vectors, the latent representations e i can act as proxies to give nonrelational machine learning algorithms such as k-means or kernel methods access to the relational similarity of entities. this setting, it has been shown analytically that a single update of E and W k scales linearly with the number of entities N e , linearly with the number of relations N r , and linearly with the number of observed triples, i.e., the number of nonzero entries in Y <ref type="bibr" target="#b65">[64]</ref>. We call this algorithm RESCAL-ALS. <ref type="bibr" target="#b8">9</ref> In practice, a small number (say 30 to 50) of iterated updates are often sufficient for RESCAL-ALS to arrive at stable estimates of the parameters. Given a current estimate of E, the updates for each W k can be computed in parallel to improve the scalability on knowledge graphs with a large number of relations. Furthermore, by exploiting the special tensor structure of RESCAL, we can derive improved updates for RESCAL-ALS that compute the estimates for the parameters with a runtime complexity of O?H 3 e ? for a single update (as opposed to a runtime complexity of O?H 5 e ? for naive updates) <ref type="bibr" target="#b66">[65]</ref>, <ref type="bibr" target="#b70">[69]</ref>. In summary, for relational domains that can be explained via a moderate number of latent features, RESCAL-ALS is highly scalable and very fast to compute. For more detail on RESCAL-ALS, see also <ref type="formula" target="#formula_28">(26)</ref> in Section VII.</p><p>Connection to Tensor Factorization: RESCAL is similar to methods used in recommendation systems <ref type="bibr" target="#b67">[66]</ref>, and to traditional tensor factorization methods <ref type="bibr" target="#b68">[67]</ref>. In matrix notation, (3) can be written compactly as as holds the latent representation of e i . See <ref type="figure" target="#fig_4">Fig. 4</ref> for an illustration. In the following, we will use this tensor representation to derive a very efficient algorithm for parameter estimation.</p><formula xml:id="formula_7">F k ? EW k E &gt; ,</formula><p>e ? time. Hence, once the parameters have been estimated, the computational complexity to predict the score of a triple depends only on the number of latent features and is independent of the size of the graph. However, during parameter estimation, the model can capture global dependencies due to the shared latent representations.</p><p>Fitting the Model: If we want to compute a probabilistic model, the parameters of RESCAL can be estimated by minimizing the log-loss using gradient-based methods such as stochastic gradient descent <ref type="bibr" target="#b69">[68]</ref>. RESCAL can also be computed as a score-based model, which has the main advantage that we can estimate the parameters 0 very efficiently: Due to its tensor structure and due to the sparsity of the data, it has been shown that the RESCAL model can be computed via a sequence of efficient closedform updates when using the squared-loss <ref type="bibr" target="#b64">[63]</ref>, <ref type="bibr" target="#b65">[64]</ref>. In Relational Learning Results: RESCAL has been shown to achieve state-of-the-art results on a number of relational learning tasks. For instance, <ref type="bibr" target="#b64">[63]</ref> showed that RESCAL provides comparable or better relationship prediction results on a number of small benchmark data sets compared to Markov logic networks (with structure learning) <ref type="bibr" target="#b71">[70]</ref>, the infinite (hidden) relational model <ref type="bibr" target="#b72">[71]</ref>, <ref type="bibr" target="#b73">[72]</ref>, and Bayesian clustered tensor factorization <ref type="bibr" target="#b74">[73]</ref>. Moreover, RESCAL has been used for link prediction on entire knowledge graphs such as YAGO and DBpedia <ref type="bibr" target="#b65">[64]</ref>, <ref type="bibr" target="#b75">[74]</ref>. Aside from link prediction, RESCAL has also successfully been applied to SRL tasks such as entity resolution and link-based clustering. For instance, RESCAL has shown state-of-the-art results in predicting which authors, publications, or publication venues are likely to be identical in publication databases <ref type="bibr" target="#b64">[63]</ref>, <ref type="bibr" target="#b66">[65]</ref>. Furthermore, the semantic embedding of entities computed by RESCAL has been exploited to create taxonomies for uncategorized data via hierarchical clusterings of entities in the embedding space <ref type="bibr" target="#b76">[75]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Other Tensor Factorization Models</head><p>Various other tensor factorization methods have been explored for learning from knowledge graphs and   data. <ref type="bibr">Kolda et al. [76]</ref> and <ref type="bibr">Franz et al. [77]</ref> factorized adjacency tensors using the CP tensor decomposition to analyze the link structure of web pages and semantic web data, respectively. Drumond et al. <ref type="bibr" target="#b79">[78]</ref> applied pairwise interaction tensor factorization <ref type="bibr" target="#b80">[79]</ref> to predict triples in knowledge graphs. Rendle <ref type="bibr" target="#b81">[80]</ref> applied factorization machines to large uni-relational data sets in recommendation settings. <ref type="bibr">Jenatton et al. [81]</ref> proposed a tensor factorization model for knowledge graphs with a very large number of different relations.</p><p>It is also possible to use discrete latent factors. Miettinen <ref type="bibr" target="#b83">[82]</ref> proposed Boolean tensor factorization to disambiguate facts extracted with OpenIE methods and applied it to large data sets <ref type="bibr" target="#b84">[83]</ref>. In contrast to previously discussed factorizations, Boolean tensor factorizations are discrete models, where adjacency tensors are decomposed into binary factors based on Boolean algebra. from this representation. In particular, we can rewrite RESCAL as</p><formula xml:id="formula_8">f RESCAL ijk :? w &gt; k F RESCAL ij (4) F RESCAL ij :? e j e i<label>(5)</label></formula><p>where w k ? vec?W k ?. Equation (4) follows from (3) via the equality vec?AXB? ? ?B &gt; A?vec?X?. Hence, RESCAL represents pairs of entities ?e i ; e j ? via the tensor product of their latent feature representations (5) and predicts the existence of the triple x ijk from F ij via w k (4). See also <ref type="figure" target="#fig_7">Fig. 5(a)</ref>. For a further discussion of the tensor product to create composite latent representations, see <ref type="bibr" target="#b89">[88]</ref>- <ref type="bibr" target="#b91">[90]</ref>.</p><p>Since the tensor product explicitly models all pairwise interactions, RESCAL can require a lot of parameters when the number of latent features are large (each matrix W k has H</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Matrix Factorization Methods</head><p>Another approach for learning from knowledge graphs is based on matrix factorization, where, prior to the factorization, the adjacency tensor</p><formula xml:id="formula_9">Y 2 R N e ?N e ?N r is reshaped into a matrix Y 2 R 2 e N 2</formula><p>e ?N r by associating rows with subject-object pairs ?e i ; e j ? and columns with relations r k (cf., <ref type="bibr" target="#b85">[84]</ref> and <ref type="bibr" target="#b86">[85]</ref>), or into a matrix Y 2 R N e ?N e N r by associating rows with subjects e i and columns with relation/objects ?r k ; e j ? (cf., <ref type="bibr" target="#b87">[86]</ref> and <ref type="bibr" target="#b88">[87]</ref>). Unfortunately, both of these formulations lose information compared to tensor factorization. For instance, if each subject-object pair is modeled via a different latent representation, the information that the relationships y ijk and y pjq share the same object is lost. It also leads to an increased memory complexity, since a separate latent representation is computed for each pair of entities, requiring O?N entries). This can, for instance, lead to scalability problems on knowledge graphs with a large number of relations.</p><p>In the following, we will discuss models based on multilayer perceptrons (MLPs), also known as feedforward neural networks. In the context of multidimensional data they can be referred to a multiway neural networks. This approach allows us to consider alternative ways to create composite triple representations and to use nonlinear functions to predict their existence.</p><p>In particular, let us define the following E-MLP model (E for entity):</p><formula xml:id="formula_10">f E-MLP ijk :? w &gt; k g h a ijk (6) h a &gt; ijk :? A k F E-MLP ij (7) 2 e H e ? N r H e ? parameters (compared to O?N e H e ? N r H 2 F E-MLP ij :? ?e i ; e j ?<label>(8)</label></formula><p>e ? parameters for RESCAL).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Multilayer Perceptrons</head><p>We can interpret RESCAL as creating composite representations of triples and predicting their existence where g?u? ? ?g?u 1 ?; g?u 2 ?; . . .? is the function g applied element-wise to vector u; one often uses the nonlinear function g?u? ? tanh?u?. Here h a is an additive hidden layer, which is deriving by adding together different weighed components of the entity representations. In particular, we create a composite representation F each other. For instance, the closest relations to the children relation are parents, spouse, and birthplace.</p><formula xml:id="formula_11">E-MLP ij ? ?e i ; e j ? 2 R</formula><p>2H a via the concatenation of e i and e j . However, concatenation alone does not consider any interactions between the latent features of e i and e j . For this reason, we add a (vectorvalued) hidden layer h a of size H a , from which the final prediction is derived via w &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Neural Tensor Networks</head><p>We can combine traditional MLPs with bilinear models, resulting in what <ref type="bibr" target="#b93">[92]</ref> calls a ''neural tensor network'' (NTN). More precisely, we can define the NTN model as follows:</p><p>k g?h a ?. The important difference to tensor-product models like RESCAL is that we learn the interactions of latent features via the matrix A k (7), while the tensor product considers always all possible interactions between latent features. This adaptive approach can reduce the number of required parameters significantly, especially on data sets with a large number of relations.</p><p>One disadvantage of the E-MLP is that it has to define a vector w k and a matrix A k for every possible relation, which requires H a ? ?H a ? 2H e ? parameters per relation. An alternative is to embed the relation itself, using a H r -dimensional vector r k . We can then define</p><formula xml:id="formula_12">f NTN ijk :? w &gt; a k g h ijk ; h b ijk h i (12) h a &gt; ijk :? A k ?e i ; e j ?<label>(13)</label></formula><formula xml:id="formula_13">h b &gt; 1 &gt; H b ijk :? e i B k e j ; . . . ; e i B k e j ? ? :<label>(14)</label></formula><p>Here B k is a tensor, where the 'th slice B </p><formula xml:id="formula_14">:? w &gt; g h c ijk (9) h c ijk :? C &gt; F ER-MLP ijk<label>(10)</label></formula><formula xml:id="formula_15">F ER-MLP ijk :? ?e i ; e j ; r k ?:<label>(11)</label></formula><p>ijk a bilinear hidden layer, since it is derived from a weighted combination of multiplicative terms.</p><p>NTN is a generalization of the RESCAL approach, as we explain in Section XII-A. Also, it uses the additive layer from the E-MLP model. However, it has many more parameters than the E-MLP or RESCAL models. Indeed, the results in <ref type="bibr" target="#b96">[95]</ref> and <ref type="bibr" target="#b27">[28]</ref> both show that it tends to overfit, at least on the (relatively small) data sets uses in those papers.</p><p>We call this model the ER-MLP, since it applies an MLP to an embedding of the entities and relations. Please note that ER-MLP uses a global weight vector for all relations. This model was used in the KV project (see Section IX), since it has many fewer parameters than the E-MLP (see <ref type="table" target="#tab_9">Table 5</ref>); the reason is that C is independent of the relation k.</p><p>It has been shown in <ref type="bibr" target="#b92">[91]</ref> that MLPs can learn to put ''semantically similar'' words close by in the embedding space, even if they are not explicitly trained to do so. In <ref type="bibr" target="#b27">[28]</ref>, they show a similar result for the semantic embedding of relations using ER-MLP. For example, <ref type="table" target="#tab_7">Table 4</ref> shows the nearest neighbors of latent representations of selected relations that have been computed with a 60-dimensional model on Freebase. Numbers in parentheses represent squared Euclidean distances. It can be seen that ER-MLP puts semantically related relations near</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Latent Distance Models</head><p>Another class of models are latent distance models (also known as latent space models in social network analysis), which derive the probability of relationships from the distance between latent representations of entities: entities are likely to be in a relationship if their latent representations are close according to some distance measure. For unirelational data, <ref type="bibr">Hoff et al. [96]</ref> proposed this approach first in the context of social networks by modeling the probability of a relationship x ij via the score function f ?e i ; e j ? ? ?d?e i ; e j ? where d??; ?? refers to an arbitrary distance measure such as the Euclidean distance.</p><p>The structured embedding (SE) model <ref type="bibr" target="#b94">[93]</ref> extends this idea to multirelational data by modeling the score of a triple x ijk as transform the global latent feature representations of entities to model relationships specifically for the kth relation. The transformations are learned using the ranking loss in a way such that pairs of entities in existing relationships are closer to each other than entities in nonexisting relationships.</p><formula xml:id="formula_16">f SE s o ijk :? ? A k e i ? A k e j 1 ? ? h a ijk 1 (15)</formula><p>To reduce the number of parameters over the SE model, the TransE model <ref type="bibr" target="#b95">[94]</ref> translates the latent feature representations via a relation-specific offset instead of transforming them via matrix multiplications. In particular, the score of a triple x ijk is defined as the triple (John, married To, Mary) from the existence of the path John ?! parentOf Anne ? parentOf Mary, representing a common child. In contrast to latent feature models, this kind of reasoning explains triples directly from the observed triples in the knowledge graph. We will now discuss some models of this kind.</p><formula xml:id="formula_17">f TransE ijk :? ?d?e i ? r k ; e j ?:<label>(16)</label></formula><p>This model is inspired by the results in <ref type="bibr" target="#b92">[91]</ref>, who showed that some relationships between words could be computed by their vector difference in the embedding space. As noted in <ref type="bibr" target="#b96">[95]</ref>, under unit-norm constraints on e i ; e j and using the squared Euclidean distance, we can rewrite (16) as follows:</p><formula xml:id="formula_18">f TransE ijk ? ? 2r &gt; &gt; k ?e i ? e j ? ? 2e i e j ? kr k k 2 2 ? ? :<label>(17)</label></formula><p>Furthermore, if we assume  <ref type="table" target="#tab_9">Table 5</ref> summarizes the different models we have discussed. A natural question is: which model is best? <ref type="bibr" target="#b27">[28]</ref> showed that the ER-MLP model outperformed the NTN model on their particular data set. Reference <ref type="bibr" target="#b96">[95]</ref> performed more extensive experimental comparison of these models, and found that RESCAL (called the bilinear model) worked best on two link prediction tasks. However, clearly the best model will be data set dependent.</p><formula xml:id="formula_19">A k ? ?r k ; ?r k ?, so that h a ijk ? ?r k ; ?r k ? T ?e i ; e j ? ? r T k ?e i ? e j ?,</formula><formula xml:id="formula_20">f TransE ijk ? ? 2h a b ijk ? 2h ijk ? kr k k 2 2 :<label>(18)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Comparison of Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. GRAPH FEATURE MODELS</head><p>In this section, we assume that the existence of an edge can be predicted by extracting features from the observed edges in the graph. For example, due to social conventions, parents of a person are often married, so we could predict</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Similarity Measures for Unirelational Data</head><p>Observable graph feature models are widely used for link prediction in graphs that consist only of a single relation, e.g., social network analysis (friendships between people), biology (interactions of proteins), and Web mining (hyperlinks between Web sites). The intuition behind these methods is that similar entities are likely to be related (homophily) and that the similarity of entities can be derived from the neighborhood of nodes or from the existence of paths between nodes. For this purpose, various indices have been proposed to measure the similarity of entities, which can be classified into local, global, and quasi-local approaches <ref type="bibr" target="#b98">[97]</ref>.</p><p>Local similarity indices such as Common Neighbors, the Adamic-Adar index <ref type="bibr" target="#b99">[98]</ref> or Preferential Attachment <ref type="bibr" target="#b100">[99]</ref> derive the similarity of entities from their number of common neighbors or their absolute number of neighbors. Local similarity indices are fast to compute for single relationships and scale well to large knowledge graphs as their computation depends only on the direct neighborhood of the involved entities. However, they can be too localized to capture important patterns in relational data and cannot model long-range or global dependencies.</p><p>Global similarity indices such as the Katz index [100] and the Leicht-Holme-Newman index <ref type="bibr" target="#b102">[101]</ref> derive the similarity of entities from the ensemble of all paths between entities, while indices like Hitting Time, <ref type="bibr">Commute Time, and PageRank [102]</ref> derive the similarity of entities from random walks on the graph. Global similarity indices often provide significantly better predictions than local indices, but are also computationally more expensive <ref type="bibr" target="#b57">[56]</ref>, <ref type="bibr" target="#b98">[97]</ref>.</p><p>Quasi-local similarity indices like the Local Katz index <ref type="bibr" target="#b57">[56]</ref> or Local Random Walks <ref type="bibr" target="#b104">[103]</ref> try to balance predictive accuracy and computational complexity by deriving the similarity of entities from paths and random walks of bounded length.</p><p>In Section V-C, we will discuss an approach that extends this idea of quasi-local similarity indices for unirelational networks to learn from large multirelational knowledge graphs.</p><p>We can then predict the edge probabilities using logistic regression</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Rule Mining and Inductive Logic Programming</head><p>Another class of models that works on the observed variables of a knowledge graph extracts rules via mining methods and uses these extracted rules to infer new links. The extracted rules can also be used as a basis for Markov logic as discussed in Section VIII. For instance, ALEPH is an inductive logic programming (ILP) system that attempts to learn rules from relational data via inverse entailment <ref type="bibr" target="#b105">[104]</ref> (For more information on ILP, see, e.g., <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b106">[105]</ref>, and <ref type="bibr" target="#b107">[106]</ref>). AMIE is a rule mining system that extracts logical rules (in particular Horn clauses) based on their support in a knowledge graph <ref type="bibr" target="#b108">[107]</ref>, <ref type="bibr" target="#b110">[108]</ref>. In contrast to ALEPH, AMIE can handle the open-world assumption of knowledge graphs and has shown to be up to three orders of magnitude faster on large knowledge graphs <ref type="bibr" target="#b110">[108]</ref>. The basis for the semantic web is description logic and <ref type="bibr" target="#b111">[109]</ref>- <ref type="bibr" target="#b113">[111]</ref> describe approaches for logic-oriented machine learning approaches in this context. Also to mention are data mining approaches for knowledge graphs as described in <ref type="bibr" target="#b114">[112]</ref>- <ref type="bibr" target="#b116">[114]</ref>. An advantage of rule-based systems is that they are easily interpretable as the model is given as a set of logial rules. However, rules over observed variables cover usually only a subset of patterns in knowledge graphs (or relational data) and useful rules can be challenging to learn.</p><formula xml:id="formula_21">f PRA ijk :? w &gt; PRA k F ijk :<label>(20)</label></formula><p>Interpretability: A useful property of PRA is that its model is easily interpretable. In particular, relation paths can be regarded as bodies of weighted rulesVmore precisely Horn clausesVwhere the weight specifies how predictive the body of the rule is for the head. For instance, <ref type="table" target="#tab_10">Table 6</ref> shows some relation paths along with their weights that have been learned by PRA in the KV project (see Section IX) to predict which college a person attended, i.e., to predict triples of the form (p, college, c). The first relation path in <ref type="table" target="#tab_10">Table 6</ref> can be interpreted as follows: it is likely that a person attended a college if the sports team that drafted the person is from the same college. This can be written in the form of a Horn clause as follows:</p><p>?p; college; c? ?p; draftedBy; t? ^ ?t; school; c?:</p><p>By using a sparsity promoting prior on w k , we can perform feature selection, which is equivalent to rule learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Path Ranking Algorithm (PRA)</head><p>The path ranking algorithm (PRA) <ref type="bibr" target="#b117">[115]</ref>, <ref type="bibr" target="#b118">[116]</ref> extends the idea of using random walks of bounded lengths for predicting links in multirelational knowledge graphs. In particular, let L ?i; j; k; t? denote a path of length L of the form e i ! r 1 e 2 ! r 2 e 3 ? ? ? ! r L e j , where t represents the Relational Learning Results: PRA has been shown to outperform the ILP method FOIL <ref type="bibr" target="#b107">[106]</ref> for link prediction in NELL <ref type="bibr" target="#b118">[116]</ref>. It has also been shown to have comparable performance to ER-MLP on link prediction in KV: PRA obtained a result of 0.884 for the area under the ROC curve, as compared to 0.882 for ER-MLP <ref type="bibr" target="#b27">[28]</ref>. sequence of edge types t ? ?r 1 ; r 2 ; . . . ; r L ?. We also require there to be a direct arc e i ! r k e j , representing the existence of a relationship of type k from e i to e j . Let q L ?i; j; k? represent the set of all such paths of length L, ranging over path types t. (We can discover such paths by enumerating all (type-consistent) paths from entities of type e i to entities of type e j . If there are too many relations to make this feasible, we can perform random sampling.) We can compute the probability of following such a path by assuming that at each step, we follow an outgoing link uniformly at random. Let P? L ?i; j; k; t?? be the probability of this particular path; this can be computed recursively by a sampling procedure, similar to PageRank (see <ref type="bibr" target="#b118">[116]</ref> for details). The key idea in PRA is to use these path probabilities as features for predicting the probability of missing edges. More precisely, define the feature vector</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. COMBINING LATENT AND GRAPH FEATURE MODELS</head><p>It has been observed experimentally (see, e.g., <ref type="bibr" target="#b27">[28]</ref>) that neither state-of-the-art relational latent feature models (RLFMs) nor state-of-the-art graph feature models are </p><formula xml:id="formula_22">F PRA ijk ? P?? : 2 q L ?i; j; k? ? ? :<label>(19)</label></formula><p>superior for learning from knowledge graphs. Instead, the strengths of latent and graph-based models are often complementary (see, e.g., <ref type="bibr" target="#b119">[117]</ref>), as both families focus on different aspects of relational data.</p><p>? Latent feature models are well-suited for modeling global relational patterns via newly introduced latent variables. They are computationally efficient if triples can be explained with a small number of latent variables.</p><p>? Graph feature models are well-suited for modeling local and quasi-local graphs patterns. They are computationally efficient if triples can be explained from the neighborhood of entities or from short paths in the graph. There has also been some theoretical work comparing these two approaches <ref type="bibr" target="#b120">[118]</ref>. In particular, it has been shown that tensor factorization can be inefficient when relational data consists of a large number of strongly connected components. Fortunately, such ''problematic'' relations can often be handled efficiently via graph-based models. A good example is the marriedTo relation: One marriage corresponds to a single strongly connected component, so data with a large number of marriages would be difficult to model with RLFMs. However, predicting marriedTo links via graph-based models is easy: the existence of the triple (John, marriedTo, Mary) can be simply predicted from the existence of (Mary, marriedTo, John), by exploiting the symmetry of the relation. If the (Mary, marriedTo, John) edge is unknown, we can use statistical patterns, such as the existence of shared children.</p><p>Combining the strengths of latent and graph-based models is therefore a promising approach to increase the predictive performance of graph models. It typically also speeds up the training. We now discuss some ways of combining these two kinds of models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Other Combined Models</head><p>In addition to ARE, further models have been explored to learn jointly from latent and observable patterns on relational data. <ref type="bibr">Jiang et al. [84]</ref> and <ref type="bibr">Riedel et al. [85]</ref> combined a latent feature model with an additive term to learn from latent and neighborhood-based information on multirelational data, as follows 11 :</p><formula xml:id="formula_23">f ADD ijk :? w ?1?&gt; ?2?&gt; k;j F SUB i ? w k;i F OBJ j ? w ?3?&gt; k F N ijk (22) F N ijk :? ?y ijk 0 : k 0 6 ? k?:<label>(23)</label></formula><p>Here, F SUB i</p><p>is the latent representation of entity e i as a subject and F OBJ j is the latent representation of entity e j as an object. The term F N</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Additive Relational Effects Model</head><p>Reference <ref type="bibr" target="#b120">[118]</ref> proposed the additive relational effects (ARE), which is a way to combine RLFMs with observable graph models. In particular, if we combine RESCAL with PRA, we get ijk captures patterns efficiently where the existence of a triple y ijk 0 is predictive of another triple y ijk between the same pair of entities (but of a different relation type). For instance, if Leonard Nimoy was born in Boston, it is also likely that he lived in Boston. This dependency between the relation types bornIn and livedIn can be modeled in (23) by assigning a large weight to w bornIn;livedIn .</p><p>ARE and the models of <ref type="bibr" target="#b85">[84]</ref> and <ref type="bibr" target="#b86">[85]</ref> are similar in spirit to the model of <ref type="bibr" target="#b121">[119]</ref>, which augments SVD (i.e., matrix factorization) of a rating matrix with additive terms to include local neighborhood information. Similarly, factorization machines <ref type="bibr" target="#b122">[120]</ref> allow to combine latent and observable patterns, by modeling higher order interactions between input variables via low-rank factorizations <ref type="bibr" target="#b79">[78]</ref>.</p><p>An alternative way to combine different prediction systems is to fit them separately, and use their outputs as inputs to another ''fusion'' system. This is called stacking <ref type="bibr" target="#b123">[121]</ref>. For instance, <ref type="bibr">Dong et al. [28]</ref> used the output of PRA and ER-MLP as scalar features, and learned a final ''fusion'' layer by training a binary classifier. Stacking has the advantage that it is very flexible in the kinds of models that can be combined. However, it has the disadvantage that the individual models cannot cooperate, and thus any individual model needs to be more complex than in a combined model which is trained jointly. For example, if we fit RESCAL separately from PRA, we will need a larger number of latent features than if we fit them jointly.</p><formula xml:id="formula_24">f RESCAL?PRA ijk ? w ?1?&gt; k F RESCAL ij ? w ?2?&gt; k F PRA ijk : (21)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. TRAINING SRL MODELS ON KNOWLEDGE GRAPHS</head><p>ARE models can be trained by alternately optimizing the RESCAL parameters with the PRA parameters. The key benefit is now RESCAL only has to model the ''residual errors'' that cannot be modelled by the observable graph patterns. This allows the method to use much lower latent dimensionality, which significantly speeds up training time. The resulting combined model also has increased accuracy <ref type="bibr" target="#b120">[118]</ref>.</p><p>In this section, we discuss aspects of training the previously discussed models that are specific to knowledge graphs, such as how to handle the open-world assumption of knowledge graphs, how to exploit sparsity, and how to perform model selection. <ref type="bibr" target="#b10">11</ref> Reference <ref type="bibr" target="#b86">[85]</ref> considered an additional term f</p><formula xml:id="formula_25">UNI ijk :? f ADD ijk ? w &gt; k F SUB?OBJ ij , where F SUB?OBJ ij</formula><p>is a (noncomposite) latent feature representation of subject-object pairs.</p><p>Vol. 104, No. 1, January 2016 | Proceedings of the IEEE 23 <ref type="bibr">Nickel et al.</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>: A Review of Relational Machine Learning for Knowledge Graphs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Penalized Maximum-Likelihood Training</head><p>Let us assume we have a set of N d observed triples and let the nth triple be denoted by x n . Each observed triple is either true (denoted y n ? 1) or false (denoted y n ? 0). Let this labeled data set be denoted by D ? f?x n ; y n ?j n ? 1; . . . ; N d g. Given this, a natural way to estimate the parameters 0 is to compute the maximum a posteriori (MAP) estimate</p><formula xml:id="formula_26">max X N d 0 log Ber y n j f ?x n ; 0? ? ? ? ? ? log p?0j? (24) n?1</formula><p>where controls the strength of the prior. (If the prior is uniform, this is equivalent to maximum-likelihood training.) We can equivalently state this as a regularized loss minimization problem:</p><formula xml:id="formula_27">min X N n 0 L f ?x n ; 0? ? ? ; y ? ? ? reg?0? (25) n?1</formula><p>where L?p; y? ? ? log Ber?yjp? is the log loss function. Another possible loss function is the squared loss, L?p; y? ? ?p ? y? 2 . Using the squared loss can be especially efficient in combination with a closed-world assumption (CWA). For instance, using the squared loss and the CWA, the minimization problem for RESCAL becomes One way around this is as to make a closed world assumption and assume that all (type consistent) triples that are not in D ? are false. We will denote this negative set as D ? ? fx n 2 Djy n ? 0g. However, for incomplete knowledge graphs this assumption will be violated. Moreover, D ? might be very large, since the number of false facts is much larger than the number of true facts. This can lead to scalability issues in training methods that have to consider all negative examples.</p><p>An alternative approach to generate negative examples is to exploit known constraints on the structure of a knowledge graph: Type constraints for predicates (persons are only married to persons), valid value ranges for attributes (the height of humans is below 3 m), or functional constraints such as mutual exclusion (a person is born exactly in one city) can all be used for this purpose. Since such examples are based on the violation of hard constraints, it is certain that they are indeed negative examples. Unfortunately, functional constraints are scarce and negative examples based on type constraints and valid value ranges are usually not sufficient to train useful models: While it is relatively easy to predict that a person is married to another person, it is difficult to predict to which person in particular. For the latter, examples based on type constraints alone are not very informative. A better way to generate negative examples is to ''perturb'' true triples. In particular, let us define</p><formula xml:id="formula_28">D ? ? ?e ' ; r k ; e j ? j e i 6 ? e ' ^ ?e i ; r k ; e j ? 2 D ? ? ? [ ?e i ; r k ; e ' ? j e j 6 ? e ' ^ ?e i ; r k ; e j ? 2 D ? ? ? : min X 2 E;fW k g kY k ? EW k E &gt; k F ? 1 kEk 2 F k ? 2 X kW k k 2 F<label>(26)</label></formula><p>k where 1 ; 2 [0 control the degree of regularization. The main advantage of <ref type="formula" target="#formula_28">(26)</ref> is that it can be optimized via RESCAL-ALS, which consists of a sequence of very efficient, closed-form updates whose computational complexity depends only on the nonzero entries in Y <ref type="bibr" target="#b64">[63]</ref>, <ref type="bibr" target="#b65">[64]</ref>. We discuss some other loss functions below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Where do the Negative Examples Come From?</head><p>One important question is where the labels y n come from. The problem is that most knowledge graphs only contain positive training examples, since, usually, they do not encode false facts. Hence, y n ? 1 for all ?x n ; y n ? 2 D. To emphasize this, we shall use the notation D ? to represent the observed positive (true) triples:</p><formula xml:id="formula_29">D ? ? fx n 2 Djy n ? 1g.</formula><p>Training on all-positive data is tricky, because the model might easily over generalize.</p><p>To understand the difference between this approach and the CWA (where we assumed all valid unknown triples were false), let us consider the example in <ref type="figure" target="#fig_0">Fig. 1</ref>. The CWA would generate ''good'' negative triples such as (LeonardNimoy, starredIn, StarWars), (AlecGuinness, starredIn, StarTrek), etc., but also type-consistent but ''irrelevant'' negative triples such as (BarackObama, starredIn, StarTrek), etc. (We are assuming (for the sake of this example) there is a type Person but not a type Actor.) The second approach (based on perturbation) would not generate negative triples such as (BarackObama, starredIn, StarTrek), since BarackObama does not participate in any starredIn events. This reduces the size of D ? , and encourages it to focus on ''plausible'' negatives. (An even better method, used in Section IX, is to generate the candidate triples from text extraction methods run on the Web. Many of these triples will be false, due to extraction errors, but they define a good set of ''plausible'' negatives.)</p><p>Another option to generate negative examples for training is to make a local-closed world assumption (LCWA) <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b108">[107]</ref>, in which we assume that a KG is only locally complete. More precisely, if we have observed any triple for a particular subject-predicate pair e i ; r k , then we will assume that any nonexisting triple ?e i ; r k ; ?? is indeed false and include them in D ? . (The assumption is valid for functional relations, such as bornIn, but not for set-valued relations, such as starredIn.) However, if we have not observed any triple at all for the pair e i ; r k , we will assume that all triples ?e i ; r k ; ?? are unknown and not include them in D ? .</p><p>(AUC-ROC) or the area under the precision-recall curve (AUC-PR) are good evaluation criteria. For data with a large number of negative examples (as it is typically the case for knowledge graphs), it has been shown that AUC-PR can give a clearer picture of an algorithm's performance than AUC-ROC <ref type="bibr" target="#b126">[124]</ref>. For entity resolution, the mean reciprocal rank (MRR) of the correct entity is an alternative evaluation measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Pairwise Loss Training</head><p>Given that the negative training examples are not always really negative, an alternative approach to likelihood training is to try to make the probability (or in general, some scoring function) to be larger for true triples than for assumed-to-be-false triples. That is, we can define the following objective function:</p><formula xml:id="formula_30">VIII. MARKOV RANDOM FIELDS min X X 0 L f ?x ? ; 0?; f ?x ? ; 0? ? ? ? reg?0? (27) x ? 2D ? x ? 2D ?</formula><p>where L?f ; f 0 ? is a margin-based ranking loss function such as</p><formula xml:id="formula_31">L?f ; f 0 ? ? max?1 ? f 0 ? f ; 0?:<label>(28)</label></formula><p>In this section, we drop the assumption that the random variables y ijk in Y are conditionally independent. However, in the case of relational data and without the conditional independence assumption, each y ijk can depend on any of the other N e ? N e ? N r ? 1 random variables in Y. Due to this enormous number of possible dependencies, it becomes quickly intractable to estimate the joint distribution P?Y? without further constraints, even for very small knowledge graphs. To reduce the number of potential dependencies and arrive at tractable models, in this section we develop template-based graphical models that only consider a small fraction of all possible dependencies. (See <ref type="bibr" target="#b127">[125]</ref> for an introduction to graphical models.)</p><p>This approach has several advantages. First, it does not assume that negative examples are necessarily negative, just that they are ''more negative'' than the positive ones. Second, it allows the f ??? function to be any function, not just a probability (but we do assume that larger f values mean the triple is more likely to be correct). This kind of objective function is easily optimized by stochastic gradient descent (SGD) <ref type="bibr" target="#b124">[122]</ref>: at each iteration, we just sample one positive and one negative example. SGD also scales well to large data sets. However, it can take a long time to converge. On the other hand, as discussed previously, some models, when combined with the squared loss objective, can be optimized using alternating least squares (ALS), which is typically much faster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Representation</head><p>Graphical models use graphs to encode dependencies between random variables. Each random variable (in our case, a possible fact y ijk ) is represented as a node in the graph, while each dependency between random variables is represented as an edge. To distinguish such graphs from knowledge graphs, we will refer to them as dependency graphs. It is important to be aware of their key difference: while knowledge graphs encode the existence of facts, dependency graphs encode statistical dependencies between random variables.</p><p>To avoid problems with cyclical dependencies, it is common to use undirected graphical models, also called Markov random fields (MRFs). <ref type="bibr" target="#b11">12</ref> A MRF has the following form:</p><p>Y</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Model Selection</head><p>Almost all models discussed in previous sections include one or more user-given parameters that are influential for the model's performance (e.g., dimensionality of latent feature models, length of relation paths for PRA, regularization parameter for penalized maximum likelihood training). Typically, cross-validation over random splits of D into training, validation, and test sets is used to find good values for such parameters without overfitting (for more information on model selection in machine learning, see, e.g., <ref type="bibr" target="#b125">[123]</ref>). For link prediction and entity resolution, the area under the ROC curve</p><formula xml:id="formula_32">P?YjQ? ? 1 Z ?y c jQ? (29) c</formula><p>where ?y c jQ?[0 is a potential function on the cth subset of variables, in particular the cth clique in the dependency graph, and Z ? P y Q c ?y c jQ? is the partition function, which ensures that the distribution sums to one. The potential functions capture local correlations between variables in each clique c in the dependency graph. (Note that in undirected graphical models, the local potentials do not have any probabilistic interpretation, unlike in directed graphical models.) This equation again defines a probability distribution over ''possible worlds,'' i.e., over joint distribution assigned to the random variables Y.</p><p>The structure of the dependency graph [which defines the cliques in <ref type="bibr" target="#b28">(29)</ref>] is derived from a template mechanism that can be defined in a number of ways. A common approach is to use Markov logic <ref type="bibr" target="#b128">[126]</ref>, which is a template language based on logical formulae:</p><p>Given a set of formulae F ? fF i g represent these dependencies using formulae such as To explain this further, consider a KG involving two types of entities, adults and children, and two types of relations, parentOf and marriedTo. <ref type="figure" target="#fig_8">Fig. 6</ref>(a) depicts a sample KG with three adults and one child. Obviously, these relations (edges) are correlated, since people who share a common child are often married, while people rarely marry their own children. In Markov logic, we</p><p>Rather than encoding the rule that adults cannot marry their own children using a formula, we will encode this as a hard constraint into the type system. Similarly, we only allow adults to be parents of children. Thus, there are six possible facts in the knowledge graph. To create a dependency graph for this KG and for this set of logical formulae F , we assign a binary random variable to each possible fact, represented by a diamond in <ref type="figure" target="#fig_8">Fig. 6(b)</ref>, and create edges between these nodes if the corresponding facts occur in grounded formulae F 1 or F 2 . For instance, grounding F 1 with x ? a 1 , y ? a 3 , and z ? c, creates the edges m 13 ! p 1 c, m 13 ! p 3 c, and p 1 c ! p 3 c. The full dependency graph is shown in <ref type="figure" target="#fig_8">Fig. 6(c)</ref>.</p><p>The process of generating the MRF graph by applying templated rules to a set of entities is known as grounding or instantiation. We note that the topology of the resulting graph is quite different from the original KG. In particular, we have one node per possible KG edge, and these nodes are densely connected. This can cause computational difficulties, as we discuss below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Inference</head><p>The inference problem consists of estimating the most probable configuration, y ? ? arg max y p?yjQ?, or the posterior marginals p?y i jQ?. In general, both of these problems are computationally intractable <ref type="bibr" target="#b127">[125]</ref>, so heuristic approximations must be used. One approach for computing posterior marginals is to use Gibbs sampling (see, or example, <ref type="bibr" target="#b30">[31]</ref> and <ref type="bibr" target="#b129">[127]</ref>) or MC-SAT <ref type="bibr" target="#b130">[128]</ref>. One approach for computing the MAP estimate is to use the MPLP (max product linear programming) method <ref type="bibr" target="#b131">[129]</ref>. See <ref type="bibr" target="#b127">[125]</ref> for more details.</p><p>If one restricts the class of potential functions to be just disjunctions (using or and not, but no and), then one obtains a (special case of) hinge loss MRF (HL-MRFs) <ref type="bibr" target="#b132">[130]</ref>, for which efficient convex algorithms can be applied, based on a continuous relaxation of the binary random variables. Probabilistic soft logic (PSL) <ref type="bibr" target="#b133">[131]</ref> provides a convenient form of ''syntactic sugar'' for defining HLMRFs, just as MLNs provide a form of syntactic sugar for regular (boolean) MRFs. HL-MRFs have been shown to scale to fairly large knowledge bases <ref type="bibr" target="#b134">[132]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Learning</head><p>The ''learning'' problem for MRFs deals with specifying the form of the potential functions (sometimes called ''structure learning'') as well as the values for the numerical parameters Q. In the case of MRFs for KGs, the potential functions are often specified in the form of logical rules, as illustrated above. In this case, structure learning is equivalent to rule learning, which has been studied in a number of published works (see Section V-C and <ref type="bibr" target="#b96">[95]</ref> and <ref type="bibr" target="#b108">[107]</ref>).</p><p>The parameter estimation problem (which is usually cast as maximum likelihood or MAP estimation), although convex, is in general quite expensive, since it needs to call inference as a subroutine. Therefore, various faster approximations, such as pseudo likelihood, have been developed (cf., relational dependency networks <ref type="bibr" target="#b135">[133]</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussion</head><p>Although approaches based on MRFs are very flexible, it is in general harder to make scalable inference and devise learning algorithms for this model class, compared to methods based on observable or even latent feature models. In this paper, we have chosen to focus primarily on latent and graph feature models because we have more experience with such methods in the context of KGs. However, all three kinds of approaches to KG modeling are useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IX. KNOWLEDGE VAULT: RELATIONAL LEARNING FOR KNOWLEDGE BASE CONSTRUCTION</head><p>edges. Finally, the confidence in the automatically extracted facts is evaluated using both the extraction scores and the prior SRL model.</p><p>The knowledge vault uses a combination of latent and observable models to predict links in a knowledge graph. In particular, it employs the ER-MLP model (see Section IV-D) as a latent feature model and PRA (Section V-C) as a graph feature model. In order to combine the two models, KV uses stacking (see Section VI-B). To evaluate the link prediction performance, these models were applied to a subset of Freebase. The ER-MLP system achieved an area under the ROC curve (AUC-ROC) of 0.882, and the PRA approach achieved an almost identical AUC-ROC of 0.884. The combination of both methods further increased the AUC-ROC to 0.911. To predict the final score of a triple, the scores from the combined linkprediction model are further combined with various features derived from the extracted triples. These include, for instance, the confidence of the extractors and the number of (deduplicated) Web pages from which the triples were extracted. <ref type="figure" target="#fig_9">Fig. 7</ref> provides a high level overview of the knowledge vault architecture.</p><p>Let us give a qualitative example of the benefits of combining the prior with the extractors (i.e., the fusion layer in <ref type="figure" target="#fig_9">Fig. 7)</ref>. Consider an extracted triple corresponding to the following relation 13 :</p><p>The knowledge vault (KV) <ref type="bibr" target="#b27">[28]</ref> is a very large-scale automatically constructed knowledge base, which follows the Freebase schema (KV uses the 4469 most common predicates). It is constructed in three steps. In the first step, facts are extracted from a host of Web sources such as natural language text, tabular data, page structure, and human annotations (the extractors are described in detail in <ref type="bibr" target="#b27">[28]</ref>). Second, an SRL model is trained on Freebase to serve as a ''prior'' for computing the probability of (new) (Barry Richter, attended, University of WisconsinMadison).</p><p>The extraction confidence for this triple (obtained by fusing multiple extraction techniques) is just 0.14, since it <ref type="bibr" target="#b12">13</ref> For clarity of presentation we show a simplified triple. Please see <ref type="bibr" target="#b27">[28]</ref> for the actually extracted triples including compound value types (CVT).</p><p>Vol. 104, No. 1, January 2016 | Proceedings of the IEEE 27 was based on the following two rather indirect statements 14 :</p><p>In the fall of 1989, Richter accepted a scholarship to the University of Wisconsin, where he played for four years and earned numerous individual accolades. . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and 15</head><p>The Polar Caps' cause has been helped by the impact of knowledgable coaches such as Andringa, Byce and former UW teammates Chris Tancill and Barry Richter.</p><p>relations. In Section II, we expressed the ternary relationship playedCharacterIn(LeonardNimoy, Spock, StarTrek-1) via two binary relationships (LeonardNimoy, played, Spock) and (Spock, characterIn, StarTrek-1). However, there are multiple actors who played Spock in different Star Trek movies, so we have lost the correspondence between Leonard Nimoy and StarTrek-1. To model this using binary relations without loss of information, we can use auxiliary nodes to identify the respective relationship. For instance, to model the relationship playedCharacterIn(LeonardNimoy, Spock, StarTrek-1), we can write However, we know from Freebase that Barry Richter was born and raised in Madison, WI, USA. According to the prior model, people who were born and raised in a particular city often tend to study in the same city. This increases our prior belief that Richter went to school there, resulting in a final fused belief of 0.61.</p><p>Combining the prior model (learned using SRL methods) with the information extraction model improved performance significantly, increasing the number of high confidence triples 16 from 100 millions (based on extractors alone) to 271 millions (based on extractors plus prior). The knowledge vault is one of the largest applications of SRL to knowledge base construction to date. See <ref type="bibr" target="#b27">[28]</ref> for further details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X. EXTENSIONS AND FUTURE WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Nonbinary Relations</head><p>So far, we completely focussed on binary relations; here we discuss how relations of other cardinalities can be handled.</p><p>Unary Relations: Unary relations refer to statements on properties of entities, e.g., the height of a person. Such data can naturally be represented by a matrix, in which rows represent entities, and columns represent attributes. <ref type="bibr" target="#b65">[64]</ref> proposed a joint tensor-matrix factorization approach to learn simultaneously from binary and unary relations via a shared latent representation of entities. In this case, we may also need to modify the likelihood function, so it is Bernoulli for binary edge variables, and Gaussian (say) for numeric features and Poisson for count data (see <ref type="bibr" target="#b136">[134]</ref>).</p><p>where we used the auxiliary entity MovieRole-1 to uniquely identify this particular relationship. In most applications auxiliary entities get an identifier; if not they are referred to as blank nodes. In Freebase auxiliary nodes are called compound value types (CVT).</p><p>Since higher arity relations involving time and location are relatively common, the YAGO2 project extended the SPO triple format to the (subject, predicate, object, time, location) (SPOTL) format to model temporal and spatial information about relationships explicitly, without transforming them to binary relations <ref type="bibr" target="#b26">[27]</ref>. Furthermore, there has also been work on extracting higher-arity relations directly from natural language <ref type="bibr" target="#b137">[135]</ref>.</p><p>A related issue is that the truth-value of a fact can change over time. For example, Google's current CEO is Larry Page, but from 2001 to 2011 it was Eric Schmidt. Both facts are correct, but only during the specified time interval. For this reason, Freebase allows some facts to be annotated with beginning and end dates, using CVT constructs, which represent n-ary relations via auxiliary nodes. In the future, it is planned to extend the KV system to model such temporal facts. However, this is nontrivial, since it is not always easy to infer the duration of a fact from text, since it is not necessarily related to the timestamp of the corresponding source (cf., <ref type="bibr" target="#b138">[136]</ref>).</p><p>As an alternative to the usage of auxiliary nodes, a set of nth-arity relations can be represented by a single ?n ? 1?th-order tensor. RESCAL can easily be generalized to higher arity relations and can be solved by higher order tensor factorization or by neural network models with the corresponding number of entity representations as inputs <ref type="bibr" target="#b136">[134]</ref>.</p><p>Higher Arity Relations: In knowledge graphs, higher arity relations are typically expressed via multiple binary</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Hard Constraints: Types, Functional Constraints, and Others</head><p>Imposing hard constraints on the allowed triples in knowledge graphs can be useful. Powerful ontology languages such as the web ontology language (OWL) <ref type="bibr" target="#b139">[137]</ref> have been developed, in which complex constraints can be formulated. However, reasoning with ontologies is computationally demanding, and hard constraints are often violated in real-world data <ref type="bibr" target="#b140">[138]</ref>, <ref type="bibr" target="#b141">[139]</ref>. Fortunately, machine learning methods can be robust in the face of contradictory evidence. the current model. Similarly, it has been shown that the relation-specific weights W k in the RESCAL model can be calculated efficiently for new relation types given already derived latent representations of entities <ref type="bibr" target="#b142">[140]</ref>.</p><p>Deterministic Dependencies: Triples in relations such as subClassOf and isLocatedIn follow clear deterministic dependencies such as transitivity. For example, if Leonard Nimoy was born in Boston, we can conclude that he was born in Massachusetts, that he was born in the United States, that he was born in North America, etc. One way to consider such ontological constraints is to precompute all true triples that can be derived from the constraints and to add them to the knowledge graph prior to learning. The precomputation of triples according to ontological constraints is also called materialization. However, on large knowledge graphs, full materialization can be computationally demanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Querying Probabilistic Knowledge Graphs</head><p>RESCAL and KV can be viewed as probabilistic databases (see, e.g., <ref type="bibr" target="#b143">[141]</ref> and <ref type="bibr" target="#b144">[142]</ref>). In the knowledge vault, only the probabilities of triples are queried. Some applications might require more complex queries such as: Who is born in Rome and likes someone who is a child of Albert Einstein. It is known that queries involving joins (existentially quantified variables) are expensive to calculate in probabilistic databases <ref type="bibr" target="#b143">[141]</ref>. In <ref type="bibr" target="#b142">[140]</ref>, it was shown how some queries involving joins can be efficiently handled within the RESCAL framework.</p><p>Type Constraints: Often relations only make sense when applied to entities of the right type. For example, the domain and the range of marriedTo is limited to entities which are persons. Modelling type constraints explicitly requires complex manual work. An alternative is to learn approximate type constraints by simply considering the observed types of subjects and objects in a relation. The standard RESCAL model has been extended by <ref type="bibr" target="#b70">[69]</ref> and <ref type="bibr" target="#b75">[74]</ref> to handle type constraints of relations efficiently. As a result, the rank required for a good RESCAL model can be greatly reduced. Furthermore, <ref type="bibr" target="#b86">[85]</ref> considered learning latent representations for the argument slots in a relation to learn the correct types from data.</p><p>Functional Constraints and Mutual Exclusiveness: Although the methods discussed in Sections IV and V can model long-range and global dependencies between triples, they do not explicitly enforce functional constraints that induce mutual exclusivity between possible values. For instance, a person is born in exactly one city, etc. If one of the these values is observed, then observable graph models can prevent other values from being asserted, but if all the values are unknown, the resulting mutual exclusion constraint can be hard to deal with computationally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Trustworthiness of Knowledge Graphs</head><p>Automatically constructed knowledge bases are only as good as the sources from which the facts are extracted. Prior studies in the field of data fusion have developed numerous approaches for modelling the correctness of information supplied by multiple sources in the presence of possible data conflicts (see <ref type="bibr" target="#b145">[143]</ref> and <ref type="bibr" target="#b146">[144]</ref> for recent surveys). However, the key assumption in data fusionVnamely, that the facts provided by the sources are indeed stated by themVis often violated when the information is extracted automatically. If a given source contains a mistake, it could be because the source actually contains a false fact, or because the fact has been extracted incorrectly. A recent study <ref type="bibr" target="#b147">[145]</ref> has formulated the problem of knowledge fusion, where the above assumption is no longer made, and the correctness of information extractors is modeled explicitly. A follow-up study by the authors <ref type="bibr" target="#b148">[146]</ref> developed several approaches for solving the knowledge fusion problem, and applied them to estimate the trustworthiness of facts in the knowledge vault (cf., Section IX).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XI. CONCLUDING REMARKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Generalizing to New Entities and Relations</head><p>In addition to missing facts, there are many entities that are mentioned on the Web but are currently missing in knowledge graphs like Freebase and YAGO. If new entities or predicates are added to a KG, one might want to avoid retraining the model due to runtime considerations. Given the current model and a set of newly observed relationships, latent representations of new entities can be calculated approximately in both tensor factorization models and in neural networks, by finding representations that explain the newly observed relationships relative to Knowledge graphs (KGs) have found important applications in question answering, structured search, exploratory search, and digital assistants. We provided a review of state-of-the-art statistical relational learning (SRL) methods applied to very large knowledge graphs. We also demonstrated how statistical relational learning can be used in conjunction with machine reading and information extraction methods to automatically build such knowledge repositories. As a result, we showed how to create a truly massive, machine-interpretable ''semantic memory'' of facts, which is already empowering numerous practical applications. However, although these KGs are impressive in their size, they still fall short of representing many kinds of knowledge that humans possess. Notably missing are representations of ''common sense'' facts (such as the fact that water is wet, and wet things can be slippery), as well as ''procedural'' or how-to knowledge (such as how to drive a car or how to send an email). Representing, learning, and reasoning with these kinds of knowledge remains the next frontier for AI and machine learning. h corresponding entries from the u and v matrices. For example</p><formula xml:id="formula_33">u 1 " v 1 v 2 ? ?? u 1 &gt; 1 0 v 1 u 2 u 2 0 0 v 2 ;</formula><p>. . . ; u 1</p><formula xml:id="formula_34">&gt; 0 0 v 1 APPENDIX u 2 0 1 v 2 # :<label>(32)</label></formula><p>A. RESCAL is a Special Case of NTN Here we show how the RESCAL model of Section IV-A is a special case of the neural tensor model (NTN) of Section IV-E. To see this, note that RESCAL has the form In general, define ij as a matrix of all 0s except for entry ?i; j? which is 1. Then, if we define B k ? ?? 1;1 ; . . . ; H e ;H e ?, we have</p><formula xml:id="formula_35">h b &gt; 1 &gt; H b ijk ? e i B k e j ; . . . ; e i B k e j ? ? ? e j e i : f RESCAL ijk ? e &gt; &gt; i W k e j ? w k ?e j e i ?:<label>(31)</label></formula><p>Finally, if we define A k as the empty matrix (so h a Next, note that ijk is undefined), and g?u? ? u as the identity function, then the NTN equation</p><formula xml:id="formula_36">v u ? vec?uv &gt; ? ? ?u &gt; B 1 v; . . . ; u &gt; B n v? f NTN ijk ? w &gt; a h i k g h ijk ; h b ijk</formula><p>where n ? jujjvj, and B k is a matrix of all 0 s except for a single 1 element in the kth position, which ''plucks out'' the matches (31).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample knowledge graph. Nodes represent entities, edge labels represent types of relations, and edges represent existing relationships.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Tensor representation of binary relational data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>N</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>i</head><label></label><figDesc>W k e j and f piq ? e &gt; p W q e i both use the same latent representation e i of the ith entity. Since all parameters are learned jointly, these shared Vol. 104, No. 1, January 2016 | Proceedings of the IEEE 17</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. RESCAL as a tensor factorization of the adjacency tensor Y.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure</head><label></label><figDesc>Figure adapted from [147].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Visualization of RESCAL and the ER-MLP model as neural networks. Here, H e ? H r ? 3 and H a ? 3. Note that the inputs are latent features. The symbol g denotes the application of the function g???. (a) RESCAL. (b) ER-MLP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. (a) A small KG. There are four entities (circles): three adults (a 1 , a 2 , and a 3 ) and one child c. There are two types of edges: adults may or may not be married to each other, as indicated by the red dashed edges, and the adults may or may not be parents of the child, as indicated by the blue dotted edges. (b) We add binary random variables (represented by diamonds) to each KG edge. (c) We drop the entity nodes, and add edges between the random variables that belong to the same clique potential, resulting in a standard MRF.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Architecture of the knowledge vault.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="false"><head>Table 1 Knowledge Base Construction Projects 2</head><label>1</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 Size of Some Schema-Based Knowledge Bases</head><label>2</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Vol . 104, No. 1, January 2016 | Proceedings of the IEEE 15 Nickel et al.: A Review of Relational Machine Learning for Knowledge Graphs</head><label>Vol</label><figDesc></figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" validated="false"><head>Table 3 Summary of the Notation</head><label>3</label><figDesc></figDesc><table>! 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" validated="false"><head>Table 4 Semantic Embeddings of KV-MLP on Freebase</head><label>4</label><figDesc></figDesc><table>where A k ? ?A 

s 

o 

s 

k ; ?A 

k ?. In (15) the matrices A 

k , A 

o 
k 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" validated="false"><head>Table 5 Summary</head><label>5</label><figDesc>of the Latent Feature Models. h a , h b , and h c Are Hidden Layers of the Neural Network; See Text for Details Vol. 104, No. 1, January 2016 | Proceedings of the IEEE 21</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" validated="false"><head>Table 6 Examples of Paths Learned by PRA on Freebase to Predict Which</head><label>6</label><figDesc></figDesc><table>College a Person Attended 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" validated="false"><head>F 1 : ?x; parentOf ; z?^?y; parentOf ; z?)?x; marriedTo; y?</head><label>1</label><figDesc></figDesc><table>F 2 : ?x; marriedTo; y? ) :?y; parentOf ; x?: 

L 

i?1 , we create an edge 
between nodes in the dependency graph if the 
corresponding facts occur in at least one grounded 
formula. A grounding of a formula F i is given by the 
(type consistent) assignment of entities to the variables in 
F i . Furthermore, we define ?y c j? such that 

P?YjQ? ? 
1 
Z 

Y 

exp? c x c ? 
(30) 

c 

where x c denotes the number of true groundings of F c in 
Y, and c denotes the weight for formula F c . If c &gt; 0, we 
prefer worlds where formula F c is satisfied; if c G 0, we 
prefer worlds where formula F c is violated. If c ? 0, then 
formula F c is ignored. 
</table></figure>

			<note place="foot" n="1"> For detailed statistics, see http://www.mpi-inf.mpg.de/departments/ databases-and-information-systems/research/yago-naga/yago/statistics/. 2 http://thenoisychannel.com/2011/11/15/cikm-2011-industry-eventjohn-giannandrea-on-freebase-a-rosetta-stone-for-entities</note>

			<note place="foot" n="20"> Proceedings of the IEEE | Vol. 104, No. 1, January 2016</note>

			<note place="foot" n="24"> Proceedings of the IEEE | Vol. 104, No. 1, January 2016 Nickel et al.: A Review of Relational Machine Learning for Knowledge Graphs</note>

			<note place="foot" n="12"> Technically, since we are conditioning on some observed features x, this is a conditional random field (CRF), but we will ignore this distinction. Vol. 104, No. 1, January 2016 | Proceedings of the IEEE 25</note>

			<note place="foot" n="14"> Source: http://www.legendsofhockey.net/LegendsOfHockey/jsp/ SearchPlayer.jsp?player=11377. 15 Source: http://host.madison.com/sports/high-school/hockey/ numbers-dwindling-for-once-mighty-madison-high-school-hockeyprograms/article_95843e00-ec34-11df-9da9-001cc4c002e0.html. 16 Triples with the calibrated probability of correctness above 90%.</note>

			<note place="foot">Vol. 104, No. 1, January 2016 | Proceedings of the IEEE 29</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ABOUT THE AUTHORS</head><p>Maximilian Nickel received the Ph.D. degree (summa cum laude) from the Ludwig Maximilian</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Introduction to Statistical Relational Learning</title>
		<editor>L. Getoor and B. Taskar</editor>
		<imprint>
			<date type="published" when="2007" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambride, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Relational Data Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dzeroski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lavra?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Logical and Relational Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>De Raedt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Yago: A core of semantic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Int. Conf. World Wide Web</title>
		<meeting>16th Int. Conf. World Wide Web</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DBpedia: A nucleus for a web of open data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>SpringerVerlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">4825</biblScope>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Toward an architecture for never-ending language learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Conf</title>
		<meeting>24th Conf</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1306" to="1313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Freebase: A collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGMOD Int. Conf. Manage. Data</title>
		<meeting>ACM SIGMOD Int. Conf. Manage. Data</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Introducing the knowledge graph: Things, not strings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<ptr target="http://googleblog.blogspot.com/2012/05/introducing-knowledge-graph-things-not.html" />
		<imprint>
			<date type="published" when="2012-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From information to knowledge: Harvesting entities and relationships from web sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Theobald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 29th ACM SIGMOD-SIGACT-SIGART Symp</title>
		<meeting>29th ACM SIGMOD-SIGACT-SIGART Symp</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="65" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">AKBC-WEKEX 2012: The knowledge extraction workshop at NAACL-HLT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<ptr target="https://akbcwekex2012.wordpress.com/" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What is a knowledge representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shrobe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Mag</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="33" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Sowa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Encyclopedia Cogn. Sci</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A framework for representing knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; Mit-Ai</forename><surname>Lab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">306</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">The semantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berners-Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hendler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lassila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Linked dataVDesign issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berners-Lee</surname></persName>
		</author>
		<ptr target="http://www.w3.org/DesignIssues/LinkedData.html" />
		<imprint>
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Linked data-the story so far</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berners-Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int.J.Semantic Web Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Resource description framework (RDF): Concepts and abstract syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Carroll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">RDF 1.1 Concepts and abstract syntax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lanthaler</surname></persName>
		</author>
		<ptr target="http://www.w3.org/TR/2014/REC-rdf11-concepts-20140225/" />
		<imprint>
			<date type="published" when="2014-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Knowledge Representation and Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Levesque</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Knowledge Representation: Logical, Philosophical and Computational Foundations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Sowa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<pubPlace>Pacific Grove, CA, USA: Brooks/Cole</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mining heterogeneous information networks: Principles and methodologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures Data Mining Knowl. Disc</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="159" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Knowledge base completion via search-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>West</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd Int. Conf. World Wide Web</title>
		<meeting>23rd Int. Conf. World Wide Web</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="515" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">CYC: A large-scale investment in knowledge infrastructure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Lenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="33" to="38" />
			<date type="published" when="1995-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">WordNet: A lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Unified Medical Language System (UMLS): Integrating biomedical terminology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="267" to="270" />
			<date type="published" when="2004-01" />
		</imprint>
	</monogr>
	<note>Database issue</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Wikidata: A free collaborative knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vrande?icvrande?icnd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kr?tzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="28" to="61" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Knowledge vault: A webscale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</title>
		<meeting>20th ACM SIGKDD Int. Conf. Knowl. Disc. Data Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">PATTY: A taxonomy of relational patterns with semantic types</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint Conf. Empirical Meth. Natural Language Process. Computat. Natural Language Learning</title>
		<meeting>Joint Conf. Empirical Meth. Natural Language ess. Computat. Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1135" to="1145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scalable knowledge harvesting with high precision and high recall</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM Int. Conf. Web Search Data Mining</title>
		<meeting>4th ACM Int. Conf. Web Search Data Mining</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="227" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Elementary: Large-scale knowledge-base construction via machine learning and statistical inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>R</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Semantic Web Inf. Syst. (IJSWIS)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="42" to="73" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empir. Meth. Natural Language Process</title>
		<meeting>Conf. Empir. Meth. Natural Language ess<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Open language learning for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint Conf. Empirical Meth. Natural Language Process. Computat. Natural Language Learning</title>
		<meeting>Joint Conf. Empirical Meth. Natural Language ess. Computat. Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="523" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Prismatic: Inducing knowledge from a large scale lexicalized relation resource</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalyanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL HLT 1st</title>
		<meeting>NAACL HLT 1st</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Int. Workshop Formalisms Method. Learning Reading</title>
		<imprint>
			<biblScope unit="page" from="122" to="127" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The singularity is not near: Slowing growth of Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Convertino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pirolli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM 5th Int. Symp. Wikis Open Collab</title>
		<meeting>ACM 5th Int. Symp. Wikis Open Collab</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Inside YAGO2s: A transparent information extraction architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kuzey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Int. Conf. World Wide Web, Republic and Canton of</title>
		<meeting>22nd Int. Conf. World Wide Web, Republic and Canton of<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="325" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Open information extraction: The second generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mausam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Int. Joint Conf</title>
		<meeting>22nd Int. Joint Conf<address><addrLine>Barcelona, Catalonia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On the thresholds of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Lenat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Feigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="250" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Understand your world with Bing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Qian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-03" />
		</imprint>
	</monogr>
	<note>Bing search blog</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Building Watson: An overview of the DeepQA project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ferrucci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Mag</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Bio2RDF: Towards a mashup to build bioinformatics knowledge systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Belleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Nolin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tourigny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rigault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morissette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inf</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="706" to="716" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Life sciences on the semantic web: The neurocommons and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ruttenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Rees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samwald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinf</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="193" to="204" />
			<date type="published" when="2009-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Expanding the pathway and interaction knowledge in linked life data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Momtchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peychev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Primov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Georgiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Semantic Web Challenge</title>
		<meeting>Int. Semantic Web Challenge</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Philosophers are mortal: Inferring the truth of unseen facts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th Conf. Comput. Natural Language Learn</title>
		<meeting>17th Conf. Comput. Natural Language Learn<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Link prediction in relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<editor>Thrun, L. Saul, and B. Sch?lkopf</editor>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2004" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Link mining: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Diehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGKDD Explor. Newslett</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="12" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Automatic linkage of vital records computers can be used to extract &apos;&apos;follow-up&apos;&apos; statistics of families from files of routine records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Axford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">3381</biblScope>
			<biblScope unit="page" from="954" to="959" />
			<date type="published" when="1959-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning object identification rules for information integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tejada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Knoblock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Minton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="607" to="633" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A survey of approaches to automatic schema matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="334" to="350" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Joint deduplication of multiple record types in relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Culotta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th ACM Int. Conf. Inf. Knowl. Manage</title>
		<meeting>14th ACM Int. Conf. Inf. Knowl. Manage</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="257" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Entity resolution with Markov logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 6th</title>
		<meeting>6th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Int</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conf</surname></persName>
		</author>
		<title level="m">Data Mining</title>
		<imprint>
			<date type="published" when="2006-12" />
			<biblScope unit="page" from="572" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Collective entity resolution in relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Joint entity resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Whang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Garcia-Molina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 28th Int. Conf. Data Eng</title>
		<meeting>IEEE 28th Int. Conf. Data Eng<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="294" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Community detection in graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rep</title>
		<imprint>
			<biblScope unit="volume">486</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="75" to="174" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The structure of scientific collaboration networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Nat. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="404" to="409" />
			<date type="published" when="2001-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The link-prediction problem for social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liben-Nowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1019" to="1031" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Linkage and autocorrelation cause feature selection bias in relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 19th Int. Conf. Mach. Learn</title>
		<meeting>19th Int. Conf. Mach. Learn<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="259" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Stochastic blockmodels: First steps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Laskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Netw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="137" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Building stochastic blockmodels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wasserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Faust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Special Issue on Blockmodels</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="137" to="161" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
	<note>Social Netw.</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Modeling homophily and stochastic equivalence in symmetric relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 20</title>
		<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="657" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Probabilities for SV machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Large Margin Classifiers</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="61" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Bayesian models of graphs, arrays and other exchangeable random structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Orbanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intell</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 28th Int. Conf. Mach. Learn</title>
		<meeting>28th Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="809" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Factorizing YAGO: Scalable machine learning for linked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st Int. Conf. World Wide Web</title>
		<meeting>21st Int. Conf. World Wide Web</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="271" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Tensor factorization for relational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-08" />
			<pubPlace>Munich, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Ludwig-Maximilians-Universit?t Mnchen</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Ph.D. dissertation</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Matrix factorization techniques for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="30" to="37" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Logistic tensor-factorization for multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Structured Learn.: Inferring Graphs Structured Unstructured Inputs (SLG 2013) Workshop</title>
		<meeting>Structured Learn.: Inferring Graphs Structured Unstructured Inputs (SLG 2013) Workshop</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Typed tensor decomposition of knowledge bases for relation extraction,&apos;&apos; in Proc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conf. Empir. Meth. Natural Lang. Process</title>
		<imprint>
			<date type="published" when="2014-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Statistical predicate invention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 24th Int. Conf. Mach. Learn</title>
		<meeting>24th Int. Conf. Mach. Learn<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="433" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Infinite hidden relational models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd Int. Conf. Uncertainty Artif. Intell</title>
		<meeting>22nd Int. Conf. Uncertainty Artif. Intell</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="544" to="551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Learning systems of concepts with an infinite relational model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st Nat. Conf. Artif. Intell</title>
		<meeting>21st Nat. Conf. Artif. Intell</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Modelling relational data using Bayesian clustered tensor factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1821" to="1828" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Large-scale factorization of typeconstrained multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krompaq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Data Sci</title>
		<meeting>Int. Conf. Data Sci</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Learning taxonomies from multi-relational data via hierarchical link-based clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Learn. Semant. Workshop</title>
		<meeting>Learn. Semant. Workshop<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Higher-order web link analysis using multilinear algebra</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Kenny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth IEEE Int. Conf. Data Mining</title>
		<meeting>Fifth IEEE Int. Conf. Data Mining<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="242" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Triplerank: Ranking semantic web data by tensor decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sizov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Staab</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Semant. Web</title>
		<imprint>
			<biblScope unit="page" from="213" to="228" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Predicting RDF triples in incomplete knowledge bases with tensor factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Drumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 27th Annu</title>
		<meeting>27th Annu<address><addrLine>Riva del Garda, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="326" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Pairwise interaction tensor factorization for personalized tag recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third ACM Int. Conf. Web Search Data Mining</title>
		<meeting>Third ACM Int. Conf. Web Search Data Mining</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Scaling factorization machines to relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 39th Int. Conf. Very Large Data Bases</title>
		<meeting>39th Int. Conf. Very Large Data Bases<address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="337" to="348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">A latent factor model for highly multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jenatton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Obozinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 25</title>
		<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3167" to="3175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Boolean tensor factorizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Miettinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 11th Int. Conf. Data Mining</title>
		<meeting>IEEE 11th Int. Conf. Data Mining</meeting>
		<imprint>
			<date type="published" when="2011-12" />
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Discovering facts with Boolean tensor tucker decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erdos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Miettinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd ACM Int. Conf. Inf. Knowl. Manage</title>
		<meeting>22nd ACM Int. Conf. Inf. Knowl. Manage<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1569" to="1572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Link prediction in multi-relational graphs using additive models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Semant. Technol. Recomm. Sys. Big Data ISWC</title>
		<editor>M. de Gemmis, T. D. Noia, P. Lops, T. Lukasiewicz, and G. Semeraro</editor>
		<meeting>Int. Workshop Semant. Technol. Recomm. Sys. Big Data ISWC</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">919</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Relation extraction with matrix factorization and universal schemas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Marlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Joint Human Language Technol. Conf./ Annu. Meet. North Amer. Chapter Assoc. Comput. Linguistics</title>
		<imprint>
			<date type="published" when="2013-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Materializing and querying learned knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bundschus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IRMLeS</title>
		<meeting>IRMLeS</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">A scalable approach for statistical learning in semantic graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semant. Web J</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Tensor product variable binding and the representation of symbolic structures in connectionist systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smolensky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="216" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Processing capacity defined by relational complexity: Implications for comparative, developmental, cognitive psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Halford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav. Brain Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">06</biblScope>
			<biblScope unit="page" from="803" to="831" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">A common framework for distributed representation schemes for compositional structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Plate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connect. Syst. Knowl. Represent. Deduct</title>
		<imprint>
			<biblScope unit="page" from="15" to="34" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop ICLR</title>
		<meeting>Workshop ICLR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26</title>
		<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Learning structured embeddings of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th AAAI Conf</title>
		<meeting>25th AAAI Conf<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 26</title>
		<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-T</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page">6575</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Latent space approaches to social network analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Handcock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Stat. Assoc</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">460</biblScope>
			<biblScope unit="page" from="1090" to="1098" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Link prediction in complex networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>L</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A, Stat. Mechan. Appl</title>
		<imprint>
			<biblScope unit="volume">390</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1150" to="1170" />
			<date type="published" when="2011-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Friends and neighbors on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Netw</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="230" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Emergence of scaling in random networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-L</forename><surname>Barabsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="issue">5439</biblScope>
			<biblScope unit="page" from="509" to="512" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">A new status index derived from sociometric analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="43" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Vertex similarity in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Leicht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Holme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">26120</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">The anatomy of a large-scale hypertextual web search engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Netw. ISDN Syst</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="117" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Link prediction based on local random walk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>L</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Europhys. Lett</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">58007</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Inverse entailment and progol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muggleton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Gen. Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="245" to="286" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Inductive logic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Gen. Computi</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="295" to="318" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Learning logical definitions from relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="239" to="266" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">AMIE: Association rule mining under incomplete evidence in ontological knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Galrraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Teflioudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 22nd</title>
		<meeting>22nd</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">World Wide Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Int</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="413" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Fast rule mining in ontological knowledge bases with AMIE+</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Galrraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Teflioudi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Vldb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Inductive logic programming in databases: From datalog to dl+log</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Lisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPLP</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Reasoning by analogy in description logics through instance-based learning,&apos;&apos; in Proc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fanizzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Esposito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semant. Web Appl. Perspect</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">DL-learner: Learning concepts in description logics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="2639" to="2642" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Mining the semantic webVStatistical learning for next generation knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>L?sch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Amato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fanizzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="662" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Graph kernels for rdf data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>L?sch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bloehdorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Int. Conf. Semant</title>
		<meeting>9th Int. Conf. Semant</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="134" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Learning to propagate knowledge in web ontologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fanizzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 10th Int. Workshop Uncertain</title>
		<meeting>10th Int. Workshop Uncertain</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title level="a" type="main">Relational retrieval using a combination of pathconstrained random walks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="67" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title level="a" type="main">Random walk inference and learning in a large scale knowledge base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empir. Meth. Nat. Lang. Process</title>
		<meeting>Conf. Empir. Meth. Nat. Lang. ess</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="529" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Workshop Continuous Vector Space Models Compositionality</title>
		<meeting>3rd Workshop Continuous Vector Space Models Compositionality</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Reducing the rank in relational factorization models by including observable patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27</title>
		<meeting><address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1179" to="1187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: A multifaceted collaborative filtering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</title>
		<meeting>14th ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<analytic>
		<title level="a" type="main">Factorization machines with libFM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rendle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intell. Syst. Technol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">57</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. COMPSTAT</title>
		<meeting>COMPSTAT</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<title level="m">Machine Learning: A Probabilistic Perspective</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">The relationship between precision-recall and ROC curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd Int. Conf. Mach. Learn</title>
		<meeting>23rd Int. Conf. Mach. Learn</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">Probabilistic Graphical Models: Principles and Techniques</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Markov logic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="136" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Towards high-throughput Gibbs sampling at scale: A study across storage managers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>R</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACM SIGMOD Int. Conf. Manage. Data</title>
		<meeting>ACM SIGMOD Int. Conf. Manage. Data</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="397" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">Sound and efficient inference with probabilistic and deterministic dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<monogr>
		<title level="m" type="main">Fixing max-product: Convergent message passing algorithms for MAP LP-relaxations,&apos;&apos; in NIPS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b132">
	<monogr>
		<title level="m" type="main">Hinge-loss Markov random fields and probabilistic soft logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Broecheler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.04406</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.LG</note>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">A short introduction to probabilistic soft logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kimmig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Broecheler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS Workshop Probab</title>
		<meeting>NIPS Workshop Probab</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<title level="m" type="main">Using semantics and statistics to turn data into knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>AI Mag.</note>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">Relational dependency networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="637" to="652" />
			<date type="published" when="2007-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">Probabilistic latent-factor database models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krompaq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 1st Workshop Linked Data Knowl. Discovery European Conf. Mach. Learn. Principles Practice Knowl. Discovery Databases</title>
		<meeting>1st Workshop Linked Data Knowl. Discovery European Conf. Mach. Learn. Principles Practice Knowl. Discovery Databases</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Improvement of n-ary relation extraction by adding lexical semantics to distant-supervision rule learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 7th Int. Conf. Agents Artif. Intell</title>
		<meeting>7th Int. Conf. Agents Artif. Intell<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="317" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">Tackling representation, annotation and classification challenges for temporal knowledge base population</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tamang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2013-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">OWL web ontology language overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Harmelen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">W3C Recommend</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">Weaving the pedantic web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Polleres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3rd Int. Workshop Linked Data Web (LDOW2010)/19th Int. World Wide Web Conf</title>
		<meeting>3rd Int. Workshop Linked Data Web (LDOW2010)/19th Int. World Wide Web Conf<address><addrLine>Raleigh, NC, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">When owl: SameAs isn&apos;t the same: An analysis of identity in linked data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Halpin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mccusker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Semant. Web</title>
		<imprint>
			<biblScope unit="page" from="305" to="320" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Querying factorized probabilistic triple databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krompaq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Semant. Web</title>
		<imprint>
			<biblScope unit="page" from="114" to="129" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<monogr>
		<title level="m" type="main">Probabilistic Databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Olteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Morgan and Claypool</publisher>
			<pubPlace>San Raphael, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">BayesStore: Managing large, uncertain data repositories with probabilistic graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Michelakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garofalakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="340" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Data fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bleiholder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Naumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2009-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">Truth finding on the deep web: Is the problem solved?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">&apos;&apos; Proc. VLDB Endow</title>
		<imprint>
			<date type="published" when="2012-12" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="97" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">From data fusion to knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="881" to="892" />
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Knowledge-based trust: Estimating the trustworthiness of web sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. VLDB Endow</title>
		<meeting>VLDB Endow</meeting>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="938" to="949" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<analytic>
		<title level="a" type="main">Machine Learning and Knowledge Discovery in Databases, ser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">8190</biblScope>
			<biblScope unit="page" from="617" to="621" />
			<date type="published" when="2013" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
	<note>Tensor factorization for multirelational learning</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
