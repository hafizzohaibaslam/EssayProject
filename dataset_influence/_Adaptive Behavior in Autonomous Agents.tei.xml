<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-17T00:10+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adaptive Behavior in Autonomous Agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="1998-12">December 1998</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ziemke</surname></persName>
							<email>tom@ida.his.se</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">University of Sk?vde</orgName>
								<address>
									<postBox>Box 408</postBox>
									<postCode>S-54128</postCode>
									<settlement>Sk?vde</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Adaptive Behavior in Autonomous Agents</title>
					</analytic>
					<monogr>
						<title level="j" type="main">special issue on Autonomous Agents</title>
						<imprint>
							<biblScope unit="volume">7</biblScope>
							<biblScope unit="issue">6</biblScope>
							<date type="published" when="1998-12">December 1998</date>
						</imprint>
					</monogr>
					<note type="submission">(originally written September 96, partly revised May 97 and July 98)</note>
					<note>NB: This is a pre-print; the printed version will differ slightly from this one. 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>adaptive behavior</term>
					<term>autonomous agents</term>
					<term>behavior-oriented AI</term>
				</keywords>
			</textClass>
			<abstract>
				<p>This paper gives an overview of the bottom-up approach to artificial intelligence (AI), commonly referred to as behavior-oriented AI. The behavior-oriented approach, with its focus on the interaction between autonomous agents and their environments, is introduced by contrasting it with the traditional approach of knowledge-based AI. Different notions of autonomy are discussed, and key problems of generating adaptive and complex behavior are identified. A number of techniques for the generation of behavior are introduced and evaluated regarding their potential for realizing different aspects of autonomy as well as adaptivity and complexity of behavior. It is concluded that in order to realize truly autonomous and intelligent agents, the behavior-oriented approach will have to focus even more on lifelike qualities in both agents and environments.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper gives an overview of the bottom-up approach to the study of artificial intelligence (AI), commonly referred to as behavior-oriented AI or autonomous agents research.</p><p>Traditionally, AI has been based on the view that intelligent behavior is the result of abstract processes at the 'knowledge level' <ref type="bibr" target="#b69">(Newell, 1982)</ref>, a level that is independent of its actual implementation in biological or physical mechanisms. In particular the Physical Symbol System Hypothesis <ref type="bibr" target="#b70">(Newell &amp; Simon, 1976)</ref> posits that the essence of intelligent behavior is rule-based manipulation of symbolic representations. Hence, traditional AI has been predominantly concerned with the synthesis of abstract capacities in representational and formal domains, such as logical problem-solving or chess-playing, rather than with robotic/sensorimotor capacities that allow interaction with the represented world. The relevance of this type of AI for virtual environments has been somewhat limited, since virtual reality (VR) is typically concerned with the modeling of the concrete/physical rather than the abstract/mental. In such domains traditional AI has had relatively little to offer since it was concerned with disembodied reasoning, rather than perception and action.</p><p>Since the mid 1980s, however, traditional AI and the underlying cognitivist paradigm in cognitive science have been questioned from a number of perspectives: In the robotics field traditional AI systems were shown to have serious problem in dealing with complex environments, let alone the real world, and the alternative approach of behavior-based robotics, focusing on perception and action, was introduced <ref type="bibr" target="#b15">(Brooks, 1986)</ref>. At the same time the re-emergence of connectionism and artificial neural nets 2 (ANNs) <ref type="bibr">(Rumelhart &amp; McClelland, 1986)</ref> began to pose a serious threat to symbolic theories of intelligence. Furthermore, researchers interested in the situated nature of cognition <ref type="bibr" target="#b100">(Suchman, 1987;</ref><ref type="bibr" target="#b2">Agre &amp; Chapman, 1987)</ref> and its bodily/biological basis <ref type="bibr" target="#b56">(Maturana &amp; Varela, 1980;</ref><ref type="bibr" target="#b57">Maturana &amp; Varela, 1987;</ref><ref type="bibr" target="#b41">Johnson, 1989)</ref> began to argue that intelligent behavior and cognition are much more about effective interaction between agent/organism and environment, rather than an agent's capacity to handle abstract world models internally. From the combination of these influences the field of behavior-oriented AI has emerged, which unlike its traditional counterpart, is predominantly concerned with the study of so-called autonomous agents, situated in and interacting with an environment. Section 2 elaborates in further detail the fundamental differences between traditional and behavior-oriented AI. Furthermore the terminology of the latter field is introduced, and related research areas are identified.</p><p>Section 3 outlines some key issues and problems of behavior-oriented AI. Firstly, different notions of autonomy are discussed, and three relevant dimensions/aspects of autonomy are identified, which will be used throughout the paper to evaluate different approaches and techniques. Secondly, adaptivity and complexity of behavior are discussed, and three key problems for the realization of adaptive control composition in autonomous agents are identified, which will be used to evaluate different approaches and techniques presented in the following sections. Thirdly, different types of autonomous agents are distinguished and their relevance and major differences are identified. Here, it will be argued that robotic agents are the most promising route from an AI perspective. Hence, the rest of this paper will focus on this type of agent.</p><p>3 Section 4 reviews relevant approaches and techniques for the generation of behavior in autonomous agents, including algorithmic and dynamic approaches, <ref type="bibr" target="#b15">Brooks' (1986)</ref> subsumption architecture and other modular architectures, self-learning in different types of ANNs, as well as evolutionary methods. These techniques are discussed in general, illustrated with examples of their practical use, and evaluated regarding their suitability for the realization of autonomous, adaptive and complex behavior.</p><p>Section 5 summarizes and integrates the discussion of key issues and open problems in behavior-oriented AI given in section 3 with the overview of available techniques given in section 4. This results in the discussion of a number of key issues/suggestions for future behavior-oriented AI research, including the possible roles different types of autonomous agents can play in virtual environments, as well as the opportunities virtual environments might have to offer behavior-oriented AI.</p><p>Section 6 briefly summarizes the work presented here, and draws a number of conclusions concerning the future development of AI in general, and its relation to virtual environments in particular.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Behavior-oriented AI: Concepts and Terminology</head><p>The main intention of this section is to introduce behavior-oriented AI by contrasting it with traditional, knowledge-based AI (section 2.1). Furthermore the terminology of behavior-oriented AI, as far as relevant, is introduced in section 2.2, and a number of related research areas, united by a common interest in autonomous agents, are identified in section 2.3. the problem of how to 'extract' a human's (expert-) knowledge and represent it in a form appropriate for a machine to reason with. The knowledge-based approach is sometimes also referred to as 'top-down AI' (e.g. <ref type="bibr" target="#b51">Maes, 1993)</ref>, due to the fact that it typically is concerned with the modeling of high-level cognitive capacities such as planning, problem solving, or game playing, but for a long time ignored lower-level mechanisms and competencies as they are required for interaction with physical environments, such as perception and motor skills. Knowledge-based AI succeeded in building systems with, in many cases, impressive performance/expertise within narrow domains such as medical diagnosis, theorem proving or chess.</p><p>This methodology does, however, result in systems which lack grounding, i.e. do not have any direct causal connection to the 'outside world' they represent, but only an indirect connection via the interpretation of the system's user/designer <ref type="bibr" target="#b93">(Searle, 1980;</ref><ref type="bibr" target="#b35">Harnad, 1990)</ref>. Furthermore most of these systems suffer from the problem of "brittleness" <ref type="bibr" target="#b39">(Holland, 1986)</ref>, i.e. the tendency to fail utterly when confronted with problems even slightly outside their domain of expertise <ref type="bibr" target="#b111">(Wilson, 1991)</ref>.</p><p>Behavior-oriented AI, on the other hand, is inspired by the notion of intelligence/cognition as a biological characteristic <ref type="bibr" target="#b97">(Steels, 1994)</ref>. Hence, the view that 'intelligence' should be considered an agent's capacity to interact with its environment, rather than to represent/model it internally. Most research in the field is therefore concerned with the study of systems that to some degree exhibit life-like qualities, in particular so-called autonomous agents, which Beer (1995) characterizes as follows:</p><p>By autonomous agent, I mean any embodied system designed to satisfy internal or external goals by its own actions while in continuous long-term 6 interaction with the environment in which it is situated. The class of autonomous agents is thus a fairly broad one, encompassing at the very least all animals and autonomous robots.</p><p>For the moment, the above broad notion can be considered a good approximation which, probably, the majority of researchers in behavior-oriented AI would agree to. Section 3 will give a more detailed discussion of different notions of autonomy, i.e. the question what exactly is to be understood as "its own actions" in the above definition, and different types of autonomous agents, i.e. the question what exactly is to be understood as "embodied" and "situated".</p><p>In analogy to living systems, in which adaptation is not restricted to self-learning at the level of the individual, behavior-oriented AI also studies intelligent behavior as a result of adaptation at the species level (evolution) as well as at the social (group) level <ref type="bibr" target="#b98">(Steels, 1995)</ref>. Approaches to the synthesis of self-learning and evolutionary adaptation in autonomous agents will be discussed in section 4.2. The aspect of 'social intelligence' is not discussed in further detail in this paper; for an overview see <ref type="bibr" target="#b23">Dautenhahn (1995)</ref>.</p><p>The behavior-oriented approach to the study of intelligent behavior, also referred to as 'bottom-up AI <ref type="bibr">' (e.g Brooks, 1986;</ref><ref type="bibr" target="#b51">Maes, 1993)</ref>, is to start off with simple agents with multiple integrated competencies, rather than expertise in narrow domains. Typically these skills are very basic 'survival' skills of the sensory-motor coordination type (such as obstacle avoidance), based on simple underlying mechanisms on top of which more complex behavior can be developed in interaction with the environment. This is supported by the insight that behavioral complexity does not necessarily require <ref type="bibr">7</ref> complexity of the underlying behavior-generating mechanisms <ref type="bibr" target="#b14">(Braitenberg, 1984;</ref><ref type="bibr" target="#b17">Brooks, 1991)</ref>. Furthermore, the approach is to a large extent supported by <ref type="bibr" target="#b79">Piaget's (1952)</ref> theory of sensorimotor intelligence and intellectual development <ref type="bibr" target="#b88">(Rutkowska, 1996)</ref>, as well as more recent work in developmental psychology (e.g. <ref type="bibr" target="#b19">Bushnell &amp; Boudreau, 1993;</ref><ref type="bibr" target="#b87">Rutkowska, 1994)</ref>, which emphasize the relevance of sensorimotor development for the acquisition of more abstract cognitive capacities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Some terminology</head><p>As a result of the diversity/interdisciplinarity of behavior-oriented AI (cf. section 2.3), much of its basic terminology is still ill-defined. The term 'agent', for example, is unfortunately used for all sorts of systems, ranging from the most complex (humans, animals) to the very simple (programs, subroutines, etc.) (cf. <ref type="bibr" target="#b31">Franklin &amp; Graesser, 1996;</ref><ref type="bibr" target="#b112">Woolridge &amp; Jennings, 1995)</ref>. In line with Beer's above definition, in this paper an agent is to be understood as a system that can be viewed as situated in an environment, and interacting with it by means of perception and action.</p><p>The use of the term 'behavior' is twofold: On the one hand it can refer to a system's 'overall (or global) behavior', on the other hand to a particular 'behavior' such as obstacle avoidance (cf. <ref type="bibr" target="#b17">Brooks, 1991)</ref>. <ref type="bibr" target="#b97">Steels (1994)</ref> defines the term as follows:</p><p>A behavior is a regularity in the interaction dynamics between an agent and its environment, for example, maintaining a bounded distance from the wall бн Behaviors belong .. to the descriptive vocabulary of the observer.</p><p>Accordingly, 'behavior systems' are defined as follows <ref type="bibr" target="#b97">(Steels, 1994)</ref>: 8 A behavior system is the set of all mechanisms that play a role in establishing a particular behavior.</p><p>Another central concept in behavior-oriented AI is that of emergence of behavior and functionality. Emergence is of central importance to the approach since it offers a possible bridge between the necessity of complex and adaptive behavior at the global level (i.e. temporally extended and dynamically varying) and the mechanisms of distributed multiple competencies and situation-based action. Steels (1994) defines emergence as follows:</p><p>A behavior is emergent if it can only be defined using descriptive categories which are not necessary to describe the behaviour of the constituent components. An emergent behaviour leads to emergent functionality if the behaviour contributes to the system's self-preservation and if the system can build further upon it.</p><p>An example is given by <ref type="bibr" target="#b67">Nehmzow (1994)</ref> who describes the emergence of a 'corridor following' behavior in a simple robot from three underlying particular behaviors: turning right when perceiving a wall on the left, turning left when perceiving a wall on the right, and moving straight forward otherwise.</p><p>Despite its central role in behavior-based AI the mechanisms of emergence are far from being fully understood yet. Hence, Maes (1993) points out:</p><p>We need a better understanding of the underlying principles of BehaviorBased AI. ... In particular, it is important to understand the mechanisms and limitations of emergent behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9</head><p>A detailed discussion of different notions of autonomy, embodiment and situatedness will be given in sections 3.1 and 3.3, since these are conceptual key issues rather than questions of terminology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Related research areas</head><p>The area of behavior-oriented AI is in its very nature interdisciplinary, bringing together researchers from such diverse areas as AI, cognitive science, psychology, ethology, philosophy, biology, control theory, etc., each of which has particular goals, interests and reasons for studying autonomous agents. Hence, there are a number of overlapping research areas sharing a common interest in autonomous agents as tools/objects of research.</p><p>In addition to 'behavior-oriented' (e.g. <ref type="bibr" target="#b97">Steels, 1994)</ref> and 'behavior-based' (e.g. <ref type="bibr" target="#b51">Maes, 1993</ref>) the autonomous agents approach, as mentioned above, is referred to 'bottom-up AI'. Moreover, behavior-oriented AI to a large extent overlaps with (a) the field of Adaptive Behavior (e.g. <ref type="bibr">Maes, Mataric, Meyer, Pollack &amp; Wilson, 1996)</ref>, which could be characterized as the study of the mechanisms of adaptive behavior in both natural and artificial agents, and (b) the Animat Approach, a term coined by <ref type="bibr" target="#b110">Wilson (1985</ref><ref type="bibr" target="#b111">Wilson ( , 1991</ref>, since it uses artificial animals ('animats') as tools for the study of intelligent behavior in natural ones. Furthermore these approaches, naturally, share an interest in life-like or living systems with the field of Artificial Life, which is typically defined as the study of computational models of biological phenomena and "life-as-it-could-be" <ref type="bibr" target="#b48">(Langton, 1989)</ref>. Moreover autonomous agents are increasingly being studied as a bottom-up approach by researchers in cognitive science, in particular those interested in Situated and/or Embodied Cognition (e.g. <ref type="bibr" target="#b109">Varela et al., 1991;</ref><ref type="bibr" target="#b37">Hendriks-Jansen, 1996;</ref><ref type="bibr" target="#b20">Clark, 1997;</ref><ref type="bibr" target="#b77">Pfeifer &amp; Scheier, 1998)</ref>, who emphasize the situated nature of activity and the bodily/sensorimotor basis of cognition and intelligent behavior. Finally, the above approaches are also referred to as "New AI" (e.g. Dorffner, 1997a) or "Nouvelle AI" (e.g. <ref type="bibr" target="#b17">Brooks, 1991;</ref><ref type="bibr" target="#b11">Boden, 1996</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Key Issues in Behavior-oriented AI</head><p>This section examines a number of conceptual key issues in behavior-oriented AI. A detailed discussion of different notions of autonomy is given in section 3.1, and three key dimensions/aspects of autonomy are identified. Section 3.2 outlines the problem of adaptive control composition, and identifies three key problems for its realization in artificial agents. These problems, along with the above aspects of autonomy, will be used throughout the rest of the paper to evaluate different approaches to the realization of behavior in artificial agents. Different types of autonomous agents, and their relevance for behavior-oriented AI, are discussed in section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Autonomy</head><p>First of all, it should be noted that there is a wide range of definitions and notions of 'autonomy' (e.g. <ref type="bibr" target="#b58">McFarland &amp; B?sser, 1993;</ref><ref type="bibr" target="#b98">Steels, 1995;</ref><ref type="bibr" target="#b11">Boden, 1996)</ref>. Roughly, however, the spectrum can be reduced to two notions, here referred to as operational and behavioral autonomy.</p><p>Both notions agree in the idea that automaticity is a necessary element of any kind of autonomy. Steels (1995) defines automaticity as follows, similar to Beer's above characterization of autonomous agents:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11</head><p>To be autonomous you must first be automatic. This means that you must be able to operate in an environment, sense this environment and impact it in ways that are beneficial to yourself and to the tasks that are crucial to your further existence.</p><p>Apart from this, an operational notion of autonomy requires the capacity to operate without human intervention, i.e. without being remotely controlled by a human or dependent on one to, for example, change batteries. This notion of autonomy is rather widespread, especially in the engineering-oriented robotics community, and does make sense where it is used to characterize systems as 'autonomous' which normally are controlled by humans, as in "autonomous vacuum cleaner" ( <ref type="bibr" target="#b105">Ulrich et al., 1997</ref>) or "autonomous land vehicle" <ref type="bibr" target="#b81">(Pomerleau, 1993)</ref>.</p><p>This operational notion of autonomy does, however, not capture all of what the term is usually associated with when applied to humans or animals (e.g <ref type="bibr" target="#b11">Boden, 1996</ref>). If you look up the term 'autonomy' in the Oxford English Dictionary, for example, you will find the following definition <ref type="bibr" target="#b94">(Sharkey &amp; Heemskerk, 1997</ref>):</p><p>Freedom of will; the Kantian doctrine of the self-determination of the will, apart from the object willed.</p><p>Obviously, this stronger notion of autonomy does not apply to today's operationally autonomous agents, whose behavior is typically to a high degree pre-programmed, rather than self-determined. It is unclear what exactly the basis of this self-determination is in natural agents, and one might be skeptical whether it ever could be synthesized in artificial ones. Hence, Bourgine and Varela (1992) point out ... the need to understand the class of processes that endows living creatures <ref type="bibr">12</ref> with their characteristic autonomy. Autonomy in this context refers to their basic and fundamental capacity to be, to assert their existence and to bring forth a world that is significant and pertinent without being pre-digested in advance.</p><p>Dissatisfied with the engineering-oriented, operational notion of autonomy, a number of researchers have started to aim for autonomy in the stronger sense, trying to find a notion more in agreement with the cognitive science use of the term, thus sometimes referred to as "true autonomy" <ref type="bibr" target="#b98">(Steels, 1995)</ref> or "real autonomy" <ref type="bibr">(Tani &amp; Asada, 1996)</ref>. <ref type="bibr">1995)</ref> points out that the term 'autonomy' is derived from the Greek words 'autos' (self) and 'nomos' (law or rule), and hence continues his above definition of autonomy/automaticity as follows:</p><formula xml:id="formula_0">Steels 1 (</formula><p>But autonomy goes beyond automaticity, because it also supposes that the basis of self-steering originates (at least partly) in the agent's own capacity to form and adapt its principles of behavior. <ref type="bibr" target="#b98">(Steels, 1995)</ref> A number of points concerning this stronger notion of autonomy, hereafter referred to as behavioral autonomy, should be noted here:</p><p>? Behavioral autonomy should be considered a continuum, not an all-or-nothing</p><p>property <ref type="bibr" target="#b11">(Boden, 1996;</ref><ref type="bibr" target="#b30">Franklin, 1995)</ref>. That means, there are different degrees of autonomy, i.e. degrees to which an agent is in control of its behavior.</p><p>? Agents with full behavioral autonomy do not exist in nature. This is due to the behavioral bias of physiology, innate instincts, reflexes, etc. which are 1 quoting personal communication with Tim Smithers 13 supplied to living creatures by evolution and typically not under (full) control of the individual.</p><p>? Agents without any behavioral autonomy on the other hand, i.e. agents whose behavior is completely innate (instinctive, reflexive) do exist in nature. They are, however, although autonomous in the operational sense, typically considered unintelligent (as individuals) and therefore of limited interest to AI and cognitive science.</p><p>Boden (1996) points out that there are different degrees and gradations of autonomy and identifies three dimensions according to which an agent's autonomy can be judged. We will in this paper use a similar list of three relevant aspects of autonomy (hereafter referred to A1, A2, A3), of which the first two are taken from <ref type="bibr" target="#b11">Boden (1996)</ref>, whereas the third is less demanding than Boden's 2 :</p><p>? A1 -the extent to which responses to external stimuli are purely reactive or mediated by inner mechanisms partly dependent on an agent's history of sensory input and/or internal state.</p><p>? A2 -the extent to which such inner control mechanisms have been selfgenerated or -organized rather than externally imposed.</p><p>? A3 -the extent to which inner control mechanisms can be selectively activated, i.e. the degree to which an agent can dynamically decide what to do 'right now'.</p><p>Aspects A1-3 are explained briefly in the following, but will be discussed further throughout the rest of the paper, and will be used to evaluate/assess the potential for different degrees and forms of autonomy in different approaches and techniques in behavior-oriented AI.</p><p>A1 can be explained with the distinction between purely reactive agents and agents making use of an internal state. A purely reactive agent's action at time t will depend on its (sensory) input at time t alone, i.e. its behavior at each time is the result of an inputoutput mapping. To be able to cope with its environment, such an agent does, of course, strongly depend on sufficient input to be available from the environment at any time.</p><p>The behavior of an agent that can make use of an internal state to encode, for example, a history of percepts and actions, is determined by a mapping from an input history to actions, which is inherently more powerful. Hence, the A1 aspect of autonomy supplied by internal state/memory is a certain freedom/independence of external memory/information supplied by or contained in the environment at a given point in time.</p><p>A2 is concerned with the distinction between engineering and self-organization, and follows directly from the notion of behavioral autonomy as including the capacity of a certain behavioral self-determination. Agents which are built/engineered/programmed to solve particular tasks, and have no means of adapting their behavior themselves, obviously lack the A2 aspect of autonomy. Agents capable of forming and/or adapting their own behavior, on the other hand, will have a certain degree of A2 autonomy depending on to what extent they are capable of self-organization and -adaptation.</p><p>Hence, autonomy in the A2 sense is (a) independence of constraints imposed by an 15 external designer/programmer, and (b) the freedom to override/adapt built-in or innate constraints and behavior.</p><p>A3 is concerned with flexibility/adaptivity of behavior, and characterizes the extent to which inner control mechanisms can be selectively used and modified. This would require an agent not only to develop itself the principles of its behavior, but also the capacity to dynamically decide which of them to use to guide its behavior in a particular situation. Hence, A3-type autonomy provides the freedom of flexibly organized behavior and independence of the need to match all possible problems/situations with a static behavioral repertoire, i.e. it allows a divide-and-conquer approach to the acquisition and control of complex behavior.</p><p>It should be noted that A1-3 are not supposed to capture all aspects of life-like autonomy, but only a number of aspects relevant in the context of behavior-oriented AI.</p><p>Hence, the rest of this paper will leave the question of 'freedom of will' aside, and instead use above aspects/dimensions A1, A2 and A3 to evaluate which degrees/forms of autonomy have been realized so far in behavior-oriented AI, and how, possibly, higher degrees can be achieved in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Complexity &amp; adaptivity of behavior</head><p>An agent that strives to fulfill internal, and possibly external, goals in interaction with a dynamic environment, will typically have to face a number of different and varying situations and tasks/requirements, each of which it has to master to a degree that ensures its long-term survival and self-preservation. That means, apart from learning to master particular situations, such an agent will typically have to exhibit different behaviors in different situations. Hence, behavioral complexity requires basically two types of adaptation/learning:</p><p>? Long-term adaptation or learning of particular behaviors, typically throughout an agent's lifetime (A2 autonomy). A typical example would be a robot that learns to avoid obstacles and might have to adapt this behavior later due to failing sensors, for example.</p><p>? Short-term adaptation of an agent's current overall control/behavior.</p><p>Typically this requires to temporarily integrate or switch between different specific behaviors/controllers (A3 autonomy). In the above example, shortterm adaptation would be required whenever the robot has to integrate/coordinate obstacle avoidance with other behaviors such as goal finding or object detection.</p><p>Hence, somewhat simplified and idealized, adaptive control of such an agent could be realized as in <ref type="bibr" target="#b5">Araujo and Grupen's (1996)</ref> control composition model ( <ref type="figure">figure 1</ref>) in which the control of a simple robotic agent is realized by a set of different controllers ('control level') for different behaviors. Each of these subsystems realizes a particular mapping from sensory input to actuator output at the 'sensorimotor level'. One of them, for example, avoids obstacles, another one approaches them. The 'adaptive control' level is realized by a higher level mechanism that learns to switch between these controllers depending on the agent's current situation.</p><p>&lt;&lt;&lt; <ref type="figure">Figure 1</ref> here &gt;&gt;&gt; Hence, adaptive control composition in such an agent poses the following three problems:</p><p>I. How to acquire and adapt particular behaviors, such as 'obstacle avoidance', realized as individual controllers in the above example from Araujo &amp;</p><p>Grupen. This poses a learning problem at the control level (part of the above A2 aspect of autonomy).</p><p>II. How to coordinate and structure the control of a possibly large number of these specific behaviors, some of which exclude/override each other and some of which have to be integrated, such as 'goal finding' and 'obstacle avoidance'. This poses a control problem at the adaptive control level, closely related to the above A3 aspect of autonomy.</p><p>III. How to learn to solve control problem II, as it would be required from an agent combining A2 and A3 autonomy. This is due to the fact that behavioral autonomy is considered to be the individual agent's own capacity not only to learn specific behaviors (problem I) but also to form and adapt its principles of behavior. Hence, this poses another learning problem, this time at the adaptive control level, namely how to acquire and adapt the overall control mechanism and structure.</p><p>It should be noted that for operationally autonomous agents above problems I and II will be solved by the system's designer. Typically this is done by programming individual behaviors and their coordination beforehand (thus the lack of A2 autonomy), which is clearly a non-trivial task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>18</head><p>In the case of behaviorally autonomous agents on the other hand the problems, at least partly, will have to be solved by the agent on its own. That means its behavior will not be fully pre-defined, but subject to self-adaptation (A2 autonomy). To allow this, the agent has to be equipped with some generic learning/adaptation mechanism by the system's designer beforehand. Hence, the designer's role here is still non-trivial, but of a different and less determining kind (cf. <ref type="bibr" target="#b27">Dorffner, 1997b;</ref><ref type="bibr" target="#b73">Nolfi, 1998</ref>).</p><p>In Araujo and Grupen's (1996) above model of control composition, for example, the agent only has a limited degree of A2 and behavioral autonomy: The individual controllers/behaviors are pre-defined and not subject to adaptation, moreover their number is limited and fixed, and the overall control can only switch between discrete behaviors, but not combine or integrate them. Further approaches to control composition will be discussed in section 4. <ref type="bibr" target="#b17">Brooks (1991)</ref> refers to embodiment and situatedness as the "two cornerstones to the new approach to Artificial Intelligence", and defines them as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Types of autonomous agents</head><formula xml:id="formula_1">Situatedness ?</formula><p>The robots are situated in the world -they do not deal with abstract descriptions but with the here and now of the world directly influencing the behavior of the system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19</head><p>As with autonomy, however, there are different notions/interpretations of embodiment and situatedness. Firstly there are those who emphasize the relevance of physical embodiment and accordingly restrict themselves to robotic forms of intelligence (e.g. <ref type="bibr" target="#b17">Brooks, 1991)</ref>, i.e. physically embodied agents, interacting with their environment by means of sensory perception and motor control. Thus, these agents, unlike traditional AI systems, can be said to have a certain degree of physical grounding <ref type="bibr" target="#b18">(Brooks, 1993)</ref>.</p><p>Secondly, there are those who also emphasize the relevance of sensorimotor interaction between robotic agents and their environments, but, for lack of physical resources, realizability, convenience or efficiency, use simulated embodied agents in sensorimotor interaction with more or less realistic simulated environments (e.g. <ref type="bibr" target="#b8">Beer, 1990</ref>).</p><p>Many researchers in the behavior-oriented AI community feel very strongly about this distinction between simulation and reality. A typical example is Steels (1994):</p><p>The goal is to build artifacts that are "really" intelligent, that is, intelligent in the physical world, not just intelligent in a virtual world. This makes unavoidable the construction of robotic agents that must sense the environment and can physically act upon the environment, particularly if sensorimotor competences are studied. This is why behavior-oriented AI researchers insist so strongly on the construction of physical agents бн Performing simulations of agents бн is, of course, an extremely valuable aid in exploring and testing out certain mechanisms, the way simulation is heavily used in the design of airplanes. But a simulation of an airplane should not be confused with the airplane itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>20</head><p>Thirdly, there are researchers who de-emphasize the role of physical embodiment and sensorimotor interaction, and rather focus on a more abstract situatedness or 'embeddedness', i.e. the property of existing within and directly interacting with a (nonphysical environment). Typical examples are so-called 'software agents' (e.g. <ref type="bibr" target="#b33">&amp; Ketchpel, 1994)</ref>, interacting with software environments such as the Internet (e.g. <ref type="bibr" target="#b52">Maes, 1994)</ref>. Unlike the above embodied agents, they lack simulated or physical body, sensors, motors, etc., but, unlike traditional AI systems, they directly interact with a complex (software) environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Genesereth</head><p>There is, however, a clear distinction to be made between agents that possess a body (or a realistic simulation of it) and those which do not ( <ref type="bibr" target="#b109">Varela et al., 1991</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Agent Control Architectures and Techniques</head><p>As mentioned in section 2.1, behavior-oriented AI typically studies the origin of complexity and adaptivity at different levels, from components and individual agents to 'species' of agents and complete eco-systems. There is however a growing consensus in the field that behavior systems should be considered the basic units of study, and that the behavior of a complete agent typically is the result of the cooperation/competition of a number of behavior systems. This section discusses different approaches to the design of behavior systems and techniques for their realization. Roughly these approaches can be categorized into two types:</p><p>? Engineering approaches, basically aiming for operational autonomy by engineering/programming an agent's behavior systems more or less completely beforehand.</p><p>? Learning approaches, aiming to equip the agent with a capacity for selforganization (the A2 aspect of autonomy), and thus provide it with a certain degree of behavioral autonomy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Engineering approaches</head><p>The problem with designing and 'hand-crafting' an agent's behavior systems is that typically not all possible situations the agent might have to face are known beforehand, especially in unpredictable environments. Hence, <ref type="bibr" target="#b89">Rylatt et al. (1998)</ref> state that "behaviour-based robot design has some reputation for being a black art", since an agent's behavior is not determined by its internal behavior systems alone, but by their interaction with its environment ( <ref type="bibr" target="#b109">Varela et al., 1991;</ref><ref type="bibr" target="#b9">Beer, 1995;</ref><ref type="bibr" target="#b20">Clark, 1997</ref>).</p><p>Furthermore, even if environmental dynamics and all possible situations could be foreseen at an abstract level, e.g. obstacles have to be avoided, this would not imply that it is actually possible to specify/formalize beforehand the agent's behavior at any point in time, i.e. to define how, in detail, all possible obstacle avoidance situations should be handled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Algorithmic approaches / Subsumption architecture</head><p>Algorithmic approaches are based on pre-programming an agent's behavior systems.</p><p>Following a divide-and-conquer approach, the overall control task is typically into suitable behaviors, to the designer. Thus, the agent's A2 autonomy is greater than in the original subsumption architecture, it does however remain limited.</p><p>Thus, the subsumption architecture has similarities to <ref type="bibr" target="#b5">Araujo and Grupen's (1996)</ref> earlier discussed control composition model. Both approaches use a fixed number of basic pre-defined behavioral modules, which in the former case combine in a selforganizing fashion to achieve bottom-up emergence of overall behavior, whereas in Araujo and Grupen's model they are switched between at a higher level of control.</p><p>In summary, pre-modularized architectures in general, and the subsumption architecture in particular, can be said to suffer from the following problems:</p><p>? The decomposition into modules/behavior systems has to be carried out topdown and a priori by the system's designer. It has been argued that this can be disadvantageous <ref type="bibr" target="#b71">(Nolfi, 1997a;</ref><ref type="bibr" target="#b72">Nolfi, 1997b;</ref><ref type="bibr" target="#b95">Sharkey et al., 1996)</ref>, and that behavioral organization/hierarchy should better be emergent instead <ref type="bibr" target="#b24">(Digney, 1996;</ref><ref type="bibr" target="#b114">Ziemke, 1996b</ref>).</p><p>? In a concrete agent, interacting with a non-trivial environment, the number of states and corresponding subsystems quickly increases, and so does their complexity <ref type="bibr" target="#b97">(Steels, 1994)</ref>.</p><p>? Priority arbitration schemes to handle conflicts between behavioral layers/modules, such as the subsumption relations in the subsumption architecture, are fixed and rather arbitrary which limits the controlled agent's flexibility ( <ref type="bibr" target="#b89">Rylatt et al., 1998;</ref><ref type="bibr" target="#b95">Sharkey et al., 1996</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>25</head><p>? The inherent commitment to finite-state automata as underlying mechanism results in a finite number of discrete states/behaviors that makes it difficult to achieve smooth, continuous behavior at the level of the overall system <ref type="bibr" target="#b97">(Steels, 1994)</ref>.</p><p>Furthermore, the algorithmic framework leaves relatively little room for the capacity to learn (A2 autonomy) which here would require an agent to re-program or re-structure itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Dynamic approaches</head><p>Dynamic approaches are based on the notion of behavior systems as continuous dynamical systems instead of discrete computational systems as in the algorithmic approach <ref type="bibr" target="#b97">(Steels, 1994)</ref>. For a detailed review see <ref type="bibr" target="#b92">Sch?ner et al. (1995)</ref>.</p><p>As the subsumption architecture, a dynamical systems architecture typically consists of a number of processes running in parallel. Each of these processes, by means of differential equations, establishes a continuous relationship between a set of quantities, e.g. between distance sensor readings and motor parameters in a mobile robot that turns sharper or slows down the closer it gets to an obstacle ( <ref type="bibr" target="#b92">Sch?ner et al., 1995)</ref>. are assigned to each behavior, which describe the behavior's state of activation and allow to switch it on or off, and a 'competition matrix' is used to define whether or not different behaviors can be active at the same time.</p><p>An advantage of behavior systems realized by differential equations is that, at least theoretically, it makes self-adaptation of an agent's behavior through dynamic adaptation of parameters, such as motivational variables, simpler than in the algorithmic framework. Another advantage of this approach is the fact that the dynamical systems paradigm is closer to descriptions used in physics, biology, and control theory <ref type="bibr" target="#b97">(Steels, 1994)</ref>.</p><p>Dynamical systems theory is, at least in theory, probably the most powerful and most appropriate framework for behavior description and explanation. It has been adopted as a framework of explanation in recurrent ANN approaches to adaptive behavior (e.g <ref type="bibr" target="#b9">Beer, 1995;</ref><ref type="bibr" target="#b102">Tani, 1996)</ref>, and also as a research framework in cognitive science <ref type="bibr" target="#b108">(van Gelder, 1995;</ref><ref type="bibr">see Port &amp; van Gelder (1995)</ref> for an introduction and overview).</p><p>The 'pure' dynamic approaches presented so far, using differential equations, however, suffer from a lack of a learning mechanism, and thus A2 autonomy. Hence, the major 27 problem is basically the same as for the algorithmic approach: It is (relatively) simple for the system's designer to increase behavioral complexity by adding further differential equations and/or motivational variables (behaviors/FSA in the algorithmic approach). It is, however, unclear how an agent could increase the complexity of its behavior on its own (A3 autonomy), let alone how it could learn to do this (A2 autonomy).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Learning approaches</head><p>As mentioned above, learning approaches to agent control aim to give agents a certain degree of A2 autonomy by providing agents with some capacity for learning/selforganization that allows them to acquire and/or adapt their behavior, at least to some extent, on their own. Most prominent among these are</p><p>? the connectionist/ANN approach to self-learning of individuals (section</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2.1), and</head><p>? evolutionary learning techniques based on adaptation at the population/species level, inspired by the mechanisms of natural selection (section 4.2.2).</p><p>The challenge for learning approaches is to design an appropriate generic learning mechanism, that allows agents the acquisition of complex and adaptive behavior, i.e. to solve problems I-III, at least partly, themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Connectionist approaches</head><p>For the understanding of the following discussion it should suffice to know that an ANN consists of a number of interconnected simple processing elements/units, each of which receives a number of numerical input values from which it calculates its own activation <ref type="bibr">28</ref> and a resulting output value. These outputs themselves can be passed on as input to other units along weighted interconnections. Thus, the ANN as a whole computes a certain mapping from input to output units; units in between are referred to as 'hidden units'. ANNs learn, from examples, to acquire a certain input-output mapping through adaptation of the connection weights between units (therefore ANNs are also referred to as connectionist networks) according to some learning algorithm, such as error backpropagation <ref type="bibr" target="#b85">(Rumelhart, Hinton &amp; Williams, 1986)</ref> A major advantage of the connectionist approach in the context of autonomous agents is that it incorporates mechanisms for learning behaviors which, often in combination with reinforcement learning techniques, i.e. learning from 'reward' and 'punishment', allows a bottom-up development of integrated control strategies <ref type="bibr" target="#b60">(Meeden, 1996)</ref>. For a detailed introduction and overview of reinforcement learning see <ref type="bibr" target="#b43">Kaelbling et al. (1996)</ref>, or Sutton (1991) for an animat-related overview. In the simplest case, this self-learning capacity reduces the system designer's task to the choice of an appropriate ANN architecture for a given control task.</p><p>Hence, connectionist networks are commonly considered to be effective mechanisms for controlling autonomous agents ( <ref type="bibr" target="#b61">Meeden et al., 1993;</ref><ref type="bibr" target="#b27">Dorffner, 1997b</ref> what connectionist architecture is best suited for which type of control task.</p><p>Feed-forward ANNs:</p><p>Because feed-forward networks compute a one-way mapping from inputs to outputs (i.e.</p><p>in the case of a robot controller from sensor input to motor outputs), a feed-forward controller can only react to its current input in each time step. As discussed above, purely reactive agents lack A1 autonomy, i.e. they depend on sufficient input to be available from the environment at any point in time. The complexity of behavior that can be achieved with such an agent is of course limited. Nevertheless it has been shown that such a system can learn to acquire far more than trivial behavior. <ref type="bibr" target="#b67">Nehmzow (1994)</ref>, for example, used a simple robotic vehicle controlled by a feed-forward network mapping the input from two whisker sensors at the front of the vehicle to four possible actions (left, right, forward, backward). It was shown that, using reinforcement learning, this vehicle could successfully be trained to perform tasks like corridor following or box pushing in a purely reactive fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recurrent ANNs:</head><p>Recurrent connectionist networks are a special case of dynamical systems (see <ref type="bibr" target="#b47">Kolen, (1994)</ref> for a detailed discussion of this aspect), and they are commonly considered more suitable for the purpose of adaptive control since they allow an implicit representation of dynamical aspects in form of feedback through an internal network state (e.g. <ref type="bibr" target="#b9">Beer, 1995;</ref><ref type="bibr">Meeden,1996;</ref><ref type="bibr" target="#b102">Tani, 1996)</ref>.  <ref type="figure">Figure 4</ref>). These recurrent controller networks have been shown to develop internal states that reflect the vehicle's current task/context ( <ref type="bibr" target="#b61">Meeden et al., 1993</ref>) and result in sequential, plan-like behavior that can be characterized as "emergent planning" <ref type="bibr" target="#b61">(Meeden et al., 1993;</ref><ref type="bibr" target="#b60">Meeden, 1996)</ref>.</p><p>Limitations of conventional ANN approaches:</p><p>A problem with the connectionist approach is that, although single ANNs might be very well suited for the realization/learning of individual behavior systems (solving problem I), a conventional monolithic network could hardly be sufficient to realize and integrate a number of complex and diverse behavior systems (problem II) as it would be required to control a complete autonomous agent that interacts with a complex and dynamic environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>31</head><p>More specifically, the problem is that an ANN always realizes a certain function, or an iterated function system in the case of recurrent networks <ref type="bibr" target="#b47">(Kolen, 1994)</ref>, i.e. a particular mapping of input (and internal state) to output. The weights in such a network, realizing this functional mapping, usually remain constant after a certain training phase, or, in continual or 'lifelong' learning approaches, are updated only stepwise and very gradually, i.e. the sensorimotor mapping will basically remain static. That means that the complexity/diversity of behavior that can be learned by a single conventional ANN is strongly limited by the degree to which a number of behavior systems can be realized/integrated in a single functional mapping. This limits the controlled agent's A3 autonomy, i.e. its capacity for flexible short-term adaptation to a possibly rapidly changing environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modular ANNs:</head><p>There are a number of modular ANN approaches to the control of autonomous agents (e.g. <ref type="bibr" target="#b90">Saunders et al., 1994;</ref><ref type="bibr" target="#b106">Urzelai et al., 1998</ref>). They do, however, mostly suffer from the problems of built-in modularization, as in the subsumption architecture, which have been discussed earlier: The controlled agents are given a certain A3 autonomy, they are, however, typically not able to re-structure/organize their behavior themselves.</p><p>A modular ANN approach that, at least partly, addresses problems I, II and III of adaptive control composition is Jordan and Jacobs' work on the Adaptive Mixture of Experts (AME) architecture. AME is a general learning approach, not specifically developed for autonomous agents control. <ref type="bibr" target="#b104">Tani &amp; Nolfi (1998)</ref>, however, have applied a similar approach, referred to as Mixture of Recurrent Neural Network Experts (MRE), to 32 robot learning. <ref type="bibr" target="#b42">Jordan &amp; Jacobs (1995)</ref> present a good overview of the AME architecture; for details see <ref type="bibr" target="#b40">Jacobs et al. (1991)</ref> or <ref type="bibr" target="#b104">Tani &amp; Nolfi (1998)</ref>.</p><p>In the AME architecture ( <ref type="figure">figure 5</ref>) a number of ANN-modules, referred to as experts, work in parallel. Each expert typically acquires a specific competence/behavior (solving problem I). Their outputs are integrated by another ANN, the so-called gating network, which assigns weights (g i ) between 0 and 1 to each of the experts' outputs (typically the sum of all g i is 1).</p><p>&lt;&lt;&lt; <ref type="figure">Figure 5</ref> here &gt;&gt;&gt; In comparison to the control composition models discussed earlier the AME has the following advantages:</p><p>? The individual controllers are learned (solving problem I), and it is up to the system how to distribute behaviors over expert networks.</p><p>? Switching between behaviors/experts is carried out by the gating network (solving problem II) and it can be learned as well (problem III).</p><p>? Combination/composition of behaviors is difficult, but possible through softswitching of the gating network (more than one g i greater 0).</p><p>Hence, an AME-controlled agent has a certain degree of A2 and A3 autonomy, and if using recurrent networks, as in the MRE case, it will also have A1 autonomy. The number of expert networks, however, is typically pre-set. Hence, the system's structure <ref type="bibr">33</ref> is still partly designed instead of fully self-acquired, which leads to problems with adaptation of the behavioral organization, concerning how and when to add or remove experts.</p><p>Self-Adapting Recurrent Networks:</p><p>As discussed above, the problem with conventional ANNs is that their connection weights are rather static, with the result that the controlled agent, apart from the influence of the internal feedback, always maps sensory input to motor output the same way. In biological neural networks, however, connection weights are known to fluctuate.</p><p>This has, for example, been pointed out by <ref type="bibr" target="#b34">Globus (1992)</ref>:</p><p>To summarize, in biologically realistic nets the connectivity, connection weights, nodal transfer functions, and network parameters can change fluidly under chemical control: the nets are chemically tunable moment to moment, leaving no trace, only a fluctuating attunement.</p><p>A connectionist control architecture that aims to provide A3 autonomy through a form of "fluctuating attunement" is the Self-Adapting Recurrent Network (SARN) <ref type="bibr" target="#b113">(Ziemke, 1996a;</ref><ref type="bibr" target="#b115">Ziemke, 1996c)</ref>, inspired by Pollack's (1991) work on 'dynamical recognizers'.</p><p>Adaptive control composition is here achieved through a different, higher-order, type of feedback which is used to adapt the sensorimotor mapping itself. Thus, the SARN ( <ref type="figure">figure 6</ref>) consists of two ANNs in a master-slave relationship:</p><p>? The function (slave) network, as conventional ANN controllers, maps sensory inputs to motor outputs, and is responsible for acquiring particular behaviors,</p><p>i.e. correct input-state-output mappings.</p><p>? The context (master) network takes as input the function network's internal state, and adapts weights in the function network. Hence, the context network has to learn when to use which behavior/sensorimotor mapping, or, in AME terms, how to 'construct' a suitable expert for each particular context and internal state.</p><p>&lt;&lt;&lt; <ref type="figure">Figure 6</ref> here &gt;&gt;&gt; In a number of experiments on mobile robots (Ziemke, 1996a; Ziemke, 1996c) SARNs have proven capable to acquire structured behavior, based on emergent behavioral hierarchy/organization realized as internal state space dynamics. In these experiments</p><p>SARNs were shown to realize adaptive control composition through context-dependent continual adaptation of their own behavioral bias (default behavior) and sensorimotor mapping. This, for example, allowed a controlled robot to integrate wandering and obstacle avoidance behaviors with periodically switching between seeking and avoiding light sources in a subsumption-like fashion (Ziemke, 1996a).</p><p>Hence, in comparison to the models of control composition discussed above, the SARN architecture offers the following advantages:</p><p>? Individual behaviors, such as obstacle avoidance, are acquired through the function network (solving learning problem I).</p><p>? The overall control is composed of multiple 'virtual controllers'</p><p>(instantiations/variations of the function network) 'constructed' by the context network (solving control problem II) which learns when to use which function network (solving learning problem III).</p><p>? Emergent behavioral organization and 'decomposition' of the overall control task into particular behaviors and their combinations, based on internal state space dynamics, in line with the earlier discussed arguments against built-in behavioral organization/structure.</p><p>Furthermore, in comparison to the AME/MRE the SARN architecture has the following characteristics:</p><p>? The SARN does not switch between a limited/fixed number of experts, but 'constructs' 'virtual experts' for each context, which to some degree circumvents AME/MRE's problems when/how to add and remove experts, which could be especially useful for developing agents in dynamical environments.</p><p>? Integration/combination of multiple behaviors is simpler, since behaviors are realized as 'virtual' rather than dedicated single-purpose experts.</p><p>Thus, the SARN combines different aspects of autonomy in an interesting way: It provides A1 autonomy through its use of internal state, A2 autonomy through its twofold learning capacity, and A3 autonomy through its capacity to selectively modify/activate behavior in a context-dependent fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>36</head><p>Problems with (connectionist) self-learning approaches:</p><p>Although the use of connectionist self-learning techniques allows for A2 autonomy, it has to be noted that there are a number of problems arising from the fact that the most powerful ANN-learning techniques are supervised or reinforcement learning techniques.</p><p>During supervised learning an ANN has to be supplied with the correct target output in every time step. This leads to a problem analog to that of engineering approaches (cf. section 4.1), namely that a sufficiently accurate model of the control task has to be available beforehand.</p><p>During reinforcement learning an ANN typically only receives occasional feedback in terms of 'good' or 'bad'. This has the advantage that no longer a detailed model of what exactly to do in every situation is required. Instead more abstract information has to be available about negative situations (e.g. a robot hitting an obstacle) and positive ones (e.g. a robot reaching a goal). This abstract feedback is, of course, easier to provide than detailed supervision, nevertheless there are problems:</p><p>? Reinforcement is typically given in abstract terms ('good' or 'bad') whereas most ANN learning algorithms require precise error measurements. There are, however, approaches addressing this problem, as the complementary reinforcement backpropagation algorithm <ref type="bibr" target="#b0">(Ackley &amp; Littman, 1990</ref>; for applications to robot learning see <ref type="bibr" target="#b60">Meeden, 1996;</ref><ref type="bibr" target="#b113">Ziemke, 1996a</ref><ref type="bibr" target="#b106">, Urzelai et al., 1998</ref>).</p><p>? ANNs typically learn from feedback in every time step. For complex tasks, however, reinforcement often is not available until, for example, a goal is achieved, i.e. typically after a possibly long sequence of actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>37</head><p>It should be noted that these problems, especially the latter one, are not ANN-specific but have to be faced by any self-learning agent when learning from interaction with an environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Evolutionary approaches</head><p>Evolutionary learning techniques are inspired by the mechanisms of natural selection <ref type="bibr" target="#b38">(Holland, 1975;</ref><ref type="bibr" target="#b83">Rechenberg, 1973)</ref>. Evolutionary algorithms typically start from a randomly initialized population of individuals/genotypes encoded as strings of bits or real numbers. Each individual usually represents a (possible) solution to the problem at hand; in the context of autonomous agent control this could, for example, be the weights in a controller ANN (of pre-defined architecture). Further generations of individuals are then typically produced through iteration of the following steps:</p><p>? Evaluate each individual's fitness according to some measure that determines how good a solution the individual represents.</p><p>? Select two parent individuals from the old population, biased in favor of fitter ones.</p><p>? Recombine the two parent individuals to give two offspring: Both parent strings are cut in pieces at randomly chosen positions. The two offspring individuals are formed by recombining parts of parent 1 with parts of parent 2.</p><p>? Mutate the offspring individuals by altering the strings at randomly chosen positions.</p><p>? Insert offspring individuals into the new population.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>38</head><p>Due to the repeated selection and reproduction of fitter individuals ('survival of the fittest'), the population's average fitness, i.e. the individuals' capacity to solve the problem at hand, tends to increase over generations. For a proper introduction to evolutionary algorithms see <ref type="bibr" target="#b66">Mitchell (1996</ref><ref type="bibr">Mitchell ( ) or B?ck (1996</ref>.</p><p>A number of researchers (e.g. <ref type="bibr" target="#b60">Meeden, 1996;</ref><ref type="bibr" target="#b29">Floreano &amp; Mondada, 1996;</ref><ref type="bibr" target="#b71">Nolfi, 1997a)</ref> have used evolutionary algorithms to evolve ANN connection weights. <ref type="bibr" target="#b60">Meeden (1996)</ref>, for example, used an evolutionary algorithm to find suitable weight settings for the recurrent controller network for the robotic vehicle discussed above. Comparisons to the results achieved with conventional ANN learning showed that evolutionary algorithms can find suitable solutions more reliably in cases where no sufficient reinforcementmodel or only delayed reinforcement is available, e.g. if the controller only gets rewarded once for reaching a goal location after a possibly large number of steps. This is due to the fact that evolutionary algorithms do not require step-by-step supervision or reinforcement, since they are not based on self-learning individuals. Instead they typically give a once-in-a-lifetime reinforcement by letting individuals reproduce according to their fitness, which in Meeden's (1996) case was evaluated by counting achieved goals and errors made for each individual during a test run.</p><p>Thus, evolutionary algorithms, typically evolve a large number of individuals, each representing a possible solution, over an even larger number of generations. The problem with this type of learning in an autonomous agent is that in an individual physical agent/robot the evolution and evaluation of such a large number of controllers is often not possible/feasible due to real time and memory restrictions. Therefore this learning process can often only be carried out in a simulated environment, therefore 39 referred to as "off-line evolution" <ref type="bibr" target="#b97">(Steels, 1994)</ref>. This is also the case in the above example from <ref type="bibr" target="#b60">Meeden (1996)</ref>, where, however, the evolved control networks were successfully transferred to the physical robot afterwards. A counter-example of the evolution of homing behavior realized entirely on a physical robot is given by <ref type="bibr" target="#b29">Floreano &amp; Mondada (1996)</ref>.</p><p>Another interesting application of evolutionary methods is the evolution of agent morphologies (e.g. <ref type="bibr" target="#b49">Lund et al., 1997;</ref><ref type="bibr" target="#b96">Sims, 1994)</ref>, sometimes in co-evolution with the agent's control mechanism <ref type="bibr" target="#b21">(Cliff &amp; Miller, 1996;</ref><ref type="bibr" target="#b50">Lund &amp; Miglino, 1998)</ref>. This approach aims to overcome <ref type="bibr">what Funes &amp; Pollack (1997)</ref> call the "chicken and egg" problem of evolutionary robotics:</p><p>Learning to control a complex body is dominated by inductive biases specific to its sensors and effectors, while building a body which is controllable is conditioned on the pre-existence of a brain.</p><p>An example of this approach is the work by <ref type="bibr" target="#b21">Cliff and Miller (1996)</ref>, who co-evolved, in simulation, the 'eyes' (optical sensors) and 'brains' (connectionist control networks) of simple agents which pursue and evade each other in a two-dimensional plane.</p><p>For detailed discussions of different approaches in evolutionary robotics see <ref type="bibr" target="#b74">Nolfi et al. (1994)</ref> or <ref type="bibr" target="#b36">Harvey et al. (1997)</ref>, for a discussion of the relation to other approaches see <ref type="bibr" target="#b73">Nolfi (1998)</ref>.</p><p>Combinations of evolutionary adaptation and self-learning:</p><p>Inspired by the variety of adaptive mechanisms in natural systems, a number of researchers have suggested the combination of different adaptation techniques (e.g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>40</head><p>Vaario &amp; Ohsuga, 1997). Combinations of evolutionary adaptation with self-learning techniques have recently received a lot of attention (e.g. <ref type="bibr" target="#b64">Michel, 1996;</ref><ref type="bibr" target="#b75">Nolfi &amp; Parisi, 1997;</ref><ref type="bibr" target="#b106">Urzelai et al., 1998</ref>). Such approaches are often inspired by natural systems, such as higher animals, which are typically equipped with some minimal innate 'default'-behavior (instincts, reflexes, etc.) by evolution, often required to ensure survival until more complex skills have been self-learned. An example of this is the innate capacity of many animals (zebras, antelopes, etc.) to learn to walk within minutes after birth <ref type="bibr" target="#b94">(Sharkey &amp; Heemskerk, 1997)</ref>.</p><p>A typical example of such a combination is the evolution of connectionist control architectures (cf. <ref type="bibr" target="#b45">Kodjabachian &amp; Meyer, 1995)</ref>, which, once evolved, can be trained in the conventional self-learning fashion (e.g. <ref type="bibr" target="#b64">Michel, 1996)</ref>. The evolution of ANN architectures has the advantage that it further reduces the designer's influence on an agent's behavior systems.</p><p>Another interesting example for the combination of evolutionary adaptation and selflearning is <ref type="bibr" target="#b75">Nolfi &amp; Parisi's (1997)</ref> work on 'self-teaching' networks which give individual robots the capacity to adapt to changing environments, learning from evolved self-supervision. These self-teaching networks produce motor outputs, but also an equal number of teaching outputs which are used to supervise the motor output units, i.e. the teaching units' outputs are used as target outputs for the motor output units during the robot's self-learning phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>After giving an overview of some key issues of the behavior-oriented approach to AI in section 2 and 3, and architectures and techniques for the realization of adaptive behavior 41 in section 4, the intention of this section is to discuss a few key issues/questions for future work on autonomous agents. Furthermore, it will be discussed what behaviororiented AI has to offer to virtual environments, and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">How relevant are autonomous agents to AI?</head><p>As Pfeifer (1995) points out, throughout its history AI's interest in intelligent behavior and cognitive capacities has been twofold, and so it is in the study of autonomous agents:</p><p>On the one hand we want to design robots, on the other we want to understand </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Behavioral autonomy in artifacts?</head><p>The question whether or not life-like levels of autonomy and intelligence can be achieved in artificial agents has to be considered an empirical issue, and time will tell how successful current approaches will be. It is clear that any technique for the realization of behavioral autonomy has to address adaptive behavior and control composition, and a number of approaches have been reviewed briefly in this paper. The key question here is how to deal with complex, but flexible structures of behavior.</p><p>The lack of environmental grounding in traditional AI, i.e. the systems' inability to relate their built-in internal mechanisms and representations to their environment via perception and action, seems to suggest to reduce engineering to a minimum (cf. e.g. <ref type="bibr" target="#b116">Ziemke (1997)</ref>, <ref type="bibr" target="#b27">Dorffner (1997b)</ref>; see, however, also Albus (1996) for an opposite viewpoint), and to rely on a maximum of self-organization instead (cf. <ref type="bibr" target="#b73">Nolfi, 1998</ref>).</p><p>This would require not to build/design too much into a system beforehand, but to let agents acquire both their behavior and its behavioral organization themselves in the course of artificial evolution, development and learning; in particular aiming for evolved/emergent control hierarchies and behavior organization, as exhibited by a number of approaches discussed in this paper.</p><p>As <ref type="bibr" target="#b109">Varela et al. (1991)</ref> point out, the autonomy and situatedness of living systems is the result of the long, evolutionary and individual, history of agent-environment interaction <ref type="bibr">43</ref> reflected in their embodiment. Hence, they view cognition and intelligent behavior as embodied action, which they describe as follows:</p><p>By using the term embodied we mean to highlight two points: first, that cognition depends upon the kinds of experience that come from having a body with various sensorimotor capacities, and second, that these individual sensorimotor capacities are themselves embedded in a more encompassing biological, psychological, and cultural context. By using the term action we mean to emphasize ... that sensory and motor processes, perception and action, are fundamentally inseparable in lived cognition.</p><p>From this perspective, behavioral autonomy is the result of the co-evolution/codevelopment of living systems with natural environments. Hence, the synthesis of behavioral autonomy and intelligence in artifacts is likely to require more life-like qualities in both agents and environments (cf. also <ref type="bibr" target="#b116">Ziemke, 1997;</ref><ref type="bibr">Ziemke &amp; Sharkey, 1998</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Life-like qualities in agents and environments</head><p>Although behavior-oriented AI is to some degree biologically inspired <ref type="bibr" target="#b97">(Steels, 1994)</ref>, so far most of its agents, environments, and learning scenarios seem rather simplistic when compared to natural agents and environments. The goal of AI is, of course, not to copy biological systems <ref type="bibr" target="#b17">(Brooks, 1991;</ref><ref type="bibr" target="#b78">Pfeifer &amp; Verschure, 1995)</ref>, but to understand and model the general principles underlying intelligent behavior and cognitive capacities.</p><p>Some of the abstractions from biology used so far, and certainly those used by cognitivism and traditional AI, however, seem to leave out relevant details which need <ref type="bibr">44</ref> to be 're-introduced' into the study of intelligent behavior ( <ref type="bibr" target="#b109">Varela et al., 1991;</ref><ref type="bibr" target="#b116">Ziemke, 1997;</ref><ref type="bibr">Ziemke &amp; Sharkey, 1998)</ref>.</p><p>Some aspects that have to be addressed on the agent side are the following:</p><p>? Much current work still focuses on one-learning-technique-, one-stagelearning of a pre-given task in a pre-given environment. Adaptation in natural systems, however, takes place through multiple mechanisms of evolution, individual development, and self-learning (e.g. <ref type="bibr" target="#b107">Vaario &amp; Ohsuga, 1997;</ref><ref type="bibr" target="#b109">Varela et al., 1991</ref>; cf. previous section).</p><p>? In particular, intelligence in natural agents is subject to development, often involving a number of developmental stages in the individual, biased by its species-dependent physiology, instincts, reflexes, etc. (cf. <ref type="bibr" target="#b94">Sharkey &amp; Heemskerk, 1997</ref>). In behavior-oriented AI the aspect of individual development has been largely neglected for a long time <ref type="bibr" target="#b63">(Meyer &amp; Guillot, 1994)</ref>, but has received attention more recently (e.g. <ref type="bibr" target="#b46">Kodjabachian &amp; Meyer, 1998</ref>).</p><p>? Agents need internal dynamics, i.e. more complex systems of varying motivations and values, including a variety of mechanisms supplying selfreinforcement for an agent's behavior (cf. <ref type="bibr" target="#b75">Nolfi &amp; Parisi's (1997)</ref> 'selfteaching' networks discussed earlier).</p><p>? Agents need to be more active following their internal dynamics and pursuing their goals. That is, they need capacities to perceive actively and selectively, to focus their attention, etc.; currently agents are typically rather passive 45 observers, purely driven by the dynamics of the "environmental puppeteer" <ref type="bibr" target="#b94">(Sharkey &amp; Heemskerk, 1997</ref>).</p><p>As discussed above, behavior results from the interaction of an agent's actions with environmental conditions and dynamics. Hence, it is unlikely that 'intelligent' behavior can be achieved in complex agents dealing with simple environments. That means, complexity is also required on the environment side. That is, there is a need for artificial ecosystems (cf. <ref type="bibr" target="#b107">Vaario &amp; Ohsuga, 1997</ref>) with competition, collaboration and coevolution at both agent and species level, in which there are ecological niches into which agents/species can specialize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Does behavior-oriented AI need virtual environments?</head><p>As discussed earlier, there is a certain resentment toward simulation in much of the autonomous agents/robotics community. The 'real world', however, happens to be a very scarce resource. It has been argued in this paper, that in line with the general behavior-oriented approach to adaptation/learning/intelligence at different levels and in different forms, learning scenarios should be more complex and more realistic than they usually are today, preferably complete ecosystems, i.e. environments containing multiple agents/species of sufficient complexity. In the typical research laboratory, however, the demand for multiple robots already poses a serious problem. The required resources for complex learning scenarios are simply not physically available, and, even if they were, much of the above could not be realized within reasonable time limits, if at all. Processes in the physical world are, for example, relatively slow, and research on the evolution of hardware is only in its beginning stages. Hence, due to the impossibility/unfeasibility of much of the above in the real world, virtual environments 46 might be an alternative route (cf. e.g. <ref type="bibr" target="#b55">Mallot, 1997</ref>). The question of how much of the above is realizable with existing VR techniques, does of course remain.</p><p>Hence, to be able to implement many of the ideas in the area of behavior-oriented AI, as well as to resolve many of its open questions, future research on autonomous agents could profit greatly from realistic simulations of autonomous agents in sensorimotor interaction with virtual environments of sufficient complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Do virtual environments need autonomous agents?</head><p>The question of possible use/roles of autonomous agents in virtual environments has to be answered with regard to different types of agents, as well as different types of virtual environments.</p><p>First of all, autonomous agents, or AI techniques in general, are of course not required in all virtual environments. In architectural VR scenarios, for example, commonly only visited by avatars, representing human visitors, there probably is no need for any type of autonomous agents, unless, possibly, as a rather passive population. In many other environments operationally autonomous agents might play the role of side-actors, as, for example, in the ALIVE system ( , which allows the interaction of humans and a virtual environment inhabited by artificial agents. Many techniques for generation/simulation of adaptive behavior in operationally autonomous agents are available, and a number of examples have been given in this paper. The role of software agents, much like in existing software environments, could be that of monitors or sentinels, e.g. in medical training simulations.</p><p>If, however, there is a need for virtual environments to be populated by more flexible and life-like agents, in particular where humans are supposed to cooperate or compete <ref type="bibr">47</ref> with artificial agents, e.g. for training purposes, then there will be a need for agents with a certain degree of behavioral autonomy and some capacity for self-organization. After all, how realistic could such a scenario be if only the humans could learn, but not their virtual collaborators/opponents? Hence, many of the AI issues discussed in this paper, such as the question of how intelligent/adaptive, and thereby how realistic, an artificial agent can ever be, are also relevant for the realization of realistic virtual environments of this type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Summary and Conclusion</head><p>The intention of this paper has been to give an overview of the key issues, available</p><p>techniques and remaining problems of research on adaptive behavior in autonomous agents. Section 2 introduced the behavior-oriented approach to AI by contrasting it with its knowledge-based counterpart. Some of the problems of traditional AI systems have been reviewed, in particular their incapacity to relate their abstract internal processes and representations to the 'world outside'. In the behavior-oriented approach, on the other hand, agent-environment interaction and a bottom-up approach to the modeling of adaptive behavior have been identified as key elements.</p><p>Section 3 discussed a number of conceptual issues in the area of behavior-oriented AI.</p><p>Different notions of autonomy were discussed, and three relevant aspects of life-like autonomy were identified. Furthermore, the generation of adaptive and complex behavior, as typical for natural agents, was introduced as a key issue in behaviororiented AI, and three key problems for its realization in artificial agents were identified.</p><p>Section 4 gave an overview of architectures and techniques used in engineering and learning approaches to the realization of agents' behavior systems in general, and <ref type="bibr">48</ref> adaptive control composition in particular. The individual techniques were discussed in general, exemplified, and evaluated regarding their potential to realize different aspects of autonomy and to address/solve the aforementioned problems of adaptive control composition.</p><p>Section 5, finally, put bits and pieces together, making a number of suggestions concerning the central importance of behavioral autonomy for autonomous agents and for AI and cognitive science research in general. In particular, it was argued, following <ref type="bibr" target="#b109">Varela et al. (1991)</ref>, that in order to synthesize true intelligence and autonomy, artificial agents, their environments, and the interaction between them would have to be more like-like. It should be noted that this does not necessarily require to mimic biological systems in detail (cf. <ref type="bibr" target="#b78">Pfeifer &amp; Verschure, 1995)</ref>, but rather to attempt to gain further understanding of the underlying principles of intelligent behavior in living systems.</p><p>Moreover, it was argued that the areas of behavior-oriented AI and virtual environments research, despite a certain resentment towards simulation in the former camp, could in fact complement each other, and that both could profit from a closer cooperation. The contribution behavior-oriented AI can make to virtual environments lies in the development of models/mechanisms for the realization of behavioral adaptivity and complexity, and thereby more realistic behavior in, for example, virtual animals or humans.</p><p>For behavior-oriented AI, due to its emphasis of embodiment and agent-environment interaction, the ultimate validation of theories/models of intelligent behavior can only be provided by physical agents. The limitations of physical experimentation, however, make the synthesis of physical life-like agents unfeasible, at least in the near future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>49</head><p>Hence, possibly as an intermediate step, virtual environments would be extremely useful tools for behavior-oriented AI experimentation if they could provide sufficiently lifelike agents, environments, and modes of interaction between them. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>50</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>? Embodiment ? The robots have bodies and experience the world directly - their actions are part of a dynamic with the world and have immediate feedback on their own sensations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>decomposed into less complex sub-problems. This usually results in a corresponding hierarchical modularization of the internal control mechanism which simplifies the engineering of the agent's behavior. Typical for traditional AI approaches is a functional decomposition following what Brooks (1991) calls the sense-model-plan-act (SMPA) framework. Here control is broken down into a series of rather isolated functional units (figure 2): Input systems handle perception of sensory input, and deliver their results to a modeling module which integrates the new information into a central world model. A planner, based on this internal representation of the world alone, decides on which actions to take. These actions, finally, are executed by the appropriate modules handling, for example, motor control. &lt;&lt;&lt; Figure 2 here &gt;&gt;&gt; Brooks (1986, 1991) pointed out a number of flaws in the SMPA framework and instead suggested a decomposition of the control task into behavior-producing modules such as 'wandering', 'obstacle avoidance' and 'goal finding' (figure 3). Each of these modules maps sensory input to motor output, and in Brooks' own work is typically implemented by a finite-state automaton (FSA). Thus the agent can make use of internal state 23 information, which gives it some A1 autonomy. Typically all behavioral modules work in parallel, and they are hierarchically organized in a subsumption architecture using priorities and subsumption relations for the communication between modules, which allows some of them to override the output of others (a form of A3 autonomy). Hence the overall behavior of the controlled agent emerges in self-organized fashion from the interaction of the individual behavioral modules with the environment and among each other. See Brooks (1989) for an elaborated example of a walking robot controlled by a subsumption architecture. &lt;&lt;&lt; Figure 3 here &gt;&gt;&gt; The subsumption architecture has the advantage that it uses a universal computational formalism that gives a high degree of freedom and allows a modular buildup of complex systems (Brooks, 1991; Steels, 1994). Typically, however, there is no self- adaptation/learning in the subsumption architecture, i.e. the resulting agents lack autonomy in the A2 sense. This can partly be overcome by implementing the individual modules with self-learning techniques. Sharkey et al. (1996) used ANNs for this. Their results, however, indicate that at least in some cases a monolithic ANN controller results in more smooth behavior than one modularized in a subsumption architecture fashion. Furthermore this approach only solves problem I (the learning of individual behaviors), but leaves problem III, i.e. the question of how to structure/decompose the control task 24</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>For a detailed example of a dynamic approach to behavioral organization see Steinhage &amp; Bergener (1998), who scale the approach up to the generation of behavioral sequences and action selection in a mobile robot. Typically processes/behavior systems are active all the time and 'cooperate' through combination of their effects at the level of actions. For example, if two independent subsystems suggest turns of 20 degrees to the left and 20 degrees to the right the result could be not to turn at all. The reduction of the overall control to a simple combination 26 of the effects of individual behavior systems does in general lead to smoother behavior (Steels, 1994). It does, however, also pose a problem since it makes a more complex integration of behaviors (such as one behavior overriding another) difficult. Hence, more complex control situations require the extension of the 'pure' framework of differential equations by introducing 'motivational variables' that causally influence behavior systems and have a dynamics of their own (Steels, 1994). In Steinhage &amp; Bergener's (1998) dynamic approach to behavioral organization 'activation variables'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>The most conventional type of feedback is to re-use some of the controller network's activation values as extra inputs at a later, typically the next, point in time. A good 30 example is the work by Meeden (1996) who uses a recurrent ANN controller, similar to Elman's Simple Recurrent Network (1990), to guide a toy-car-like vehicle. The vehicle's task is to keep moving around in an environment while minimizing contact with obstacles and periodically seeking/avoiding a light source placed in the environment. The controller network (figure 4) receives sensory input from a number of touch and light sensors as well as a special input determining its current goal, and controls the vehicle's two motors. &lt;&lt;&lt; Figure 4 here &gt;&gt;&gt; In this controller it is the internal state (hidden unit values) which are fed back as extra inputs (cf.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>cognition in humans, animals, and robots. The former goal is one of engineering, the latter one of cognitive science. бн The two perspectives are intimately related but different. These two goals are also reflected in the two different notions of autonomy, operational and behavioral. From the engineering perspective, operational autonomy is 'sufficient' in most cases, and such systems offer an interesting alternative to systems that require teleoperation or other forms of human intervention. The relevant issues are of a typical engineering nature, such as the question how to build in the adaptivity and complexity required for a system to operate without human intervention in unpredictable environments. From the cognitive science perspective, behavioral autonomy, and the question what its underlying mechanisms in natural and artificial systems are, is certainly the most interesting aspect of autonomous agents research, since behavioral autonomy is an essential element of a modern notion of human-level intelligence. Unlike traditional AI systems, autonomous agents offer a platform/tool for the study of the issues relevant to 42 behavioral autonomy and modern notions of cognition, such as dynamics of agent- environment interaction, situatedness, embodiment and the relevance of sensorimotor intelligence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 .Figure 2 .Figure 3 .Figure 4 .</head><label>1234</label><figDesc>Figure 1. Control composition of an agent. Redrawn from Araujo &amp; Grupen (1996)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head></head><label></label><figDesc>. If activation is passed forward only, i.e. from input toward output units, we speak of feed-forward networks. If networks, in addition, use internal feedback of activation we speak of recurrent networks. For a proper introduction to the basic ideas and techniques underlying connectionism and ANNs see Medler (1998) or Knight (1990).</figDesc><table></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>). Connectionist approaches to agent control are usually based on a more or less direct coupling between the agent's sensory inputs and action parameter outputs, often using a single ANN 29 instead of separate behavior systems. There is, however, only little consensus yet on</figDesc><table></table></figure>

			<note place="foot" n="2"> Boden&apos;s (1996) third point is the &quot;extent to which a system&apos;s inner directing mechanisms can be reflected upon and/or selectively modified, by the individual concerned&quot;, i.e. the capacity for &quot;conscious reflection and self-modification&quot;.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Generalization and scaling in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Ackley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<editor>D. S.</editor>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Touretzky</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<biblScope unit="page" from="550" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pengi: An Implementation of a Theory of Activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chapman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth National Conference on Artificial Intelligence</title>
		<meeting>the Sixth National Conference on Artificial Intelligence<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="268" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The Engineering of Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Albus</surname></persName>
		</author>
		<editor>P. Maes, M. Mataric, J.-A. Meyer, J. Pollack &amp; S</editor>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<title level="m">From Animals to Animats 4 -Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning Control Composition in a Complex Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Grupen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-A</forename><surname>Mataric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meyer</surname></persName>
		</author>
		<title level="m">From Animals to Animats 4 -Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior</title>
		<editor>J. Pollack &amp; S. Wilson</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="333" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Evolutionary Algorithms in Theory and Practice -Evolution Strategies, Evolutionary Programming, Genetic Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>B?ck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Intelligence as Adaptive Behavior: An Experiment in Computational Neuroethology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Beer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Academic Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A dynamical systems perspective on agent-environment interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Beer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="173" to="215" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The dynamics of adaptive behavior: A research program</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Beer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="257" to="289" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Autonomy and Artificiality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Boden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Philosophy of Artificial Life</title>
		<editor>M. A. Boden</editor>
		<meeting><address><addrLine>Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="95" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Towards a Practice of Autonomous Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bourgine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Varela</surname></persName>
		</author>
		<editor>F. J. Varela &amp; P</editor>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bourgine</surname></persName>
		</author>
		<title level="m">Toward a Practice of Autonomous Systems -Proceedings of the First European Conference on Artificial Life (pp. xi-xvii)</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Vehicles: Experiments in Synthetic Psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Braitenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A robust layered control system for a mobile robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Robotics and Automation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="23" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Robot That Walks: Emergent Behavior from a Carefully Evolved Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="253" to="262" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Intelligence without Reason</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twelfth International Joint Conference on Artificial Intelligence<address><addrLine>San Mateo, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="569" to="595" />
		</imprint>
	</monogr>
	<note>IJCAII-91</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Engineering of Physical Grounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Brooks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Annual Conference of the Cognitive Science Society</title>
		<meeting>the Fifteenth Annual Conference of the Cognitive Science Society<address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="153" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Motor development in the mind: The potential role of motor abilities as a determinant of aspects of perceptual development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Bushnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Boudreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Child Development</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="1005" to="1021" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Being There -Putting Brain, Body and World Together Again</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Co-evolution of Pursuit and Evasion II: Simulation Methods and Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>In</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-A</forename><surname>Mataric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meyer</surname></persName>
		</author>
		<title level="m">From Animals to Animats 4 -Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior</title>
		<editor>J. Pollack &amp; S. Wilson</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="506" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Getting to know each other -Artificial social intelligence for autonomous robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dautenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="333" to="356" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Emergent Hierarchical Control Structures: Learning Reactive Hierarchical Relationships in Reinforcement Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Digney</surname></persName>
		</author>
		<editor>P. Maes, M. Mataric, J.-A. Meyer, J. Pollack &amp; S</editor>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilson</surname></persName>
		</author>
		<title level="m">From Animals to Animats 4 -Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="363" to="372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Neural Networks and a New Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dorffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>International Thomson Computer Press</publisher>
			<pubPlace>London, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Radical connectionism -a neural bottom-up approach to AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dorffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks and a New Artificial Intelligence</title>
		<editor>G. Dorffner</editor>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>International Thomson Computer Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="93" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Finding Structure in Time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Elman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="179" to="192" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evolution of Homing Navigation in a Real Mobile Robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mondada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Artificial Minds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franklin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graesser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Third International Workshop on Agent Theories, Architectures, and Languages</title>
		<meeting>Third International Workshop on Agent Theories, Architectures, and Languages<address><addrLine>Berlin/Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Computer Evolution of Buildable Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Funes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth European Conference on Artificial Life</title>
		<meeting>the Fourth European Conference on Artificial Life<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="358" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Software Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Genesereth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Ketchpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="48" to="53" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Toward a Noncomputational Cognitive Neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Globus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="299" to="310" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The Symbol Grounding Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harnad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="335" to="346" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evolutionary Robotics: the Sussex Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Husbands</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jakobi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="205" to="224" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Catching Ourselves in the Act -Situated Activity, Interactive Emergence, Evolution, and Human Thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hendriks-Jansen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Adaptation in natural and artificial systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>The University of Michigan Press</publisher>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Escaping brittleness: The possibilities of general purpose learning algorithms applied to parallel rule-based systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine learning: An Artificial Intelligence Approach -Volume II</title>
		<editor>R. S. Michalski, J. G. Carbonell &amp; T. M. Mitchell</editor>
		<meeting><address><addrLine>Los Altos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kauffmann</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="593" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adaptive mixtures of local experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="337" to="345" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The Body in the Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>University of Chicago Press</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modular and hierarchical learning systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Handbook of Brain Theory and Neural Networks</title>
		<editor>M. Arbib</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="579" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Reinforcement Learning: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="237" to="285" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Connectionist Ideas and Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="59" to="74" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Evolution and development of control architectures in animats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kodjabachian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-A</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="161" to="182" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Evolution and Development of Modular Control Architectures for 1-D Locomotion in Six-Legged Animats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kodjabachian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-A</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>special issue on BioRobotics</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Exploring the computational capabilities of recurrent neural networks (Doctoral dissertation)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kolen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
		<respStmt>
			<orgName>The Ohio State University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Artificial Life</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Langton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Life</title>
		<editor>Langton, C. G.</editor>
		<meeting><address><addrLine>Reading, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Addison-Wesley</publisher>
			<date type="published" when="1989" />
			<biblScope unit="page" from="1" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Evolving Robot Morphology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hallam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Fourth International Conference on Evolutionary Computation</title>
		<meeting>IEEE Fourth International Conference on Evolutionary Computation</meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Evolving and Breeding Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">&amp;amp;</forename><forename type="middle">O</forename><surname>Miglino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First European Workshop on Evolutionary Robotics</title>
		<meeting>the First European Workshop on Evolutionary Robotics<address><addrLine>Berlin/Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Behavior-Based Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Fifteenth Annual Meeting of the Cognitive Science Society<address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="74" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Agents that Reduce Work and Information Overload</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The ALIVE System: Wireless, Full-body, Interaction with Autonomous Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Blumberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Multimedia Systems, special issue on New Horizons of Commercial and Industrial AI</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mataric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-A</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pollack</surname></persName>
		</author>
		<title level="m">From Animals to Animats 4 -Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior</title>
		<editor>B. &amp; Wilson, S. W.</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Behavior-Oriented Approaches to Cognition: Theoretical Perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Mallot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory in Biosciences</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="196" to="220" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Autopoiesis and cognition: The realization of the living</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Varela</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Reidel</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The Tree of Knowledge: The biological roots of human understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Varela</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>New Science Library</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Intelligent Behavior in Animals and Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>B?sser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A Brief History of Connectionism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Medler</surname></persName>
		</author>
		<ptr target="http://www.icsi.berkeley.edu/?jagota/NCS" />
	</analytic>
	<monogr>
		<title level="j">Neural Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="101" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">An Incremental Approach to Developing Intelligent Neural Network Controllers for Robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Meeden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="page">26</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Emergence of control and planning in an autonomous vehicle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Meeden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mcgraw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Fifteenth Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="735" to="740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nj: Lawrence</forename><surname>Hillsdale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Erlbaum</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">From SAB90 to SAB94: Four Years of Animat Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-A</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guillot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Animals to Animats -Proceedings of the Third International Conference on Simulation of Adaptive Behavior</title>
		<editor>D. Cliff, P. Husbands, J.-A. Meyer &amp; S. W. Wilson</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">An Artificial Life Approach for the Synthesis of Autonomous Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Michel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Evolution -AE95 -Selected Papers</title>
		<editor>J.-M. Alliot, E. Lutton, E.. Ronald, M. Schoenauer, D. Snyers</editor>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berlin/Heidelberg</surname></persName>
		</author>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<pubPlace>Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">An Introduction to Genetic Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Experiments in Competence Acquisition for Autonomous Mobile Robots (Doctoral dissertation)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Nehmzow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Physical Symbol Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="135" to="183" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">The Knowledge Level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="87" to="127" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Computer science as empirical inquiry: Symbols and search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="113" to="126" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Using emergent modularity to develop control systems for mobile robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">special issue on Environment Structure and Behavior</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="343" to="363" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note>Adaptive Behavior</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Evolving non-trivial behavior on autonomous robots: Adaptation is more powerful than decomposition and integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
		<editor>T. Gomi</editor>
		<imprint>
			<date type="published" when="1997" />
			<publisher>AAI Books</publisher>
			<pubPlace>Ottawa, Canada</pubPlace>
		</imprint>
	</monogr>
	<note>Evolutionary Robotics?97Robotics?97 -From Intelligent Robotics to Artificial Life</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Evolutionary Robotics -Exploiting the full power of self-organization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">special issue on BioRobotics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>Connection Science</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">How to evolve autonomous robots: Different approaches in evolutionary robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Miglino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mondada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Artificial Life IV Conference</title>
		<meeting>the Artificial Life IV Conference<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Learning to Adapt to Changing Environments in Evolving Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="98" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Cognition -perspectives from autonomous agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pfeifer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="47" to="70" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Understanding Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pfeifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">The Challenge of Autonomous Agents: Pitfalls and How to Avoid Them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pfeifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Verschure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Artificial Life Route to Artificial Intelligence: Building Embodied, Situated Agents</title>
		<editor>L. Steels, L. &amp; R. A. Brooks</editor>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">The origins of intelligence in children</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Piaget</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1952" />
			<publisher>International Universities Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">The induction of dynamical recognizers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="227" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Neural Network Perception for Mobile Robot Guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Pomerleau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Kluwer</publisher>
			<pubPlace>Dordrecht, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Mind as Motion: Explorations in the Dynamics of Cognition</title>
		<editor>Port, R. F. &amp; van Gelder, T.</editor>
		<imprint>
			<date type="published" when="1995" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Evolutionsstrategie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rechenberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<publisher>Frommann-Holzboog</publisher>
			<pubPlace>Stuttgart, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Parallel Distributed Processing: Explorations in the Microstructure of Cognition</title>
	</analytic>
	<monogr>
		<title level="j">Foundations. Cambridge</title>
		<editor>Rumelhart, J. McClelland &amp; the PDP Group</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1986" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Learning internal representations by error propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Parallel Distributed Processing: Explorations in the Microstructure of Cognition</title>
		<editor>D. E. Rumelhart, J. McClelland &amp; the PDP Group</editor>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="318" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Scaling up sensorimotor systems: Constraints from human infancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Rutkowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="349" to="373" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Reassessing Piaget&apos;s Theory of Sensorimotor Intelligence: A View from Cognitive Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Rutkowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Infant Development: Recent Advances</title>
		<editor>Bremner, J. G.</editor>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Connectionist Learning in Behaviour-Based Mobile Robots: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rylatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Routen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Review</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">The importance of leaky levels for behavior-based AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kolen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Pollack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Animals to AnimatsProceedings of the Third International Conference on Simulation of Adaptive Behavior</title>
		<editor>D. Cliff, P. Husbands, J.-A. Meyer &amp; S. W. Wilson</editor>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Dynamics of behavior: Theory and applications for autonomous robot architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sch?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Engels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="213" to="245" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Minds, brains and programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Searle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="417" to="457" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">The Neural Mind and the Robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Sharkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N H</forename><surname>Heemskerk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Network Perspectives on Cognition and Adaptive Robotics</title>
		<editor>A. J. Browne</editor>
		<meeting><address><addrLine>Bristol, UK</addrLine></address></meeting>
		<imprint>
			<publisher>IOP Publishing</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="169" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Training Artificial Neural Networks for Robot Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Sharkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N H</forename><surname>Heemskerk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Solving Engineering Problems with Neural Networks</title>
		<editor>A. Bulsari, S. Kallio &amp; D. Tsaptsinos</editor>
		<meeting><address><addrLine>Turku, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>Systems Engineering Association</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="190" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Evolving 3D Morphology and Behavior by Competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life Proceedings</title>
		<imprint>
			<date type="published" when="1994" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">The Artificial Life Roots of Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="75" to="100" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">When are robots intelligent autonomous agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Steels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="3" to="9" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Dynamical Systems for the Behavioral Organization of an Anthropomorphic Mobile Robot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Steinhage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bergener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Simulation of Adaptive Behavior</title>
		<meeting>the Fifth International Conference on Simulation of Adaptive Behavior<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title level="m" type="main">Plans and situated action -The problem of human-machine interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Suchman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Reinforcement Learning Architectures for Animats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Animals to Animats -Proceedings of the First International Conference on the Simulation of Adaptive Behavior</title>
		<editor>J.-A. Meyer &amp; S. W. Wilson</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="288" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Model-Based Learning for Mobile Robot Navigation from the Dynamical Systems Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
				<title level="m">Proceedings of the 1996 IROS Workshop &apos;Towards Real Autonomy</title>
		<editor>Tani, J. &amp; Asada, M.</editor>
		<meeting>the 1996 IROS Workshop &apos;Towards Real Autonomy<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Learning to Perceive the World as Articulated: An Approach for Hierarchical Learning in Sensory-Motor Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nolfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Simulation of Adaptive Behavior</title>
		<meeting>the Fifth International Conference on Simulation of Adaptive Behavior<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Autonomous Vacuum Cleaner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ulrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mondada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-D</forename><surname>Nicoud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Robotics and Autonomous Systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="233" to="245" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Incremental Robot Shaping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urzelai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Floreano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Colombetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>special issue on BioRobotics</note>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">On growing intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vaario</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ohsuga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks and a New Artificial Intelligence</title>
		<editor>G. Dorffner</editor>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>International Thomson Computer Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="189" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">What might cognition be if not computation?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Gelder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="345" to="381" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">The Embodied Mind -Cognitive Science and Human Experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Varela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Knowledge growth in an artificial animal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Genetic Algorithms and Their Applications</title>
		<meeting>the First International Conference on Genetic Algorithms and Their Applications<address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1985" />
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">The Animat Path to AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Animals to Animats -Proceedings of the First International Conference on Simulation of Adaptive Behavior</title>
		<editor>J.-A. Meyer &amp; S. W. Wilson</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1991" />
			<biblScope unit="page" from="15" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Intelligent Agents: Theory and Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Woolridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Jennings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge Engineering Review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Towards Adaptive Behaviour System Integration using Connectionist Infinite State Automata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ziemke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">From Animals to Animats 4 -Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior</title>
		<editor>P. Maes, M. Mataric, J.-A. Meyer, J. Pollack &amp; S. Wilson</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="145" to="154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Towards Autonomous Robot Control via Self-Adapting Recurrent Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ziemke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks -ICANN 96</title>
		<editor>C. von der Malsburg, W. von Seelen, J. C. Vorbr? ggen &amp; B. Sendhoff</editor>
		<meeting><address><addrLine>Berlin/Heidelberg; Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="611" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Towards Adaptive Perception in Autonomous Robots using Second-Order Recurrent Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ziemke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Euromicro Workshop on Advanced Mobile Robots</title>
		<meeting>the First Euromicro Workshop on Advanced Mobile Robots</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Rethinking Grounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ziemke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Does Representation Need Reality? Proceedings of the International Conference &apos;New Trends in Cognitive Science&apos;</title>
		<editor>A. Riegler &amp; M. Peschl</editor>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<analytic>
		<title/>
		<idno>97-01</idno>
	</analytic>
	<monogr>
		<title level="j">ASoCS</title>
		<imprint>
			<publisher>Austrian Society of Cognitive Science</publisher>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b118">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Special Issue on BioRobotics</title>
		<editor>Ziemke, T. &amp; Sharkey, N. E.</editor>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>Connection Science</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
