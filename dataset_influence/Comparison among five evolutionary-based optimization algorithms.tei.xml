<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-16T23:50+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparison among five evolutionary-based optimization algorithms</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Elsevier BV</publisher>
				<availability status="unknown"><p>Copyright Elsevier BV</p>
				</availability>
				<date type="published" when="2005">2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emad</forename><surname>Elbeltagi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarek</forename><surname>Hegazy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Grierson</surname></persName>
						</author>
						<title level="a" type="main">Comparison among five evolutionary-based optimization algorithms</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Advanced Engineering Informatics</title>
						<title level="j" type="abbrev">Advanced Engineering Informatics</title>
						<idno type="ISSN">1474-0346</idno>
						<imprint>
							<publisher>Elsevier BV</publisher>
							<biblScope unit="volume">19</biblScope>
							<biblScope unit="issue">1</biblScope>
							<biblScope unit="page" from="43" to="53"/>
							<date type="published" when="2005">2005</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.aei.2005.01.004</idno>
					<note type="submission">Received 15 October 2004; revised 9 January 2005; accepted 19 January 2005</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Evolutionary algorithms</term>
					<term>Genetic algorithms</term>
					<term>Memetic algorithms</term>
					<term>Particle swarm</term>
					<term>Ant colony</term>
					<term>Shuffled frog leaping</term>
					<term>Optimization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Evolutionary algorithms (EAs) are stochastic search methods that mimic the natural biological evolution and/or the social behavior of species. Such algorithms have been developed to arrive at near-optimum solutions to large-scale optimization problems, for which traditional mathematical techniques may fail. This paper compares the formulation and results of five recent evolutionary-based algorithms: genetic algorithms, memetic algorithms, particle swarm, ant-colony systems, and shuffled frog leaping. A brief description of each algorithm is presented along with a pseudocode to facilitate the implementation and use of such algorithms by researchers and practitioners. Benchmark comparisons among the algorithms are presented for both continuous and discrete optimization problems, in terms of processing time, convergence speed, and quality of the results. Based on this comparative analysis, the performance of EAs is discussed along with some guidelines for determining the best operators for each algorithm. The study presents sophisticated ideas in a simplified form that should be beneficial to both practitioners and researchers involved in solving optimization problems. q</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The difficulties associated with using mathematical optimization on large-scale engineering problems have contributed to the development of alternative solutions. Linear programming and dynamic programming techniques, for example, often fail (or reach local optimum) in solving NP-hard problems with large number of variables and non-linear objective functions <ref type="bibr" target="#b0">[1]</ref>. To overcome these problems, researchers have proposed evolutionary-based algorithms for searching near-optimum solutions to problems.</p><p>Evolutionary algorithms (EAs) are stochastic search methods that mimic the metaphor of natural biological evolution and/or the social behavior of species. Examples include how ants find the shortest route to a source of food and how birds find their destination during migration. The behavior of such species is guided by learning, adaptation, and evolution <ref type="bibr" target="#b0">[1]</ref>. To mimic the efficient behavior of these species, various researchers have developed computational systems that seek fast and robust solutions to complex optimization problems. The first evolutionary-based technique introduced in the literature was the genetic algorithms (GAs) <ref type="bibr" target="#b1">[2]</ref>. GAs were developed based on the Darwinian principle of the 'survival of the fittest' and the natural process of evolution through reproduction. Based on its demonstrated ability to reach near-optimum solutions to large problems, the GAs technique has been used in many applications in science and engineering <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. Despite their benefits, GAs may require long processing time for a nearoptimum solution to evolve. Also, not all problems lend themselves well to a solution with GAs <ref type="bibr" target="#b5">[6]</ref>.</p><p>In an attempt to reduce processing time and improve the quality of solutions, particularly to avoid being trapped in local optima, other EAs have been introduced during the past 10 years. In addition to various GA improvements, recent developments in EAs include four other techniques inspired by different natural processes: memetic algorithms (MAs) <ref type="bibr" target="#b6">[7]</ref>, particle swarm optimization (PSO) <ref type="bibr" target="#b7">[8]</ref>, antcolony systems <ref type="bibr" target="#b8">[9]</ref>, and shuffled frog leaping (SFL) <ref type="bibr" target="#b9">[10]</ref>. A schematic diagram of the natural processes that the five algorithms mimic is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>In this paper, the five EAs presented in <ref type="figure" target="#fig_0">Fig. 1</ref> are reviewed and a pseudocode for each algorithm is presented to facilitate its implementation. Performance comparison among the five algorithms is then presented. Guidelines are then presented for determining the proper parameters to use with each algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Five evolutionary algorithms</head><p>In general, EAs share a common approach for their application to a given problem. The problem first requires some representation to suit each method. Then, the evolutionary search algorithm is applied iteratively to arrive at a near-optimum solution. A brief description of the five algorithms is presented in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Genetic algorithms</head><p>GAs are inspired by biological systems' improved fitness through evolution <ref type="bibr" target="#b1">[2]</ref>. A solution to a given problem is represented in the form of a string, called 'chromosome', consisting of a set of elements, called 'genes', that hold a set of values for the optimization variables <ref type="bibr" target="#b10">[11]</ref>.</p><p>GAs work with a random population of solutions (chromosomes). The fitness of each chromosome is determined by evaluating it against an objective function. To simulate the natural survival of the fittest process, best chromosomes exchange information (through crossover or mutation) to produce offspring chromosomes. The offspring solutions are then evaluated and used to evolve the population if they provide better solutions than weak population members. Usually, the process is continued for a large number of generations to obtain a best-fit (nearoptimum) solution. More details on the mechanism of GAs can be found in Goldberg <ref type="bibr" target="#b10">[11]</ref> and Al-Tabtabai and Alex <ref type="bibr" target="#b2">[3]</ref>.</p><p>A pseudocode for the GAs algorithm is shown in Appendix A. Four main parameters affect the performance of GAs: population size, number of generations, crossover rate, and mutation rate. Larger population size (i.e. hundreds of chromosomes) and large number of generations (thousands) increase the likelihood of obtaining a global optimum solution, but substantially increase processing time.</p><p>Crossover among parent chromosomes is a common natural process <ref type="bibr" target="#b11">[12]</ref> and traditionally is given a rate that ranges from 0.6 to 1.0. In crossover, the exchange of parents' information produces an offspring, as shown in <ref type="figure">Fig. 2</ref>. As opposed to crossover, mutation is a rare process that resembles a sudden change to an offspring. This can be done by randomly selecting one chromosome from the population and then arbitrarily changing some of its information. The benefit of mutation is that it randomly introduces new genetic material to the evolutionary process, perhaps thereby avoiding stagnation around local minima. A small mutation rate less than 0.1 is usually used <ref type="bibr" target="#b10">[11]</ref>.</p><p>The GA used in this study is steady state (an offspring replaces the worst chromosome only if is better than it) and real coded (the variables are represented in real numbers). The main parameters used in the GA procedure are population size, number of generations, crossover rate and mutation rate.</p><p>The number of swaps and consequently the size of the neighborhood grow quadratically with the chromosome length (problem variables). In order to reduce processing time, <ref type="bibr">Merz and Freisleben [14]</ref> suggested stopping the pairwise interchange after performing the first swap that enhances the objective function of the current chromosome. The local-search algorithm, however, can be designed to suit the problem nature. For example, another local search can be conducted by adding or subtracting an incremental value from every gene and testing the chromosome's performance. The change is kept if the chromosome's performance improves; otherwise, the change is ignored. A pseudocode of this modified local search is given in Appendix C. As discussed, the parameters involved in MAs are the same four parameters used in GAs: population size, number of generations, crossover rate, and mutation rate in addition to a local-search mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Particle swarm optimization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Memetic algorithms</head><p>MAs are inspired by Dawkins' notion of a meme <ref type="bibr" target="#b12">[13]</ref>. MAs are similar to GAs but the elements that form a chromosome are called memes, not genes. The unique aspect of the MAs algorithm is that all chromosomes and offsprings are allowed to gain some experience, through a local search, before being involved in the evolutionary process <ref type="bibr" target="#b13">[14]</ref>. As such, the term MAs is used to describe GAs that heavily use local search <ref type="bibr" target="#b14">[15]</ref>. A pseudocode for a MA procedure is given in Appendix B.</p><p>Similar to the GAs, an initial population is created at random. Afterwards, a local search is performed on each population member to improve its experience and thus obtain a population of local optimum solutions. Then, crossover and mutation operators are applied, similar to GAs, to produce offsprings. These offsprings are then subjected to the local search so that local optimality is always maintained.</p><p>Merz and Freisleben <ref type="bibr" target="#b13">[14]</ref> proposed one approach to perform local search through a pair-wise interchange heuristic <ref type="figure" target="#fig_1">(Fig. 3)</ref>. In this method, the local-search neighborhood is defined as the set of all solutions that can be reached from the current solution by swapping two elements (memes) in the chromosome. For a chromosome of length n, the neighborhood size for the local search i:</p><formula xml:id="formula_0">N Z 1=2 !n !?n K 1? (1)</formula><p>PSO was developed by Kennedy and Eberhart <ref type="bibr" target="#b7">[8]</ref>. The PSO is inspired by the social behavior of a flock of migrating birds trying to reach an unknown destination. In PSO, each solution is a 'bird' in the flock and is referred to as a 'particle'. A particle is analogous to a chromosome (population member) in GAs. As opposed to GAs, the evolutionary process in the PSO does not create new birds from parent ones. Rather, the birds in the population only evolve their social behavior and accordingly their movement towards a destination <ref type="bibr" target="#b15">[16]</ref>.</p><p>Physically, this mimics a flock of birds that communicate together as they fly. Each bird looks in a specific direction, and then when communicating together, they identify the bird that is in the best location. Accordingly, each bird speeds towards the best bird using a velocity that depends on its current position. Each bird, then, investigates the search space from its new local position, and the process repeats until the flock reaches a desired destination. It is important to note that the process involves both social interaction and intelligence so that birds learn from their own experience (local search) and also from the experience of others around them (global search).</p><p>The pseudocode for the PSO is shown in Appendix D. The process is initialized with a group of random particles (solutions), N. The ith particle is represented by its position as a point in a S-dimensional space, where S is the number of variables. Throughout the process, each particle i monitors three values: its current position (X i ); the best position it reached in previous cycles (P i ); its flying velocity (V i ).</p><p>These three values are represented as follows:</p><formula xml:id="formula_1">Current position X i Z ?x i1 ; x i2 ; .; x iS ? Best previous position P i Z ?p i1 ; p i2 ; .; p iS ? 9 &gt; = &gt; ;<label>(2)</label></formula><p>Flying velocity</p><formula xml:id="formula_2">V i Z ?v i1 ; v i2 ; .; v iS ?</formula><p>In each time interval (cycle), the position (P g ) of the best particle (g) is calculated as the best fitness of all particles. Accordingly, each particle updates its velocity V i to catch up with the best particle g, as follows <ref type="bibr" target="#b15">[16]</ref>:</p><formula xml:id="formula_3">New V i Z u !current V i C c 1 !rand? ?!?P i K X i ? C c 2 !Rand? ?!?P g K X i ?<label>(3)</label></formula><p>As such, using the new velocity V i , the particle's updated position becomes:</p><formula xml:id="formula_4">New position X i Z current position X i C New V i ; (4) V max R V i RKV max</formula><p>where c 1 and c 2 are two positive constants named learning factors (usually c 1 Zc 2 Z2); rand( ) and Rand( ) are two random functions in the range <ref type="bibr">[0,</ref><ref type="bibr" target="#b0">1]</ref>, V max is an upper limit on the maximum change of particle velocity <ref type="bibr" target="#b7">[8]</ref>, and u is an inertia weight employed as an improvement proposed by Shi and Eberhart <ref type="bibr" target="#b15">[16]</ref> to control the impact of the previous history of velocities on the current velocity. The operator u plays the role of balancing the global search and the local search; and was proposed to decrease linearly with time from a value of 1.4-0.5 <ref type="bibr" target="#b15">[16]</ref>. As such, global search starts with a large weight and then decreases with time to favor local search over global search <ref type="bibr" target="#b16">[17]</ref>.</p><p>It is noted that the second term in Eq. (3) represents cognition, or the private thinking of the particle when comparing its current position to its own best. The third term in Eq. <ref type="formula" target="#formula_3">(3)</ref>, on the other hand, represents the social collaboration among the particles, which compares a particle's current position to that of the best particle <ref type="bibr" target="#b17">[18]</ref>. Also, to control the change of particles' velocities, upper and lower bounds for velocity change is limited to a user-specified value of V max . Once the new position of a particle is calculated using Eq. (4), the particle, then, flies towards it <ref type="bibr" target="#b15">[16]</ref>. As such, the main parameters used in the PSO technique are: the population size (number of birds); number of generation cycles; the maximum change of a particle velocity V max ; and u. pheromone trails, which ants deposit whenever they travel, as a form of indirect communication.</p><p>As shown in <ref type="figure" target="#fig_0">Fig. 1d</ref>, when ants leave their nest to search for a food source, they randomly rotate around an obstacle, and initially the pheromone deposits will be the same for the right and left directions. When the ants in the shorter direction find a food source, they carry the food and start returning back, following their pheromone trails, and still depositing more pheromone. As indicated in <ref type="figure" target="#fig_0">Fig. 1d</ref>, an ant will most likely choose the shortest path when returning back to the nest with food as this path will have the most deposited pheromone. For the same reason, new ants that later starts out from the nest to find food will also choose the shortest path. Over time, this positive feedback (autocatalytic) process prompts all ants to choose the shorter path <ref type="bibr" target="#b18">[19]</ref>.</p><p>Implementing the ACO for a certain problem requires a representation of S variables for each ant, with each variable i has a set of n i options with their values l ij , and their associated pheromone concentrations {t ij }; where iZ1, 2, ., S, and jZ1, 2, ., n i . As such, an ant is consisted of S values that describe the path chosen by the ant as shown in <ref type="figure" target="#fig_2">Fig. 4</ref>  <ref type="bibr" target="#b19">[20]</ref>. A pseudocode for the ACO is shown in Appendix E. Other researchers use a variation of this general algorithm, incorporating a local search to improve the solution <ref type="bibr" target="#b20">[21]</ref>.</p><p>In the ACO, the process starts by generating m random ants (solutions). An ant k (kZ1, 2,., m) represents a solution string, with a selected value for each variable. Each ant is then evaluated according to an objective function. Accordingly, pheromone concentration associated with each possible route (variable value) is changed in a way to reinforce good solutions, as follows <ref type="bibr" target="#b8">[9]</ref>:</p><formula xml:id="formula_5">t ij ?t? Z rt ij ?t K 1? C Dt ij ; t Z 1; 2; .; T (5)</formula><p>where T is the number of iterations (generation cycles); t ij (t) is the revised concentration of pheromone associated with option l ij at iteration t, t ij (tK1) is the concentration of pheromone at the previous iteration (tK1); Dt ij Zchange in pheromone concentration; and rZpheromone evaporation rate (0-1). The reason for allowing pheromone evaporation is to avoid too strong influence of the old pheromone to avoid premature solution stagnation <ref type="bibr" target="#b21">[22]</ref>. In Eq. (5), the change in</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Ant-colony optimization</head><p>Similar to PSO, ant-colony optimization (ACO) algorithms evolve not in their genetics but in their social behavior. ACO was developed by Dorigo et al. <ref type="bibr" target="#b8">[9]</ref> based on the fact that ants are able to find the shortest route between their nest and a source of food. This is done using pheromone concentration Dt ij is calculated as <ref type="bibr" target="#b8">[9]</ref>:</p><formula xml:id="formula_6">( Dt ij Z X m R=fitness k if option l ij is chosen by ant k kZ1 0 otherwise (6)</formula><p>where R is a constant called the pheromone reward factor; and fitness k is the value of the objective function (solution performance) calculated for ant k. It is noted that the amount of pheromone gets higher as the solution improves. Therefore, for minimization problems, Eq. <ref type="formula">(6)</ref> shows the pheromone change as proportional to the inverse of the fitness. In maximization problems, on the other hand, the fitness value itself can be directly used.</p><p>Once the pheromone is updated after an iteration, the next iteration starts by changing the ants' paths (i.e. associated variable values) in a manner that respects pheromone concentration and also some heuristic preference. As such, an ant k at iteration t will change the value for each variable according to the following probability <ref type="bibr" target="#b8">[9]</ref>:</p><p>For S-dimensional problems (S variables), a frog i is represented as X i Z(x i1 , x i2 ,., x iS ). Afterwards, the frogs are sorted in a descending order according to their fitness. Then, the entire population is divided into m memeplexes, each containing n frogs (i.e. PZm!n). In this process, the first frog goes to the first memeplex, the second frog goes to the second memeplex, frog m goes to the mth memeplex, and frog mC1 goes back to the first memeplex, etc.</p><p>Within each memeplex, the frogs with the best and the worst fitnesses are identified as X b and X w , respectively. Also, the frog with the global best fitness is identified as X g . Then, a process similar to PSO is applied to improve only the frog with the worst fitness (not all frogs) in each cycle. Accordingly, the position of the frog with the worst fitness is adjusted as follows:</p><formula xml:id="formula_7">Change in frog position ?D i ? Z rand? ?!?X b K X w ? (8) New position X w Z current position X w C D i ; D max R D i RKD max (9) a b P ij ?k; t? Z ?t ij ?t?? !?h ij ? P l ij ?t ij ?t?? a (7) !?h ij ? b</formula><p>where P ij (k, t)Zprobability that option l ij is chosen by ant k for variable i at iteration t; t ij (t)Zpheromone concentration associated with option l ij at iteration t; h ij Zheuristic factor for preferring among available options and is an indicator of how good it is for ant k to select option l ij (this heuristic factor is generated by some problem characteristics and its value is fixed for each option l ij ); and a and b are exponent parameters that control the relative importance of pheromone concentration versus the heuristic factor <ref type="bibr" target="#b19">[20]</ref>. Both a and b can take values greater than zero and can be determined by trial and error. Based on the previous discussion, the main parameters involved in ACO are: number of ants m; number of iterations t; exponents a and b; pheromone evaporation rate r; and pheromone reward factor R.</p><p>where rand( ) is a random number between 0 and 1; and D max is the maximum allowed change in a frog's position. If this process produces a better solution, it replaces the worst frog. Otherwise, the calculations in Eqs. <ref type="formula">(8)</ref> and <ref type="formula">(9)</ref> are repeated but with respect to the global best frog (i.e. X g replaces X b ). If no improvement becomes possible in this case, then a new solution is randomly generated to replace that frog. The calculations then continue for a specific number of iterations <ref type="bibr" target="#b9">[10]</ref>. Accordingly, the main parameters of SFL are: number of frogs P; number of memeplexes; number of generation for each memeplex before shuffling; number of shuffling iterations; and maximum step size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Comparison among evolutionary algorithms' results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Shuffled frog leaping algorithm</head><p>The SFL algorithm, in essence, combines the benefits of the genetic-based MAs and the social behavior-based PSO algorithms. In the SFL, the population consists of a set of frogs (solutions) that is partitioned into subsets referred to as memeplexes. The different memeplexes are considered as different cultures of frogs, each performing a local search. Within each memeplex, the individual frogs hold ideas, that can be influenced by the ideas of other frogs, and evolve through a process of memetic evolution. After a defined number of memetic evolution steps, ideas are passed among memeplexes in a shuffling process <ref type="bibr" target="#b22">[23]</ref>. The local search and the shuffling processes continue until defined convergence criteria are satisfied <ref type="bibr" target="#b9">[10]</ref>.</p><p>As described in the pseudocode of Appendix F, an initial population of P frogs is created randomly.</p><p>All the EAs described earlier have been coded using the Visual Basic programming language and all experiments took place on a 1.8 GHz AMD Laptop machine. The performance of the five EAs is compared using two benchmark problems for continuous optimization and a third problem for discrete optimization. A description of these test problems is given in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Continuous optimization</head><p>Two well-known continuous optimization problems are used to test four of the EAs: F8 (Griewank's) function and the F10 function. Details of these functions are as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">F8 (Griewank's function)</head><p>The objective function to be optimized is a scalable, nonlinear, and non-separable function that may take any number of variables (x i s), i.e.</p><formula xml:id="formula_8">f ?x ijiZ1;N ? Z 1 C X N x 2 i Y N 4000 K ?cos?x i = ffi ffi i p ?? (10) iZ1 iZ1</formula><p>Similar to the F8 function, the global optimum solution for this function is known to be zero when all N variables equal zero, for the variable values ranging from K100 to 100.</p><p>The summation term of the F8 function (Eq. <ref type="formula">(10)</ref>) includes a parabolic shape while the cosine function in the product term creates waves over the parabolic surface. These waves create local optima over the solution space <ref type="bibr" target="#b23">[24]</ref>. The F8 function can be scaled to any number of variables N. The values of each variable are constrained to a range (K512 to 511). The global optimum (minimum) solution for this function is known to be zero when all N variables equal zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Discrete optimization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">F10 function</head><p>This function is non-linear, non-separable, and involves two variables x and y, i.e.</p><formula xml:id="formula_9">f 10?x; y? Z ?x 2 C y 2 ? 0:25 ?sin 2 ?50?x 2 C y 2 ? 0:1 ? C 1?<label>(11)</label></formula><p>To scale this function (Eq. <ref type="formula" target="#formula_9">(11)</ref>) to any number of variables, an extended EF10 function is created using the following relation, <ref type="bibr" target="#b23">[24]</ref>,</p><formula xml:id="formula_10">EF?x ijiZN ? Z X N X N F?x i ; x j ? (12) jZ1 iZ1</formula><p>Accordingly, the extended F10 function is:</p><formula xml:id="formula_11">EF10?x ijiZ1;N ? NK1 Z X ?x 2 2 2 2 i C x iC1 ? 0:25 ?sin 2 ?50?x i C x iC1 ? 0:1 ? C 1? (13) iZ1</formula><p>In this section, a time-cost trade-off (TCT) construction management problem is used to compare among the five EAs with respect to their ability to solve discrete optimization problems. The problem relates to an 18-activity construction project that was described in Ref. <ref type="bibr" target="#b24">[25]</ref>. The activities, their predecessors, and durations are presented in <ref type="table" target="#tab_0">Table 1</ref> along with five optional methods of construction that vary from cheap and slow (option 5) to fast and expensive (option 1). The 18 activities were input to a project management software (Microsoft Project) with activity durations being set to those of option 5 (least costs and longest durations among the five options). The total direct cost of the project in this case is $99,740 (sum of all activities' costs for option 5) with the project duration being 169 days (respecting the precedence relations in <ref type="table" target="#tab_0">Table 1</ref>). The indirect cost of $500/day was then added to obtain a total project cost of $184,240.</p><p>With the initial schedule exceeding a desired deadline of 110-days, it is required to search for the optimum set of construction options that meet the deadline at minimum total cost. In this problem, the decision variables are the different methods of construction possible for each activity (i.e. five discrete options, 1-5, with associated durations and costs). The objective function is to minimize the total project cost (direct and indirect) and is formulated  <ref type="table" target="#tab_0">- 13  3  14  4000  18  3200  24  1800  - - - - 14  4, 10  9  3000  15  2400  18  2200  - - - - 15  12  12  4500  16  3500  - - - - - - 16  13, 14  20  3000  22  2000  24  1750  28  1500  30  1000  17  11, 14, 15 14  4000  18  3200  24  1800  - - - - 18  16, 17  9  3000  15  2400  18  2200  - - - -</ref>as follows:</p><formula xml:id="formula_12">! Min T !I C X n C ij (14) iZ1</formula><p>where nZnumber of activities; C ij Zdirect cost of activity i using its method of construction j; TZtotal project duration; and IZdaily indirect cost. To facilitate the optimization using the different EAs, macro programs of the 5 EAs were written using the VBA language that comes with the Microsoft Project software. The data in <ref type="table" target="#tab_0">Table 1</ref> were stored in one of the tables associated with the software. When any one of the EA routines is activated, the evolutionary process selects one of the five construction options to set the activities' durations and costs. Accordingly, the project's total cost (objective function) and duration changes. The evolutionary process then continues to attempt to optimize the objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Particle swarm optimization</head><p>Upon experimentation, the suitable numbers of particles and generations were found to be 40 and 10,000, respectively. Also, the maximum velocity was set as 20 for the continuous problems and 2 for the discrete problem. The inertia weight factor u was also set as a time-variant linear function decreasing with the increase of number of generations where, at any generation i, u Z 0:4 C 0:8 !?number of generations K i?= ?number of generations K 1? ? 15? such that uZ1.2 and 0.4 at the first and last generation, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Parameter settings for evolutionary algorithms</head><p>As discussed earlier, each algorithm has its own parameters that affect its performance in terms of solution quality and processing time. To obtain the most suitable parameter values that suit the test problems, a large number of experiments were conducted. For each algorithm, an initial setting of the parameters was established using values previously reported in the literature <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b19">20]</ref>. Then, the parameter values were changed one by one and the results were monitored in terms of the solution quality and speed. The final parameter values adopted for each of the five EAs are given in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4.">Ant-colony optimization</head><p>As the ACO algorithm is suited to discrete problems alone, no experiments were done using it for the F8 and F10 test functions. However, the TCT discrete problem was used for experimentation with the ACO. After extensive experimentation, 30 ants and 100 iterations were found suitable. Also, the other parameters were set as follows: aZ 0.5; bZ2.5; r (pheromone evaporation rate)Z0.4; and R (reward factor depends on problem nature)Z10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.5.">Shuffled frog leaping</head><p>Different settings were experimented with to determine suitable values for parameters to solve the test problems using the SFL algorithm. A population of 200 frogs, 20 memeplexes, and 10 iterations per memeplex were found suitable to obtain good solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Results and discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Genetic algorithms</head><p>The crossover probability (C P ) and the mutation probability (M P ) were set to 0.8 and 0.08, respectively. The population size was set at 200 and 500 offsprings. The evolutionary process was kept running until no improvements were made in the objective function for 10 consecutive generation cycles (i.e. 500!10 offsprings) or the objective function reached its known target value, whichever comes first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Memetic algorithms</head><p>MAs are similar to GAs but apply local search on chromosomes and offsprings. The standard pair-wise interchange search does not suit the continuous functions F8 and F10, and the local-search procedure in Appendix C is used instead. For the discrete problem, on the other hand, the pair-wise interchange was used. The same values of C P Z0.8 and M P Z0.08 that were used for the GAs are applied to the MAs. After experimenting with various values, a population size of 100 chromosomes was used for the MAs.</p><p>The results found from solving the three test problems using the five EAs, which represents a fairly wide class of problems, are summarized in <ref type="table" target="#tab_1">Tables 2 and 3</ref>, and <ref type="figure" target="#fig_3">Fig. 5</ref> (the Y axis of <ref type="figure" target="#fig_3">Fig. 5</ref> is a log scale to show long computer run times). It is noted that the processing time for solving the EF10 function was similar to that of the F8 function and follows the same trend as shown in <ref type="figure" target="#fig_3">Fig. 5</ref>.</p><p>Twenty trial runs were performed for each problem. The performance of the different algorithms was compared using three criteria: (1) the percentage of success, as represented by the number of trials required for the objective function to reach its known target value; (2) the average value of the solution obtained in all trials; (3) the processing time to reach the optimum target value. The processing time, and not the number of generation cycles, was used to measure the speed of each EA, because the number of generations in each evolutionary cycle is different from one algorithm to another. In all experiments, the solution stopped when one of two following criteria was satisfied: (1) the F8 and EF10 objective functions reached a target value of 0.05 or less (i.e. to within an acceptable tolerance of the known optimum value of zero), or 110 days for the TCT problem;  or (2) the objective function value did not improve in ten consecutive generations. To experiment with different problem sizes, the F8 test function in Eq. (10) was solved using 10, 20, 50, and 100 variables, while the EF10 test function in Eq. (13) was solved using 10, 20, and 50 variables (it becomes too complex for larger numbers of variables). Surprisingly, the GA performed more poorly than all the other four algorithms. In fact, it was found to perform more poorly than even that reported in Whitley et al. <ref type="bibr" target="#b23">[24]</ref> and Raphael and Smith <ref type="bibr" target="#b25">[26]</ref> when using the CHC and Genitor GAs, while it performed better than the ESGAT GA version. A commercial GA package, Evolver <ref type="bibr" target="#b26">[27]</ref>, was used to verify the results. Evolver is an add-in program to Microsoft Excel, where the objective function, variables (adjustable cells), and the constraints are readily specified by highlighting the corresponding spreadsheet cells. Evolver performed almost the same way as the VB code with slight improvement. The results of using Evolver are reported in <ref type="table" target="#tab_1">Table 2</ref>. The difference in GA results than those reported in Refs. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref> may in part be because the GA utilized in this paper uses real rather than binary coding.</p><p>As shown in <ref type="table" target="#tab_1">Table 2</ref> for the F8 function, the GA was able to reach the target for 50% of the trials with 10 variables, and the number of successes decreased as the number of variables increased. Despite its inability to reach the optimum value of zero with the larger number of 100 variables, the GA was able to achieve a solution close to the optimum (0.432 for the F8 function with 100 variables). Also, it is noticed from <ref type="figure" target="#fig_3">Fig. 5</ref> that as the number of variables increased, the processing time to reach the target also increased (from 5 min:12 s with 10 variables to 40 min:27 s with 50 variables). As shown in <ref type="table" target="#tab_1">Table 2</ref> for the EF10 test function, the GA was only able to achieve 20% success using 10 variables, and that the solution quality decreased as the number of variables increased (e.g. the objective functionZ5.951 using 50 variables). Using the GA to solve the TCT problem, the minimum solution obtained was 113 days with a minimum total cost of $162,270 and the success rate for reaching the optimum solution was zero, as shown in <ref type="table" target="#tab_2">Table 3</ref>.</p><p>Upon applying the MA, the results improved significantly compared to those obtained using the GA, in terms of both the success rate <ref type="table" target="#tab_1">(Table 2</ref>) and the processing time <ref type="figure" target="#fig_3">(Fig. 5)</ref>. Solving the F8 function using 100 variables, for example, the success rate was 100% with a processing time of 7 min:08 s. Even for the trials with less success rate, as shown in <ref type="table" target="#tab_1">Table 2</ref>, the solutions were very close to the optimum. That is to say, the local search of the MA improved upon the performance of the GA. When applying the MA to the TCT problem, it was able to reach the optimum project duration of 110 days and a total cost of $161,270, with a 20% success rate and an average cost that improved upon that of the GA <ref type="table" target="#tab_2">(Table 3)</ref>. It is to be noted that the local-search module presented in Appendix C was applied for the F8 and EF8 functions, while the pair-wise interchange local-search module was applied to the TCT problem. The PSO algorithm outperformed the GA and the MA in solving the EF10 function in terms of the success rate <ref type="table" target="#tab_1">(Table 2)</ref>, the processing time <ref type="figure" target="#fig_3">(Fig. 5)</ref>, while it was less successful than the MA in solving the F8 function. Also, the PSO algorithm outperformed all other algorithms when used to solve the TCT problem, with a success rate of 60% and average total cost of $161,940, as shown in <ref type="table" target="#tab_2">Table 3</ref>.</p><p>The ACO algorithm was applied only to the TCT discrete optimization problem. While it was able to achieve the same success rate as the GA (20%), the average total cost of the 20 runs was greater than that of all other algorithms <ref type="table" target="#tab_2">(Table 3</ref>). This is due to the scattered nature of the obtained results (minimum duration of 110 days, and maximum duration of 139 days) caused by premature convergence that happened in some runs. To avoid premature convergence, the pair-wise interchange local-search module was applied and the results obtained were greatly improved with a success rate of 100%, but the average processing time increased from 10 to 48 s.</p><p>When solving the F8 and EF10 test functions using the SFL algorithm, it was found that the success rate <ref type="table" target="#tab_1">(Table 2)</ref> was better than the GA and similar to that for PSO. However, it performed less well when used to solve the EF10 function. As shown in <ref type="figure" target="#fig_3">Fig. 5</ref>, the SFL processing times were the least among all algorithms. Interestingly, it is noticed from <ref type="table" target="#tab_1">Table 2</ref> that as the number of variables increased for the F8 function, the success rates for SFL, MA and PSO all increased. This is because the F8 function becomes smoother as its dimensions increase <ref type="bibr" target="#b23">[24]</ref>. As opposed to this trend, the success rate decreased for the GA as the number of variables increased. The same trend for the GA was also reported in Refs. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref> when used to solve the F8 function. Also, using the SFL algorithm to solve the TCT problem, the minimum duration obtained was 112 days with minimum total cost of $162,020 <ref type="table" target="#tab_2">(Table 3)</ref>. While the success rate for the SFL was zero, its performance was better than the GA.</p><p>It is interesting to observe that the behavior of each optimization algorithm in all test problems (continuous and discrete) was consistent. In particular, the PSO algorithm generally outperformed all other algorithms in solving all the test problems in terms of solution quality (except for the F8 function with 10 and 50 variables). Accordingly, it can be concluded that the PSO is a promising optimization tool, in part due to the effect of the inertia weight factor u. In fact, to take advantage of the fast speed of the SFL algorithm, the authors suggest using a weight factor in Eq. (3) for SFL that is similar to that used for PSO (some preliminary experiments conducted by the authors in this regard have shown good results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions</head><p>In this paper, five evolutionary-based search methods were presented. These include: GA, MA, PSO, ACO, and SFL. A brief description of each method is presented along with a pseudocode to facilitate their implementation. Visual Basic programs were written to implement each algorithm. Two benchmark continuous optimization test problems were solved using all but the ACO algorithm, and the comparative results were presented. Also presented were the comparative results found when a discrete optimization test problem was solved using all five algorithms. The PSO method was generally found to perform better than other algorithms in terms of success rate and solution quality, while being second best in terms of processing time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Pseudocode for a GA procedure</head><p>Begin;</p><p>Generate random population of P solutions (chromosomes); For each individual i2P: calculate fitness (i); For iZ1 to number of generations; Randomly select an operation (crossover or mutation); If crossover; Select two parents at random i a and i b ; Generate on offspring i c Zcrossover (i a and i b ); Else If mutation;</p><p>Select one chromosome i at random; Generate an offspring i c Zmutate (i); End if; Calculate the fitness of the offspring i c ; If i c is better than the worst chromosome then replace the worst chromosome by i c ; Next i; Check if terminationZtrue; End;</p><p>Appendix B. Pseudocode for a MA procedure Begin;</p><p>Generate random population of P solutions (chromosomes); For each individual i2P: calculate fitness (i); For each individual i2P: do local-search (i);</p><p>For iZ1 to number of generations; Randomly select an operation (crossover or mutation); If crossover; Select two parents at random i a and i b ; Generate on offspring i c Zcrossover (i a and i b ); i c Zlocal-search (i c ); Else If mutation;</p><p>Select one chromosome i at random; Generate an offspring i c Zmutate (i); i c Zlocal-search (i c ); End if; Calculate the fitness of the offspring; If i c is better than the worst chromosome then replace the worst chromosome by i c ; Next i; Check if terminationZtrue; End;</p><p>End;</p><p>Appendix E. Pseudocode for an ACO procedure Begin;</p><p>Initialize the pheromone trails and parameters; Generate population of m solutions (ants); For each individual ant k2m: calculate fitness (k); For each ant determine its best position; Determine the best global ant; Update the pheromone trail; Check if terminationZtrue; End;</p><p>Appendix F. Pseudocode for a SFL procedure Appendix C. Pseudocode for the memetic local search</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Begin;</head><p>Select an incremental value dZa*Rand( ), where a is a constant that suits the variable values; For a given chromosome i2P: calculate fitness (i); For jZ1 to number of variables in chromosome i; Value (j)Zvalue (j)Cd; If chromosome fitness not improved then value (j)Zvalue (j)Kd; If chromosome fitness not improved then retain the original value (j); Next j; End;</p><p>Appendix D. Pseudocode for a PSO procedure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Begin;</head><p>Generate random population of P solutions (frogs); For each individual i2P: calculate fitness (i); Sort the population P in descending order of their fitness; Divide P into m memeplexes; For each memeplex; Determine the best and worst frogs; Improve the worst frog position using Eqs. (4) or (5); Repeat for a specific number of iterations; End; Combine the evolved memeplexes; Sort the population P in descending order of their fitness; Check if terminationZtrue; End;</p><p>Begin;</p><p>Generate random population of N solutions (particles); For each individual i2N: calculate fitness (i); Initialize the value of the weight factor, u; For each particle; Set pBest as the best position of particle i; If fitness (i) is better than pBest; pBest(i)Zfitness (i); End; Set gBest as the best fitness of all particles; For each particle;</p><p>Calculate particle velocity according to Eq. (3); Update particle position according to Eq. (4); End; Update the value of the weight factor, u; Check if terminationZtrue;</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Schematic diagram of natural evolutionary systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Applying local search using pair-wise interchange.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Ant representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Processing time to reach the optimum for F8 function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 Test problem for discrete optimization</head><label>1</label><figDesc></figDesc><table>Activity 
no. 

Depends 
on 

Option 1 
Option 2 
Option 3 
Option 4 
Option 5 

Duration 
(days) 

Cost ($) 
Duration 
(days) 

Cost ($) 
Duration 
(days) 

Cost ($) 
Duration 
(days) 

Cost ($) 
Duration 
(days) 

Cost ($) 

1 
-
14 
2400 
15 
2150 
16 
1900 
21 
1500 
24 
1200 
2 
-
15 
3000 
18 
2400 
20 
1800 
23 
1500 
25 
1000 
3 
-
15 
4500 
22 
4000 
33 
3200 
-
-
-
-
4 
-
12 
45,000 
16 
35,000 
20 
30,000 
-
-
-
-
5 
1 
22 
20,000 
24 
17,500 
28 
15,000 
30 
10,000 
-
-
6 
1 
14 
40,000 
18 
32,000 
24 
18,000 
-
-
-
-
7 
5 
9 
30,000 
15 
24,000 
18 
22,000 
-
-
-
-
8 
6 
14 
220 
15 
215 
16 
200 
21 
208 
24 
120 
9 
6 
15 
300 
18 
240 
20 
180 
23 
150 
25 
100 
10 
2, 6 
15 
450 
22 
400 
33 
320 
-
-
-
-
11 
7, 8 
12 
450 
16 
350 
20 
300 
-
-
-
-
12 
5, 9, 10 
22 
2000 
24 
1750 
28 
1500 
30 
1000 
-
</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="true"><head>Table 2 Results of the continuous optimization problems</head><label>2</label><figDesc></figDesc><table>Comparison 
criteria 

Algorithm 
Number of variables 

F8 
EF10 

10 
20 
50 
100 
10 
20 
50 

% Success 
GAs (Evolver) 
50 
30 
10 
0 
20 
0 
0 
MAs 
90 
100 
100 
100 
100 
70 
0 
PSO 
30 
80 
100 
100 
100 
80 
60 
A C O 
-
-
-
-
-
-
-
SFL 
50 
70 
90 
100 
80 
20 
0 
Mean solution 
GAs (Evolver) 
0.06 
0.097 
0.161 
0.432 
0.455 
1.128 
5.951 
MAs 
0.014 
0.013 
0.011 
0.009 
0.014 
0.068 
0.552 
PSO 
0.093 
0.081 
0.011 
0.011 
0.009 
0.075 
2.895 
A C O 
-
-
-
-
-
-
-
SFL 
0.08 
0.063 
0.049 
0.019 
0.058 
2.252 
6.469 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 3 Results of the discrete optimization problem</head><label>3</label><figDesc></figDesc><table>Algorithm 
Minimum project 
duration (days) 

Average project 
duration (days) 

Minimum 
cost ($) 

Average 
cost ($) 

% Success 
rate 

Processing 
time (s) 

GAs 
113 
120 
162,270 
164,772 
0 
16 
MAs 
110 
114 
161,270 
162,495 
20 
21 
PSO 
110 
112 
161,270 
161,940 
60 
15 
ACO 
110 
122 
161,270 
166,675 
20 
10 
SFL 
112 
123 
162,020 
166,045 
0 
15 

</table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Improving particle swarm optimization by hybridization of stochastic search heuristics and self-organized criticality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lovbjerg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>Aarhus Universitet, Denmark</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Masters Thesis</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Adaptation in natural and artificial systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Holland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
			<publisher>University of Michigan Press</publisher>
			<pubPlace>Ann Arbor, MI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using genetic algorithms to solve optimization problems in construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Al-Tabtabai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eng Constr Archit Manage</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="153" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optimization of construction time-cost trade-off analysis using genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hegazy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Can J Civil Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="685" to="97" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Method for conceptual design applied to office buildings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Grierson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khajehpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Civil Eng</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="83" to="103" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Genetic algorithms and their use in the design of evolvable hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joglekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tungare</surname></persName>
		</author>
		<ptr target="http://www.manastungare.com/articles/genetic/genetic-algorithms.pdf" />
		<imprint>
			<date type="published" when="2003-05-20" />
			<biblScope unit="volume">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On evolution, search, optimization, genetic algorithms and martial arts: towards memetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moscato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Report</title>
		<imprint>
			<biblScope unit="volume">826</biblScope>
			<date type="published" when="1989" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report Caltech Concurrent Computation Program</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Particle swarm optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on neural networks</title>
		<meeting>the IEEE international conference on neural networks<address><addrLine>Perth, Australia; Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="1942" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ant system: optimization by a colony of cooperating agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Maniezzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Colorni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Syst Man Cybern</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="41" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Optimization of water distribution network design using the shuffled frog leaping algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Eusuff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Lansey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Water Resour Plan Manage</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="210" to="235" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Genetic algorithms in search, optimization and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Addison-Wesley Publishing Co</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caudill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary neural networks. AI Expert</title>
		<imprint>
			<biblScope unit="page" from="28" to="33" />
			<date type="published" when="1991-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The selfish gene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dawkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A genetic local search approach to the quadratic assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Merz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freisleben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th international conference on genetic algorithms</title>
		<editor>B?ck CT</editor>
		<meeting>the 7th international conference on genetic algorithms<address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="465" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A memetic approach for the traveling salesman problem-implementation of a computational ecology for combinatorial optimization on message-passing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moscato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mg ;</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Valero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Onate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><forename type="middle">M</forename><surname>Larriba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Suarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on parallel computing and transputer application</title>
		<meeting><address><addrLine>Amsterdam, Holland</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="177" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A modified particle swarm optimizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on evolutionary computation</title>
		<meeting>the IEEE international conference on evolutionary computation<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="69" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparison between genetic algorithms and particle swarm optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eberhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th annual conference on evolutionary programming</title>
		<meeting>the 7th annual conference on evolutionary programming<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="611" to="619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The particle swarm: social adaptation of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on evolutionary computation</title>
		<meeting>the IEEE international conference on evolutionary computation<address><addrLine>Indianapolis, Indiana; Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="303" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ant colonies for the traveling salesman problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dorigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biosystems, Elsevier Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="73" to="81" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ant colony optimization for design of water distribution systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Zecchin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Foong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Y</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Seah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Water Resour Plan Manage</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="200" to="209" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ant-colony algorithms for permutation flowshop scheduling to minimize makespan/total flowtime of Jobs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur J Oper Res</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="426" to="464" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ant colony optimization for resource-constrained project scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Middendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schmeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the genetic and evolutionary computation conference</title>
		<meeting>the genetic and evolutionary computation conference</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="893" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimal design of water distribution network using shuffled complex evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S-Y</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atiquzzaman</forename><surname>Md</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Inst Eng</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="107" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Test driving three genetic algorithms: new test functions and geometric matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Whitley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Beveridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mathias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Heurist</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="77" to="104" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using genetic algorithms to solve construction time-cost trade-off problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Comput Civil Eng</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="184" to="193" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A direct stochastic algorithm for global search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ifc</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Appl Math Comput</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="729" to="58" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Evolver Version 4.0.2, Palisade Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Evolver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
