<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-17T00:07+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Link Prediction Problem for Social Networks *</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2004-01-08">January 8, 2004</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Liben-Nowell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Laboratory for Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology Cambridge</orgName>
								<address>
									<postCode>02139</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
							<email>kleinber@cs.cornell.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Cornell University Ithaca</orgName>
								<address>
									<postCode>14853</postCode>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Link Prediction Problem for Social Networks *</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2004-01-08">January 8, 2004</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? We formalize this question as the link prediction problem, and develop approaches to link prediction based on measures for analyzing the &quot;proximity&quot; of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As part of the recent surge of research on large, complex networks and their properties, a considerable amount of attention has been devoted to the computational analysis of social networksstructures whose nodes represent people or other entities embedded in a social context, and whose edges represent interaction, collaboration, or influence between entities. Natural examples of social networks include the set of all scientists in a particular discipline, with edges joining pairs who have co-authored papers; the set of all employees in a large company, with edges joining pairs working on a common project; or a collection of business leaders, with edges joining pairs who have served together on a corporate board of directors. The availability of large, detailed datasets encoding such networks has stimulated extensive study of their basic properties, and the identification of recurring structural features. (See, for example, the work of Watts and Strogatz <ref type="bibr" target="#b27">[28]</ref>, Watts <ref type="bibr" target="#b26">[27]</ref>, Grossman <ref type="bibr" target="#b8">[9]</ref>, Newman <ref type="bibr" target="#b18">[19]</ref>, and Adamic and Adar <ref type="bibr" target="#b0">[1]</ref>, or, for a thorough recent survey, Newman <ref type="bibr" target="#b19">[20]</ref>.) Social networks are highly dynamic objects; they grow and change quickly over time through the addition of new edges, signifying the appearance of new interactions in the underlying social structure. Understanding the mechanisms by which they evolve is a fundamental question that is still not well understood, and it forms the motivation for our work here. We define and study a basic computational problem underlying social network evolution, the link prediction problem:</p><p>Given a snapshot of a social network at time t, we seek to accurately predict the edges that will be added to the network during the interval from time t to a given future time t .</p><p>In effect, the link prediction problem asks: to what extent can the evolution of a social network be modeled using features intrinsic to the network itself ? Consider a co-authorship network among scientists, for example. There are many reasons, exogenous to the network, why two scientists who have never written a paper together will do so in the next few years: for example, they may happen to become geographically close when one of them changes institutions. Such collaborations can be hard to predict. But one also senses that a large number of new collaborations are hinted at by the topology of the network: two scientists who are "close" in the network will have colleagues in common, and will travel in similar circles; this suggests that they themselves are more likely to collaborate in the near future. Our goal is to make this intuitive notion precise, and to understand which measures of "proximity" in a network lead to the most accurate link predictions. We find that a number of proximity measures lead to predictions that outperform chance by factors of 40 to 50, indicating that the network topology does indeed contain latent information from which to infer future interactions. Moreover, certain fairly subtle measures-involving infinite sums over paths in the network-often outperform more direct measures, such as shortest-path distances and numbers of shared neighbors.</p><p>We believe that a primary contribution of the present paper is in the area of network evolution models. While there has been a proliferation of such models in recent years-see, for example, the work of Jin et al. <ref type="bibr" target="#b10">[11]</ref>, Barabasi et al. <ref type="bibr" target="#b1">[2]</ref>, and Davidsen et al. <ref type="bibr" target="#b4">[5]</ref> for recent work on collaboration networks, or the survey of Newman <ref type="bibr" target="#b19">[20]</ref>-they have generally been evaluated only by asking whether they reproduce certain global structural features observed in real networks. As a result, it has been difficult to evaluate and compare different approaches on a principled footing. Link prediction, on the other hand, offers a very natural basis for such evaluations: a network model is useful to the extent that it can support meaningful inferences from observed network data. One sees a related approach in recent work of Newman <ref type="bibr" target="#b16">[17]</ref>, who considers the correlation between certain network growth models and data on the appearance of edges of co-authorship networks.</p><p>In addition to its role as a basic question in social network evolution, the link prediction problem could be relevant to a number of interesting current applications of social networks. Increasingly, for example, researchers in artificial intelligence and data mining have argued that a large organization, such as a company, can benefit from the interactions within the informal social network among its members; these serve to supplement the official hierarchy imposed by the organization itself <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23]</ref>. Effective methods for link prediction could be used to analyze such a social network, and suggest promising interactions or collaborations that have not yet been utilized within the organization. In a different vein, research in security has recently begun to emphasize the role of social network analysis, largely motivated by the problem of monitoring terrorist networks; link prediction in this context allows one to conjecture that particular individuals are working together even though their interaction has not been directly observed <ref type="bibr" target="#b13">[14]</ref>.</p><p>The link prediction problem is also related to the problem of inferring missing links from an observed network: in a number of domains, one constructs a network of interactions based on observable data and then tries to infer additional links that, while not directly visible, are likely to exist <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26]</ref>. This line of work differs from our problem formulation in that it works with a static snapshot of a network, rather than considering network evolution; it also tends to take into account specific attributes of the nodes in the network, rather than evaluating the power of prediction methods based purely on the graph structure.</p><p>We now turn to a description of our experimental setup, in Section 2. Our primary focus is on training period Core authors papers edges authors |E old | |E new | <ref type="table" target="#tab_2">astro-ph  5343  5816  41852  1561  6178  5751  cond-mat  5469  6700  19881  1253  1899  1150  gr-qc  2122  3287  5724  486  519  400  hep-ph  5414  10254 17806  1790  6654  3294  hep-th  5241  9498  15842  1438  2311  1576</ref> Figure 1: The five sections of the arXiv from which co-authorship networks were constructed: astro-ph (astrophysics), cond-mat (condensed matter), gr-qc (general relativity and quantum cosmology), hep-ph (high energy physics-phenomenology), and hep-th (high energy physicstheory). The set Core is the subset of the authors who have written at least ¦Ê training = 3 papers during the training period and ¦Ê test = 3 papers during the test period. The sets E old and E new denote edges between Core authors which first appear during the training and test periods, respectively.</p><p>understanding the relative effectiveness of network proximity measures adapted from techniques in graph theory, computer science, and the social sciences, and we review a large number of such techniques in Section 3. Finally, we discuss the results of our experiments in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Experimental Setup</head><p>Suppose we have a social network G = V, E in which each edge e = u, v ¡Ê E represents an interaction between u and v that took place at a particular time t(e). We record multiple interactions between u and v as parallel edges, with potentially different time-stamps. For two times t &lt; t , let G[t, t ] denote the subgraph of G consisting of all edges with a time-stamp between t and t . Here, then, is a concrete formulation of the link prediction problem. We choose four times t 0 &lt; t 0 &lt; t 1 &lt; t 1 , and give an algorithm access to the network G[t 0 , t 0 ]; it must then output a list of edges, not present in G[t 0 , t 0 ], that are predicted to appear in the network G[t 1 , t 1 ]. We refer to [t 0 , t 0 ] as the training interval and [t 1 , t 1 ] as the test interval. Of course, social networks grow through the addition of nodes as well as edges, and it is not sensible to seek predictions for edges whose endpoints are not present in the training interval. Thus, in evaluating link prediction methods, we will generally use two parameters ¦Ê training and ¦Ê test (each set to 3 below), and define the set Core to be all nodes incident to at least ¦Ê training edges in G[t 0 , t 0 ] and at least ¦Ê test edges in G[t 1 , t 1 ]. We will then evaluate how accurately the new edges between elements of Core can be predicted.</p><p>We now describe our experimental setup more specifically. We work with five co-authorship networks G, obtained from the author lists of papers at five sections of the physics e-Print arXiv, www.arxiv.org. (See <ref type="figure">Figure 1</ref> for statistics on the size of each of these five networks.) Some heuristics were used to deal with occasional syntactic anomalies; and authors were identified by first initial and last name, a process that introduces a small amount of noise due to multiple authors with the same identifier <ref type="bibr" target="#b17">[18]</ref>. The errors introduced by this process appear to be minor. Now consider any one of these five graphs. We define the training interval to be the three years <ref type="bibr">[1994,</ref><ref type="bibr">1996]</ref>, and the test interval to be <ref type="bibr">[1997,</ref><ref type="bibr">1999]</ref>. We denote the subgraph G <ref type="bibr">[1994,</ref><ref type="bibr">1996]</ref> on the training interval by G collab := A, E old , and use E new to denote the set of edges u, v such that u, v ¡Ê A, and u, v co-author a paper during the test interval but not the training interval-these are the new interactions we are seeking to predict. graph distance (negated) length of shortest path between x and y common neighbors |¦£(x) ¡É ¦£(y)| Jaccard's coefficient</p><formula xml:id="formula_0">|¦£(x)¡É¦£(y)| |¦£(x)¡È¦£(y)| Adamic/Adar z¡Ê¦£(x)¡É¦£(y) 1 log |¦£(z)| preferential attachment |¦£(x)| ¡¤ |¦£(y)| Katz ¦Â ¡Þ =1 ¦Â ¡¤ |paths x,y |</formula><p>where paths</p><p>x,y := {paths of length exactly from x to y} weighted: paths </p><formula xml:id="formula_1">stationary-normed ?H x,y ¡¤ ¦Ð y commute time ?(H x,y + H y,x ) stationary-normed ?(H x,y ¡¤ ¦Ð y + H y,x ¡¤ ¦Ð x )</formula><p>where H x,y := expected time for random walk from x to reach y ¦Ð y := stationary distribution weight of y (proportion of time the random walk is at node y) rooted PageRank ¦Á stationary distribution weight of y under the following random walk: with probability ¦Á, jump to x. with probability 1 ? ¦Á, go to random neighbor of current node. Evaluating a link predictor. Each link predictor p that we consider outputs a ranked list L p of pairs in A ¡Á A ? E old ; these are predicted new collaborations, in decreasing order of confidence. For our evaluation, we focus on the set Core, so we define E * new := E new ¡É (Core ¡Á Core) and n := |E * new |. Our performance measure for predictor p is then determined as follows: from the ranked list L p , we take the first n pairs in Core ¡Á Core, and determine the size of the intersection of this set of pairs with the set E * new .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods for Link Prediction</head><p>In this section, we survey an array of methods for link prediction. All the methods assign a connection weight score(x, y) to pairs of nodes x, y, based on the input graph G collab , and then produce a ranked list in decreasing order of score(x, y). Thus, they can be viewed as computing a measure of proximity or "similarity" between nodes x and y, relative to the network topology. In general, the methods are adapted from techniques used in graph theory and social network analysis; in a number of cases, these techniques were not designed to measure node-to-node similarity, and hence need to be modified for this purpose. <ref type="figure" target="#fig_1">Figure 2</ref> summarizes most of these measures; below we discuss them in more detail. We note that some of these measures are designed only for connected graphs; since each graph G collab that we consider has a giant component-a single component containing most of the nodes-it is natural to restrict the predictions for these measures to this component.</p><p>Perhaps the most basic approach is to rank pairs x, y by the length of their shortest path in G collab . Such a measure follows the notion that collaboration networks are "small worlds," in which individuals are related through short chains <ref type="bibr" target="#b17">[18]</ref>. (In keeping with the notion that we rank pairs in decreasing order of score(x, y), we define score(x, y) here to be the negative of the shortest path length.) Pairs with shortest-path distance equal to 1 are joined by an edge in G collab , and hence they belong to the training edge set E old . For all of our graphs G collab , there are well more than n pairs at shortest-path distance two, so our shortest-path predictor simply selects a random subset of these distance-two pairs.</p><p>Methods based on node neighborhoods. For a node x, let ¦£(x) denote the set of neighbors of x in G collab . A number of approaches are based on the idea that two nodes x and y are more likely to form a link in the future if their sets of neighbors ¦£(x) and ¦£(y) have large overlap; this follows the natural intuition that such nodes x and y represent authors with many colleagues in common, and hence are more likely to come into contact themselves. Jin et al. <ref type="bibr" target="#b10">[11]</ref> and Davidsen et al. <ref type="bibr" target="#b4">[5]</ref> have defined abstract models for network growth using this principle, in which an edge x, y is more likely to form if edges x, z and z, y are already present for some z.</p><p>? Common neighbors. The most direct implementation of this idea for link prediction is to define score(x, y) := |¦£(x) ¡É ¦£(y)|, the number of neighbors that x and y have in common. Newman <ref type="bibr" target="#b16">[17]</ref> has computed this quantity in the context of collaboration networks, verifying a correlation between the number of common neighbors of x and y at time t, and the probability that they will collaborate in the future.</p><p>? Jaccard's coefficient and Adamic/Adar. The Jaccard coefficient-a commonly used similarity metric in information retrieval <ref type="bibr" target="#b23">[24]</ref>-measures the probability that both x and y have a feature f , for a randomly selected feature f that either x or y has. If we take "features" here to be neighbors in G collab , this leads to the measure score(x, y) := |¦£(x) ¡É ¦£(y)|/|¦£(x) ¡È ¦£(y)|. Adamic and Adar <ref type="bibr" target="#b0">[1]</ref> consider a related measure, in the context of deciding when two personal home pages are strongly "related." To do this, they compute features of the pages, and define the similarity between two pages to be 1 log(frequency(z)) . This refines the simple counting of common features by weighting rarer features more heavily. This suggests the measure score(x, y) := z¡Ê¦£(x)¡É¦£(y) 1 log |¦£(z)| .</p><p>? Preferential attachment has received considerable attention as a model of the growth of networks <ref type="bibr" target="#b15">[16]</ref>. The basic premise is that the probability that a new edge involves node x is proportional to |¦£(x)|, the current number of neighbors of x. Newman <ref type="bibr" target="#b16">[17]</ref> and Barabasi et al. <ref type="bibr" target="#b1">[2]</ref> have further proposed, on the basis of empirical evidence, that the probability of co-authorship of x and y is correlated with the product of the number of collaborators of x and y. This corresponds to the measure score(x, y) := |¦£(x)| ¡¤ |¦£(y)|.</p><p>Methods based on the ensemble of all paths. A number of methods refine the notion of shortest-path distance by implicitly considering the ensemble of all paths between two nodes.</p><p>? Katz <ref type="bibr" target="#b11">[12]</ref> defines a measure that directly sums over this collection of paths, exponentially damped by length to count short paths more heavily. This leads to the measure</p><formula xml:id="formula_2">¡Þ score(x, y) := ¦Â ¡¤ |paths x,y |, =1</formula><p>where paths</p><p>x,y is the set of all length-paths from x to y. (A very small ¦Â yields predictions much like common neighbors, since paths of length three or more contribute very little to the summation.) One can verify that the matrix of scores is given by (I ? ¦ÂM ) ?1 ? I, where M is the adjacency matrix of the graph. We consider two variants of this Katz measure: (1) unweighted, in which paths 1 x,y = 1 if x and y have collaborated and 0 otherwise, and (2) weighted, in which paths 1 x,y is the number of times that x and y have collaborated.</p><p>? Hitting time, PageRank, and variants. A random walk on G collab starts at a node x, and iteratively moves to a neighbor of x chosen uniformly at random. The hitting time H x,y from x to y is the expected number of steps required for a random walk starting at x to reach y. Since the hitting time is not in general symmetric, it is also natural to consider the commute time C x,y := H x,y +H y,x . Both of these measures serve as natural proximity measures, and hence (negated) can be used as score(x, y).</p><p>One difficulty with hitting time as a measure of proximity is that H x,y is quite small whenever y is a node with a large stationary probability ¦Ð y , regardless of the identity of x. To counterbalance this phenomenon, we also consider normalized versions of the hitting and commute times, by defining score(x, y) := ?H x,y ¡¤ ¦Ð y or score(x, y) :</p><formula xml:id="formula_3">= ?(H x,y ¡¤ ¦Ð y + H y,x ¡¤ ¦Ð x ).</formula><p>Another difficulty with these measures is their sensitive dependence to parts of the graph far away from x and y, even when x and y are connected by very short paths. A way of counteracting this is to allow the random walk from x to y to periodically "reset," returning to x with a fixed probability ¦Á at each step; in this way, distant parts of the graph will almost never be explored. Random resets form the basis of the PageRank measure for Web pages <ref type="bibr" target="#b2">[3]</ref>, and we can adapt it for link prediction as follows: Define score(x, y) under the rooted PageRank measure to be the stationary probability of y in a random walk that returns to x with probability ¦Á each step, moving to a random neighbor with probability 1 ? ¦Á.</p><p>? SimRank <ref type="bibr" target="#b9">[10]</ref> is a fixed point of the following recursive definition: two nodes are similar to the extent that they are joined to similar neighbors. Numerically, this is specified by defining similarity(x, x) := 1 and</p><formula xml:id="formula_4">similarity(x, y) := ¦Ã ¡¤ a¡Ê¦£(x) b¡Ê¦£(y) similarity(a, b) |¦£(x)| ¡¤ |¦£(y)| for some ¦Ã ¡Ê [0, 1].</formula><p>We then define score(x, y) := similarity(x, y). SimRank can also be interpreted in terms of a random walk on the collaboration graph: it is the expected value of ¦Ã , where is a random variable giving the time at which random walks started from x and y first meet.</p><p>Higher-level approaches. We now discuss three "meta-approaches" that can be used in conjunction with any of the methods discussed above.</p><p>? Low-rank approximation. Since the adjacency matrix M can be used to represent the graph G collab , all of our link prediction methods have an equivalent formulation in terms of this matrix M . In some cases, this was noted explicitly above (for example in the case of the Katz similarity score); but in many cases the matrix formulation is quite natural. For example, the common neighbors method consists simply of mapping each node x to its row r(x) in M , and then defining score(x, y) to be the inner product of the rows r(x) and r(y).</p><p>A common general technique when analyzing the structure of a large matrix M is to choose a relatively small number k and compute the rank-k matrix M k that best approximates M with respect to any of a number of standard matrix norms. This can be done efficiently using the singular value decomposition, and it forms the core of methods like latent semantic analysis in information retrieval <ref type="bibr" target="#b5">[6]</ref>. Intuitively, working with M k rather than M can be viewed as a type of "noise-reduction" technique that generates most of the structure in the matrix but with a greatly simplified representation.</p><p>In our experiments, we investigate three applications of low-rank approximation: (i) ranking by the Katz measure, in which we use M k rather than M in the underlying formula; (ii) ranking by common neighbors, in which we score by inner products of rows in M k rather than M ; and-most simply of all-(iii) defining score(x, y) to be the x, y entry in the matrix M k .</p><p>? Unseen bigrams. Link prediction is akin to the problem of estimating frequencies for unseen bigrams in language modeling-pairs of words that co-occur in a test corpus, but not in the corresponding training corpus (see, e.g., the work of Essen and Steinbiss <ref type="bibr" target="#b6">[7]</ref>). Following ideas proposed in that literature <ref type="bibr">[15,</ref> for example], we can augment our estimates for score(x, y) using values of score(z, y) for nodes z that are "similar" to x. Specifically, we adapt this to the link prediction problem as follows. Suppose we have values score(x, y) computed under one of the measures above. Let S ¦Ä x denote the ¦Ä nodes most related to x under score(x, ¡¤), for a parameter ¦Ä ¡Ê Z + . We then define enhanced scores in terms of the nodes in this set:</p><formula xml:id="formula_5">score * unweighted (x, y) := {z : z ¡Ê ¦£(y) ¡É S ¦Ä x } score * weighted (x, y) := z¡Ê¦£(y)¡ÉS ¦Ä x score(x, z).</formula><p>? Clustering. One might seek to improve on the quality of a predictor by deleting the more "tenuous" edges in G collab through a clustering procedure, and then running the predictor on the resulting "cleaned-up" subgraph. Consider a measure computing values for score(x, y). We compute score(u, v) for all edges in E old , and delete the (1 ? ¦Ñ) fraction of these edges for which the score is lowest. We now recompute score(x, y) for all pairs x, y on this subgraph; in this way we determine node proximities using only edges for which the proximity measure itself has the most confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>As discussed in Section 1, many collaborations form (or fail to form) for reasons outside the scope of the network; thus the raw performance of our predictors is relatively low. To more meaningfully represent predictor quality, we use as our baseline a random predictor which simply randomly selects pairs of authors who did not collaborate in the training interval. A random prediction is correct with probability between 0.15% (cond-mat) and 0.48% (astro-ph). <ref type="figure">Figures 3 and 4</ref> show each predictor's performance on each arXiv section, in terms of the factor improvement over random. <ref type="figure" target="#fig_5">Figures 5, 6, and 7</ref> show the average relative performance of several different predictors versus three baseline predictors-the random predictor, the graph distance predictor, and the common neighbors predictor. There is no single clear winner among the techniques, but we see that a number of methods significantly outperform the random predictor, suggesting that there is indeed useful information contained in the network topology alone. The Katz measure and its variants based on clustering and low-rank approximation perform consistently well; on three of the five predictor astro-ph cond-mat gr-qc hep-ph hep-th probability that a random prediction is correct 0.475% 0.147% 0.341% 0.207% 0.153% graph distance (all distance-two pairs)</p><p>9 Figure 3: Performance of various predictors on the link prediction task defined in Section 2. For each predictor and each arXiv section, the given number specifies the factor improvement over random prediction. Two predictors in particular are used as baselines for comparison: graph distance and common neighbors (see Section 3 for definitions of these). Italicized entries have performance at least as good as the graph distance predictor; bold entries are at least as good as the common neighbors predictor. See also <ref type="figure">Figure 4</ref>.</p><p>predictor astro-ph cond-mat gr-qc hep-ph hep-th probability that a random prediction is correct 0.475% 0.147% 0.341% 0.207% 0.153% graph distance (all distance-two pairs)</p><p>9 Figure 4: Performance of various meta-approaches on the link prediction task defined in Section 2. As before, for each predictor and each arXiv section, the given number specifies the factor improvement over random prediction. See <ref type="figure">Figure 3</ref>.   <ref type="figure">Figure 5</ref>: Relative average performance of various predictors versus random predictions. The value shown is the average ratio over the five datasets of the given predictor's performance versus the random predictor's performance. The error bars indicate the minimum and maximum of this ratio over the five datasets. The parameters for the starred predictors are: (1) for weighted Katz, ¦Â = 0.005; (2) for Katz clustering, ¦Â 1 = 0.001, ¦Ñ = 0.15, ¦Â 2 = 0.1; (3) for low-rank inner product, rank = 256; (4) for rooted Pagerank, ¦Á = 0.15; (5) for unseen bigrams, unweighted common neighbors with ¦Ä = 8; and (6) for SimRank, ¦Ã = 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.00</head><p>2.00</p><p>1.00</p><p>graph distance predictor The plotted value shows the average taken over the five datasets of the ratio of the performance of the given predictor versus the graph distance predictor; the error bars indicate the range of this ratio over the five datasets. All parameter settings are as in <ref type="figure">Figure 5</ref>.  <ref type="figure">Figure 6</ref>. Error bars display the range of the performance ratio of the given predictor versus common neighbors over the five datasets; the displayed value gives the average ratio. Parameter settings are as in <ref type="figure">Figure 5</ref>. Similarities among the predictors and the datasets. Not surprisingly, there is significant overlap in the predictions made by the various methods. In <ref type="figure" target="#fig_6">Figure 8</ref>, we show the number of common predictions made by ten of the most successful measures on the cond-mat graph. We see that Katz, low-rank inner product, and Adamic/Adar are quite similar in their predictions, as are (to a somewhat lesser extent) rooted PageRank, SimRank, and Jaccard. Hitting time is remarkably unlike any of the other nine in its predictions, despite its reasonable performance. The number of common correct predictions shows qualitatively similar behavior; see <ref type="figure" target="#fig_8">Figure 9</ref>. It would interesting to understand the generality of these overlap phenomena, especially since certain of the large overlaps do not seem to follow obviously from the definitions of the measures. It is harder to quantify the relationships among the datasets, but this is a very interesting issue as well. One perspective is provided by the methods based on low-rank approximation: on four of the datasets, their performance tends to be best at an intermediate rank, while on gr-qc they perform best at rank 1. This suggests a sense in which the collaborations in gr-qc have a much "simpler" structure than in the other four. One also observes the apparent importance of node degree in the hep-ph collaborations: the preferential attachment predictor-which considers only the number (and not the identity) of a scientist's co-authors-does uncharacteristically well on this dataset, outperforming the basic graph distance predictor. Finally, it would be interesting to make precise a sense in which astro-ph is a "difficult" dataset, given the low performance of all methods relative to random, and the fact that none beats simple ranking by common neighbors. We will explore this issue further below when we consider collaboration data drawn from other fields.   Small worlds. It is reassuring that even the basic graph distance predictor handily outperforms random predictions, but this measure has severe limitations. Extensive research has been devoted to understanding the so-called small world problem in collaboration networks-i.e., accounting for the existence of short paths connecting virtually every pair of scientists <ref type="bibr" target="#b17">[18]</ref>. This property is normally viewed as a vital fact about the scientific community (new ideas spread quickly, and every discipline interacts with and gains from other fields) but in the context of our prediction task, we come to a different conclusion: the small world problem is really a problem. The shortest path between two scientists in wholly unrelated disciplines is often very short (and very tenuous). To take one particular (but not atypical) example, the developmental psychologist Jean Piaget has as small an Erd?s Number-three <ref type="bibr" target="#b3">[4]</ref>-as most mathematicians and computer scientists. Overall, the basic graph distance predictor is not competitive with most of the other approaches studied; our most successful link predictors can be viewed as using measures of proximity that are robust to the few edges that result from rare collaborations between fields.</p><p>Restricting to distance three. The small world problem suggests that there are many pairs with graph distance two that will not collaborate, but we also observe the dual problem: many pairs that collaborate are at distance larger than two. Between 71% (hep-ph) and 83% (cond-mat) of new edges form between pairs at distance three or greater; see <ref type="figure">Figure 10</ref>. Since most new collaborations are not at distance two, we are also interested in how well our predictors perform when we disregard all distance-two pairs. Clearly, nodes at distance greater than two have no neighbors in common, and hence this task essentially rules out the use of methods based on common neighbors. The performance of the other measures is shown in <ref type="figure">Figure 11</ref>. The graph astro-ph cond-mat gr-qc hep-ph hep- <ref type="table" target="#tab_2">th  # pairs at distance two  33862  5145  935  37687  7545  # new collaborations at distance two  1533  190  68  945  335  # new collaborations  5751  1150  400  3294  1576</ref> Figure 10: Relationship between new collaborations and graph distance.</p><p>distance predictor (i.e., predicting all distance-three pairs) performs between three and eight times random, and is consistently beaten by virtually all of the predictors: SimRank, rooted PageRank, Katz, and the low-rank approximation and unseen bigram techniques. The unweighted Katz and unseen bigram predictors have the best performance (as high as about 30 times random, on gr-qc), followed closely by weighted Katz, SimRank, and rooted PageRank.</p><p>The breadth of the data. We also have considered three other datasets: <ref type="formula">(1)</ref>  Performance versus random swells dramatically as the topical focus of our data set widens. That is, when we consider a more diverse collection of scientists, it is fundamentally easier to group scientists into fields of study (and outperform random predictions, which will usually make guesses between fields). When we consider a sufficiently narrow set of researchers-e.g., STOC/FOCSalmost any author can collaborate with almost any other author, and there seems to a strong random component to new collaborations. (In extensive experiments on the STOC/FOCS data, we could not beat random guessing by a factor of more than about seven.) It is an interesting challenge to formalize the sense in which the STOC/FOCS collaborations are truly intractable to predict-i.e., to what extent information about new collaborations is simply not present in the old collaboration data.</p><p>Future directions. While the predictors we have discussed perform reasonably well, even the best (Katz clustering on gr-qc) is correct on only about 16% of its predictions. There is clearly much room for improvement in performance on this task, and finding ways to take better advantage of the information in the training data is an interesting open question. Another issue is to improve the efficiency of the proximity-based methods on very large networks; fast algorithms for approximating the distribution of node-to-node distances may be one approach <ref type="bibr" target="#b20">[21]</ref>. The graph G collab is a lossy representation of the data; we can also consider a bipartite collaboration graph B collab , with a vertex for every author and paper, and an edge connecting each paper to each of its authors. The bipartite graph contains more information than G collab , so we may hope that predictors can use it to improve performance. The size of B collab is much larger than G collab , making experiments prohibitive, but we have tried using the SimRank and Katz predictors on smaller datasets (gr-qc, or shorter training periods). Their performance does not seem to improve, but perhaps other predictors can fruitfully exploit the additional information in B collab . predictor astro-ph cond-mat gr-qc hep-ph hep-th graph distance (all distance-three pairs)</p><p>3.1 5. ¦Ñ = 0.10 3.5 4.2 31.7 7.1 8.7 Katz (¦Â1 = 0.001, ¦Â2 = 0.1) ¦Ñ = 0.15 4.8 4.2 32.8 7.7 6.7 ¦Ñ = 0.20 2.5 5.9 7.4 4.5 8.0 ¦Ñ = 0.25 2.1 11.9 6.3 6.8 5.3</p><p>Figure 11: The Distance-3 Task: performance of predictors only on edges in E new for which the endpoints were at distance three or more in G collab . Methods based on common neighbors are not appropriate for this task. See Section 4.</p><p>Similarly, our experiments treat all training period collaborations equally. Perhaps one can improve performance by treating more recent collaborations as more important than older ones. One could also tune the parameters of the Katz predictor, e.g., by dividing the training set into temporal segments, training ¦Â on the beginning, and then using the end of the training set to make final predictions.</p><p>Finally, there has been relevant work in the machine learning community on estimating distribution support: given samples from an unknown probability distribution P , we must find a "simple" set S so that Pr x?P [x / ¡Ê S] &lt; ¦Å <ref type="bibr" target="#b24">[25]</ref>. We can view training period collaborations as samples drawn from a probability distribution on pairs of scientists; our goal is to approximate the set of pairs that have positive probability of collaborating. It is an open question whether these techniques can be fruitfully applied to the link prediction problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Values for score(x, y) under various predictors; each predicts pairs x, y in descending order of score(x, y). The set ¦£(x) consists of the neighbors of the node x in G collab .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>z</head><label></label><figDesc>: feature shared by x, y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 6: Relative average performance of various predictors versus the graph distance predictor. The plotted value shows the average taken over the five datasets of the ratio of the performance of the given predictor versus the graph distance predictor; the error bars indicate the range of this ratio over the five datasets. All parameter settings are as in Figure 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Relative average performance of various predictors versus the common neighbors predictor, as in Figure 6. Error bars display the range of the performance ratio of the given predictor versus common neighbors over the five datasets; the displayed value gives the average ratio. Parameter settings are as in Figure 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: The number of common predictions made by various predictors on the cond-mat dataset, out of 1150 predictions. Parameter settings are as in Figure 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Adamic</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: The number of correct common predictions made by various predictors on the cond-mat dataset, out of 1150 predictions. The diagonal entries indicate the number of correct predictions for each predictor. Parameter settings are as in Figure 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>the proceedings of the theoretical computer science conferences Symposium on the Theory of Computing (STOC) and Foundations of Computer Science (FOCS), (2) the papers found in the Citeseer (www.citeseer. com) online database, which finds papers by crawling the web for any files in postscript form, and (3) all five of the arXiv sections merged into one. Consider the performance of the common neighbor predictor versus random on these datasets: STOC/FOCS arXiv sections all arXiv'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>0</head><label>0</label><figDesc></figDesc><table>Relative performance ratio versus random predictions 

Adamic/Adar 

weighted Katz  *  

Jaccard 

unseen bigrams  *  
SimRank  *  

Katz clustering  *  

low-rank inner product  *  
common neighbors 
rooted PageRank  *  

graph distance 
hitting time 

</table></figure>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="annex">
			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Friends and neighbors on the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eytan</forename><surname>Adamic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="230" />
			<date type="published" when="2003-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evolution of the social network of scientific collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>N¨¦da</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ravasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vicsek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica A</title>
		<imprint>
			<biblScope unit="volume">311</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="590" to="614" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The anatomy of a large-scale hypertextual Web search engine. Computer Networks and ISDN Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Page</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Famous trails to Paul Erd?s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><forename type="middle">De</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerrold</forename><forename type="middle">W</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Intelligencer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="51" to="63" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Emergence of a small world from local interactions: Modeling acquaintance networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn</forename><surname>Davidsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Ebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bornholdt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Indexing by latent semantic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Deerwester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><forename type="middle">T</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">W</forename><surname>Furnas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Harshman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="391" to="407" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cooccurrence smoothing for stochastic language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ute</forename><surname>Essen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Steinbiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<meeting>the IEEE International Conference on Acoustics, Speech, and Signal Processing</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="161" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Assessing experimentally derived interactions in a small world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debra</forename><forename type="middle">S</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><forename type="middle">P</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences USA</title>
		<meeting>the National Academy of Sciences USA</meeting>
		<imprint>
			<date type="published" when="2003-04" />
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="4372" to="4376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The evolution of the mathematical research collaboration graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerrold</forename><forename type="middle">W</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Southeast Conference on Combinatorics, Graph Theory, and Computing</title>
		<meeting>the Southeast Conference on Combinatorics, Graph Theory, and Computing</meeting>
		<imprint>
			<date type="published" when="2002-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SimRank: A measure of structural-context similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Glen</forename><surname>Jeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Widom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2002-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The structure of growing social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Girvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">046132</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A new status index derived from sociometric analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="43" />
			<date type="published" when="1953-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ReferralWeb: Combining social networks and collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Selman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1997-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mapping networks of terrorist cells</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valdis</forename><surname>Krebs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connections</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="43" to="52" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Measures of distributional similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A brief history of lognormal and power law distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mitzenmacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Allerton Conference on Communication, Control, and Computing</title>
		<meeting>the Allerton Conference on Communication, Control, and Computing</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="182" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Clustering and preferential attachment in growing networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The structure of scientific collaboration networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences USA</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="404" to="409" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The structure and function of networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Physics Communications</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="40" to="45" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The structure and function of complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="167" to="256" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">ANF: A fast and scalable tool for data mining in massive graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2002-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Statistical relational learning for link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Learning Statistical Models from Relational Data at the International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Social networks: From the web to the enterprise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet Computing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="94" />
			<date type="published" when="2002-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Introduction to Modern Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>McGrawHill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Estimating the support of a high-dimensional distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
		<idno>MSR-TR-99-87</idno>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Microsoft Research</pubPlace>
		</imprint>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Link prediction in relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Taskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Neural Information Processing Systems</title>
		<meeting>Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><forename type="middle">J</forename><surname>Watts</surname></persName>
		</author>
		<title level="m">Small Worlds</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collective dynamics of &apos;small-world&apos; networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">H</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strogatz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="page" from="440" to="442" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
