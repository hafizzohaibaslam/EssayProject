<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-16T23:45+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Multi-Agent System for Distributed Cluster Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">W</forename><surname>Reed</surname></persName>
							<email>reedjw@ornl.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">Oak Ridge National Laboratory</orgName>
								<address>
									<postBox>P. O. Box 2008</postBox>
									<postCode>6359, 37831</postCode>
									<settlement>Oak Ridge</settlement>
									<region>MS, Tennessee</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">E</forename><surname>Potok</surname></persName>
							<email>potokte@ornl.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">Oak Ridge National Laboratory</orgName>
								<address>
									<postBox>P. O. Box 2008</postBox>
									<postCode>6359, 37831</postCode>
									<settlement>Oak Ridge</settlement>
									<region>MS, Tennessee</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Patton</surname></persName>
							<email>pattonrm@ornl.gov</email>
							<affiliation key="aff0">
								<orgName type="institution">Oak Ridge National Laboratory</orgName>
								<address>
									<postBox>P. O. Box 2008</postBox>
									<postCode>6359, 37831</postCode>
									<settlement>Oak Ridge</settlement>
									<region>MS, Tennessee</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Multi-Agent System for Distributed Cluster Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>2. Background One of the approaches used to improve the accuracy and relevancy in information retrieval is cluster analysis. Clustering methods determine relationships among text documents, and allow the determination of similar groups or clusters of documents. These methods are computationally expensive, thereby limiting their use to a relatively small set of documents. This paper describes a multi-agent system to cluster large data sets. This technique is then compared to hierarchical agglomerative clustering using a small set of text data. Results show that the agent-based approach can significantly reduce the time required to cluster large data sets.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>There is a wealth of textual information readily available over the Internet. There are many search engines and portals available to retrieve this information. Unfortunately, the retrieval accuracy and relevancy is often quite low <ref type="bibr" target="#b2">[2]</ref>. One of the approaches used to improve this accuracy and relevancy in information retrieval is to use advanced textual analysis methods, such as cluster analysis. These clustering methods determine relationships among text documents, and allow the determination of similar groups or clusters of documents. However, clustering methods are computationally expensive, typically between O(n 2 ) and O(n 3 ), where n is the number of documents to be clustered <ref type="bibr" target="#b11">[10]</ref>. Practically, this limits its use of these methods to a relatively small set of documents.</p><p>To address this problem, this paper describes a new distributed clustering technique based on agent technology. This new clustering technique is then compared to hierarchical agglomerative clustering (HAC). Preliminary results show that this new approach can handle larger document sets much more quickly and efficiently than the agglomerative hierarchical approach.</p><p>The basic technique of hierarchical agglomerative clustering involves several steps. First, the set of documents is processed by removing all of the stop words, or commonly occurring words that have little meaning within a document. The next step is to stem the remaining words, or to reduce them to their root form. The words within the document set are then used to create a vector that represents the document. A set of these document vectors can be used to create a vector space model (VSM) that represents the relationships between the documents <ref type="bibr" target="#b8">[7]</ref>. In a VSM, each unique word within a document collection is represented as a dimension in space and each document is represented by a vector in that multidimensional space. The numeric representation of a word within a document (which is a single element of the document's vector and a single dimension in the VSM) is typically based on the frequency of the word within a specific document (local term frequency), and the frequency within the document set (global term frequency). A word with a high frequency within a specific document and low frequency within a set of documents, often called Term Frequency Inverse Document Frequency (TFIDF) <ref type="bibr" target="#b9">[8]</ref>, produces a high value. Words with high values have been shown to be very useful in accurately classifying and retrieving documents. Since a word frequency over a set of documents is required, all documents within a set must be analyzed before a VSM can be constructed. This part of the clustering process has a time complexity of O(n 2 ). The VSM can be used to define a similarity value between a pair of documents. Typically, this value is obtained by using Euclidian distance between the vector endpoints or using the dot product to calculate the cosine of the angle between the pair of document vectors. All of the possible pairs of document in the collection can be compared and their similarity values collected to create a similarity matrix. This similarity matrix is needed to compute the document clusters. The agglomerative clustering process begins by placing each document within its own cluster. Next, the pair of clusters that contain the most similar documents (as defined by the similarity matrix) are merged into a single cluster. At this point, the similarity matrix values must be updated to reflect the merge. This process iterates until all of the documents are in a single cluster. This part of the clustering process has a time complexity of O(n 3 ). There are several issues with this approach to clustering. First, the TFIDF calculation cannot be easily distributed across multiple computer systems because of its dependence on a global term frequency. Second, using TFIDF and HAC on a large, dynamic data set does not work very well. As new documents are added to the data set, global term frequencies would need to be updated, which would ultimately require the need to re-cluster the data set. Finally, the combined computational complexity of TFIDF and HAC makes this approach infeasible for large data sets.</p><p>already exist in the clustering system. Finally, either the document is given to a software agent representing a set of document very similar to it, or if the document is unlike any currently in the system, a new software agent is created to represent it. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Multi-agent distributed clustering</head><p>Sub-Cluster Agent</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-Cluster Agent</head><p>Sub-Cluster Agent</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-Cluster Agent</head><p>To address these issues, a multi-agent system for distributed clustering of text documents was developed. This approach does not depend on a global term frequency count, and is essentially a hybrid HAC and Kmeans clustering approach.</p><p>To implement this multi-agent clustering system, several types of agents are used. At the lowest level, there are sub-cluster agents. Each sub-cluster agent represents a set of documents that are very similar. Above these, there are cluster agents. Each cluster agent represents a set of sub-cluster agents whose document sets have some similarities, but are not as similar as documents in a sub-cluster agent's document set. Above the cluster agent is the master cluster agent. These master cluster agents manage a set of cluster agents. There is not any implied relationship between the set of cluster agents (and their associated documents) managed by a master cluster agent. The master cluster agents are used to move cluster agents between other master cluster agents on different computer systems and therefore achieve better load balancing.</p><p>Each computer in the distributed clustering system has only one master cluster agent. Finally, there are document multiplexer agents in the system. The document multiplexer agents accept new documents (and their representative vectors) and help to insert them into the clustering system. All of these types of agents work together to organize a set of documents as shown in <ref type="figure" target="#fig_1">Figure 1</ref>.</p><p>Incorporating a new document into the distributed clustering system requires several steps.</p><p>First, a document vector representing the document must be created. The document vector is then used to evaluate how the document compares to the documents that A new document is first processed into a document vector, which will represent the document's content. This vector can then be used to compare it with other documents or sets of documents. To create a document vector, all of the words in the document are filtered by a set of rules. Word below a minimum length (typically 3 or 4 characters) and common words like "and" and "the" are ignored. Once this is complete, the remaining words are processed into a set of tokens. This process can be as simple as creating a token for each word in the document or it can use some very complex algorithms to group several word together into a single token. We use a reasonable simple algorithm that creates a token for each word in the document and creates a token for each pair of adjacent words that are not separated by a word below the minimum allowable length or a stop word. Each word or phrase in the token list is replaced with a canonical synonym if it exists. For example, all occurrences of "bin laden", "usama bin laden", "usama", and "osama" are replaced with the token "osama bin laden". Next, each token is stemmed <ref type="bibr" target="#b3">[3]</ref> <ref type="bibr" target="#b4">[4]</ref>. A vector is created by taking each value in the token list and associating it with its frequency in the original document. The final document vector is obtained by normalizing this vector. Once this vector is calculated, the new document can begin the evaluation process.</p><p>The document evaluation process calculates where a new document will best fit into the clusters of documents already in the system. This process begins when the document multiplexer agent receives a new document and its representative document vector. As soon as this happens, the document vector is sent to all of the master cluster agents for evaluation. The master cluster agent then passes the vector to each of the cluster agent that it oversees. As mentioned above, each of these cluster agents is responsible for a set of sub-cluster agents, which are responsible for a set of documents. The sub-cluster agent maintains a single composite vector that represents all of the documents it oversees. Likewise, each cluster agent maintains a single composite vector that represents all of the sub-cluster agents under it. These composite vectors are calculated by summing the vectors to be represented and the normalizing the result. Each of the cluster agents then evaluates the new document, by comparing the document's vector to its own composite vector using cosine measure, Euclidean distance, or one of the other common methods. The comparison result is sent back to the master cluster agent. The master cluster agents collect all of the comparisons and send the closest one back to the multiplexer agent. Similarly, the multiplexer agent will collect all of the values from the master clusters agents and find the best match value. This value will indicate either that a cluster of documents similar to the new document already exists in the system or that no similar documents are in the system. If a cluster of similar documents exists, the new document needs to be incorporated into that cluster; otherwise, a new cluster needs to be created.</p><p>Once the document evaluation process is complete, if the document multiplexer agent has decided that a similar set of document exists in the system, the new document needs to be incorporated into that document set. The multiplexer agent will send the document and its vector to the master cluster agent that it determined represented a similar cluster set. The master cluster agent will then forward the document and vector to the cluster agent, which responded with the closest similarity value. During the evaluation process, the document vector was compared to the cluster agent's composite vector rather than to each sub-cluster's composite vector, so to find out which sub-cluster agent contains the most similar documents, this must occur now. Each sub-cluster agent compares the document vector to its composite vector and sends the similarity value up to the cluster agent above it. The cluster agent examines all of the similarity values and determines whether the document is close enough to a sub-clusters document set to be added to it or whether a new sub-cluster agent needs to be created for the document.</p><p>If the new document evaluation process determined that there were no other documents similar to the new document, then a new cluster agent must be created for it. First, the multiplexer agent will query master cluster agents to see what their current load is like. The multiplexer agent will determine which master cluster agent has the least load and it will send the document and vector there. The master cluster agent will create a new cluster agent, which will create a new sub-cluster agent for the new document.</p><p>Because of the process used to add documents to the system, the set of documents represented by a sub-cluster agent are very similar and likewise, the set of sub-cluster agents represented by a cluster agent contain documents less similar, but still related to one another. These relationships can be used to generate any type of desired clustering visualization. At the cluster agent level and at the sub-cluster agent level, the composite vectors can be compared to one another to determine relationships between sets of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Comparison</head><p>As a data source for comparing HAC and the multiagent approach described here, the Text Retrieval Conference (TREC) 1996 corpus was used. This corpus contains 130,000 documents of worldwide news events <ref type="bibr" target="#b10">[9]</ref>. To compare the two clustering methods, several sets of randomly selected documents were chosen from the TREC corpus.</p><p>Six sets of documents were created that varied in size. For the purposes of this paper, the primary focus of the comparison is on the time required and the memory usage needed for clustering. Both approaches were performed on a single machine and were implemented using Java. For larger or distributed data sets, the multi-agent approach could be used on multiple machines. <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure">Figure 2</ref> show the time results of both approaches. Notice that for smaller data sets, the multiagent approach performed poorly, requiring nearly twice the amount of time. This is due to the communication overhead of the agent architecture. However, this communication overhead becomes insignificant once the document set reaches 500 in size. The speed-up then becomes increasingly significant as the number of documents increases. In fact, the multi-agent system could handle 2000 documents in less time than the TFIDF/HAC approach could handle 1000 documents.    <ref type="figure">Figure 3</ref> show the memory usage comparison between the two approaches. Notice that the usage is not significantly different. Notice also that as the data set doubled in size, nearly doubled as well. While the agent architecture does not store or use global term frequency counts, the memory usage for the multi-agent system remains approximately the same due to the memory requirements of the agent infrastructure and communication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2. Multi-agent clustering memory usage</head><p>There are a number of complex issues in comparing clustering results. In a preliminary experiment, we had several human subjects manually cluster a set of documents so that the results could then be compared to both the HAC and multi-agent clustering methods. The multi-agent approach yielded results closer to the manually generated clusters than the HAC method. Clearly more analysis is required; however, using our test dataset, we can not reject the hypothesis that the multiagent clustering method achieves results very similar to manually derived sets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Documents</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>The distributed agent-based clustering worked surprisingly fast for large document sets. In addition, it allows for distributed processing of documents, and a hybrid k-mean and hierarchical clustering result. With this approach, it will be possible to cluster massive amounts of textual information in relatively short amounts of time, due to the scalability of the agent architecture. We plan to explore further the scalability of the agent architecture presented in this paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Multi-agent architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 . Comparison of time between the multi- agent and HAC approaches Figure 3 . Comparison of memory usage between the multi-agent and HAC approaches</head><label>23</label><figDesc>Figure 2. Comparison of time between the multiagent and HAC approaches</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . Time Comparison</head><label>1</label><figDesc></figDesc><table>Number of 
Documents 

Multi-agent 
Time (seconds) 

TFIDF/HAC 
Time (seconds) 
50 
2.9 
1.8 
100 
6.3 
3.3 
250 
24.1 
15.6 
500 
71.1 
119.8 
1000 
195.3 
868.1 
2000 
576.0 
N/A 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 and</head><label>2</label><figDesc></figDesc><table></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Elmore</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Frederick</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dynamic Data Fusion Using An Ontology-Based Software Agent System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheldon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IIIS Agent Based Computing</title>
		<meeting>the IIIS Agent Based Computing<address><addrLine>Orlando, 7/</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Results and Challenges in Web Search Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thistlewaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harmon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1321" to="1330" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Development of a Stemming Algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Lovins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mechanical Translation and Computational Linguistics</title>
		<imprint>
			<date type="published" when="1968" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="22" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">An Algorithm for Suffix Stripping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">VIPAR: Advanced Information Agents discovering knowledge in an open and changing environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">E</forename><surname>Potok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Elmore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><forename type="middle">T</forename><surname>Sheldon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">World Multiconference on Systemics, Cybernetics and Informatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Multi-Agent System for Analyzing Massive Scientific Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">W</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">E</forename><surname>Potok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Software Engineering</title>
		<meeting>the International Conference on Software Engineering</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computer Evaluation of Indexing and Text Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lesk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="36" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Term Weighting Approaches in Automatic Text Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Overview of the Fifth Text REtrieval Conference (TREC-5)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Text Retrieval Conference</title>
		<meeting>the Fifth Text Retrieval Conference</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Evaluation of Hierarchical Clustering Algorithms for Document Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<idno>#02-022</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>University of Minnesota</orgName>
		</respStmt>
	</monogr>
<note type="report_type">Technical Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
