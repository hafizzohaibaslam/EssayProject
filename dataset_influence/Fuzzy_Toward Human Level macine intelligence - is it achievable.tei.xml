<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-16T23:53+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toward Human Level Machine Intelligence - Is It Achievable? The Need for a Paradigm Shift</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
				<availability status="unknown"><p>Copyright Institute of Electrical and Electronics Engineers (IEEE)</p>
				</availability>
				<date type="published" when="2008-08">2008-08</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lotfi</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Toward Human Level Machine Intelligence - Is It Achievable? The Need for a Paradigm Shift</title>
					</analytic>
					<monogr>
						<title level="j" type="main">IEEE Computational Intelligence Magazine</title>
						<title level="j" type="abbrev">IEEE Comput. Intell. Mag.</title>
						<idno type="ISSN">1556-603X</idno>
						<imprint>
							<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
							<biblScope unit="volume">3</biblScope>
							<biblScope unit="issue">3</biblScope>
							<biblScope unit="page" from="11" to="22"/>
							<date type="published" when="2008-08" />
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/mci.2008.926583</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>Officially, AI was born in 1956. Since then, very impressive progress has been made in many areas-but not in the realm of human level machine intelligence.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A chievement of human level machine intelligence (HLMI) has profound implications for modern society-a society which is becoming increasingly infocentric in its quest for efficiency, convenience and enhancement of quality of life. Achievement of human level machine intelligence has long been one of the basic objectives of AI. In the fifties of last century, the question "Can machines think?" was an object of many spirited discussions and debates <ref type="bibr" target="#b4">(Dreyfus and Dreyfus 2000)</ref>. Exaggerated expectations were the norm, with few exceptions. In an article "Thinking machines-a new field in electrical engineering," published in January l950, I began with a sample of headlines of articles which appeared in the popular press in the late forties. One of them read "Electric brain capable of translating foreign languages is being built." Today, more than half a century later, we have translation software, but nothing that approaches the level of human translation. In l948, on the occasion of inauguration of IBM's Mark l relay computer, Howard Aiken, Director of Harvard's Computation Laboratory, said "There is no problem in applied mathematics that this computer cannot solve." Today, there is no dearth of problems which cannot be solved by any supercomputer. Exaggerated expectations should be forgiven. As Jules Verne wrote at the turn of last century, "Scientific progress is driven by exaggerated expectations."</p><p>Where do we stand today? What can we expect in the future? Officially, AI was born in l956. Today, half a century later, there is much that AI can be proud of-but not in the realm of human level machine intelligence. A telling benchmark is summarization. We have software that can passably summarize a class of documents but nothing that can summarize miscellaneous articles, much less books. We have humanoid robots but nothing that can compare in agility with that of a four year old child. We can automate driving a car in very light city traffic but there is nothing on the horizon that could automate driving in Cairo. Far too often, we have to struggle with a dumb automated customer service system which we are forced to use. Such experiences make us keenly aware that human level machine intelligence is an objective rather than reality. The Turing Test lies far beyond. What should be noted, however, is that authoritative views within the AI community tend to be substantially more optimistic. Representative views can be found in ( <ref type="bibr" target="#b8">Guha and Lenat 1994;</ref><ref type="bibr" target="#b9">Hibbard 2002;</ref><ref type="bibr">H. Kurzweil 2005;</ref><ref type="bibr" target="#b13">McCarthy 2007;</ref><ref type="bibr" target="#b14">Minsky et al 2004)</ref>.</p><p>In an article "A new direction in AI-toward a computational theory of perceptions," AI Magazine, 200l, I argued that, in large measure, the lack of significant progress in many realms of human level machine intelligence is attributable to AI's failure to develop a machinery for dealing with perceptions. Underlying human level machine intelligence are two remarkable human capabilities. First, the capability to perform a wide variety of physical and mental tasks, such as driving a car in heavy city traffic, without any measurements and any computations. And second, the capability to reason, converse and make rational decisions in an environment of imprecision, uncertainty, incompleteness of information, partiality of truth and partiality of possibility. A principal objective of human level intelligence is mechanization of these remarkable human capabilities.</p><p>What is widely unrecognized within the AI community is that mechanization of these capabilities is beyond the reach of methods based on classical, Aristotelian, bivalent logic and bivalent-logic-based probability theory. In short, if the question is: Can human level machine intelligence be achieved through the use of methods based on bivalent logic and bivalent-logic-based probability theory, then in my view the answer is: No. If the question is: Can human level machine intelligence be achieved sometime in the future, then my answer is: Possibly, but the challenge will be hard to meet. Extensions of existing techniques will not be sufficient. Basically, what is needed is a paradigm shift. More specifically, what is needed is an addition to the armamentarium of AI of two methodologies: (a) a nontraditional methodology of computing with words (CW) or, more generally, NL-Computation; and (b) a countertraditional methodology which involves a progression from computing with numbers to computing with words. The centerpiece of these methodologies is the concept of precisiation of meaning-a concept drawn from fuzzy logic.</p><p>What is fuzzy logic? What does it have to offer? There are many misconceptions about fuzzy logic. The following pr¨¦cis of fuzzy logic is intended to correct the misconceptions.</p><p>Fuzzy logic is not fuzzy. Basically, fuzzy logic is a precise logic of imprecision and approximate reasoning. In fact, fuzzy logic is much more than a logical system. It has many facets. The principal facets are logical, fuzzy-set-theoretic, epistemic and relational <ref type="figure" target="#fig_1">(Figure 1)</ref>. Most of the applications of fuzzy  logic involve the concept of a linguistic variable and the machinery of fuzzy if-then rules. The formalism of linguistic variables and fuzzy if-then rules is associated with the relational facet. The cornerstones of fuzzy logic are graduation, granulation, precisiation and the concept of a generalized constraint ( <ref type="figure" target="#fig_2">Figure 2</ref>). Graduation should be understood as an association of a concept with grades or degrees.</p><p>In fuzzy logic, everything is or is allowed to be a matter of degree or, equivalently, fuzzy. Furthermore, in fuzzy logic everything is or is allowed to be granulated, with a granule being a clump of attribute values drawn together by indistinguishability, equivalence, proximity or functionality. Graduated granulation or, equivalently, fuzzy granulation is inspired by what humans employ to deal with complexity, imprecision and uncertainty. Graduated granulation underlies the concept of a linguistic variable. When Age, for example, is treated as a linguistic variable, its granular values may be young, middleaged and old. The granular values of Age are labels of fuzzy sets. Informally, a fuzzy set is a class with unsharp boundary. A fuzzy set is defined by its membership function. A trapezoidal membership which defines middle-age is shown in <ref type="figure" target="#fig_3">Figure 3</ref>.</p><p>A concept which plays a pivotal role in fuzzy logic is that of a generalized constraint, <ref type="bibr" target="#b29">(Zadeh 1986</ref><ref type="bibr" target="#b37">(Zadeh , 2008</ref> represented as X isr R, where X is the constrained variable, R is the constraining relation and r is an indexical variable which defines the modality of the constraint, that is, its semantics. The principal generalized constraints are possibilistic, probabilistic and veristic. The fundamental thesis of fuzzy logic is that information may be represented as a generalized constraint. A consequence of the fundamental thesis is that the meaning of a proposition, p, may likewise be represented as a generalized constraint. The concept of a generalized constraint serves as a basis for representation of and computation with propositions drawn from a natural language. This is the province of NL-Computation/Computing with Words-computation with information described in natural language.</p><p>NL-Computation opens the door to achievement of human level machine intelligence. The validity of this assertion rests on two basic facts. First, much of human knowledge, and especially world knowledge, is described in natural language. And second, a natural language is basically a system for describing perceptions. What this implies is that NL-Computation serves two major functions: (a) providing a conceptual framework and techniques for precisiation of natural language in the context of human level machine intelligence; and (b) providing a capability to compute with natural language descriptions of perceptions. These capabilities play essential roles in progression toward human level machine intelligence.</p><p>Human level machine intelligence has many components. The principal components are shown in <ref type="figure" target="#fig_5">Figure 4</ref>. Basically, achievement of human level machine intelligence requires a mechanization of the components of HLMI. Among the principal components of HLMI the component which stands out in importance involves mechanization of natural language understanding. A prerequisite to mechanization of natural ? Imprecision of Meaning = Elasticity of Meaning       language understanding is precisiation of meaning. Humans can understand unprecisiated natural language but machines cannot ( <ref type="figure" target="#fig_6">Figure 5</ref>). What has been widely unrecognized is that in the final analysis, progress toward achievement of human level machine intelligence requires a resol ution of a critical problem-the problem of precisiation of meaning. The two cornerstones of fuzzy logic-precisiation of meaning and the concept of a generalized constraint-are of direct relevance to human level machine intelligence. The primary purpose of this paper is to bring these concepts to the attention of the Computational Intelligence community. The exposition which follows is based on <ref type="bibr" target="#b36">(Zadeh 2006</ref>) and <ref type="bibr" target="#b37">(Zadeh 2008)</ref>. Additional details may be found in these papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Precisiation Language p: Object of Precisiation</head><p>Semantic imprecision of natural languages is a very basic characteristic-a characteristic which is rooted in imprecision of perceptions. Basically, a natural language is a system for describing perceptions. Perceptions are imprecise. Imprecision of perceptions entails semantic imprecision of natural languages.</p><p>The concept of precisiation has few precursors in the literature of logic, probability theory and philosophy of languages <ref type="bibr" target="#b1">(Carnap 1950</ref>). The reason is that the conceptual structure of bivalent logic-on which the literature is based-is much too limited to allow a full development of the concept of precisiation. In HLMI what is used for this purpose is the conceptual structure of fuzzy logic.</p><p>Precisiation and precision have many facets. More specifically, it is expedient to consider what may be labeled ¦Ë-precisiation, with ¦Ë being an indexical variable whose values identify various modalities of precisiation. In particular, it is important to differentiate between precision in value (¦Í-precision) and precision in meaning (m-precision). For example, proposition X = 5 is ¦Í-precise and m-precise, but proposition 2 ¡Ü X ¡Ü 6, is ¦Í-imprecise and m-precise. Similarly, proposition "X is a normally distributed random variable with mean 5 and variance 2," is ¦Í-imprecise and mprecise. Some of the basic concepts relating to precisiation are defined in <ref type="figure" target="#fig_8">Figure 6</ref>.</p><p>A further differentiation applies to m-precisiation. Thus, mh-precisiation is human-oriented meaning precisiation, while it mm-precisiation is machine-oriented or, equivalently, mathematically-based meaning precisiation ( <ref type="figure">Figure 7</ref>). A dictionary definition may be viewed as a form of mh-precisiation, while a mathematical definition of a concept, e.g., stability, is mm-precisiation whose result is mm-precisiand of stability.</p><p>So far as imprecisiation is concerned, it may be forced or deliberate. Imprecisiation is forced when a precise value of a variable is not known. Imprecisiation is deliberate when a precise value is not needed and precision carries a cost. Familiar examples of deliberate imprecisiation are data compression and summarization. For convenience, the precisiand and imprecisiand of p are denoted as p * and *</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Concept of Precisiation</head><p>In one form or another, precisiation of meaning has always played an important role in science. Mathematics is a quintessential example of what may be called a meaning precisiation language. Precisiation of meaning has direct relevance to mechanization of natural language understanding. For this reason, precisiation of meaning is an issue that is certain to grow in visibility and importance as we move further into the age of machine intelligence and automated reasoning.</p><p>p, respectively. Note: Deliberate imprecisiation plays an important role in many applications of fuzzy logic especially in the realm of consumer products where cost is an important consideration. In such applications, what is employed is what is referred to as "The fuzzy logic gambit" <ref type="figure">(Figure 8</ref>). In the fuzzy logic gambit deliberate v-imprecisiation is followed by mm-precisiation.</p><p>A more general illustration of mm-precisiation relates to representation of a function as a collection of fuzzy if-then rules-a mode of representation which is widely used in practical applications of fuzzy logic <ref type="bibr" target="#b20">(Yen and Langari 1998)</ref>. More specifically, let f be a function from reals to reals which is represented as <ref type="figure" target="#fig_11">(Figure 9)</ref>.</p><formula xml:id="formula_0">f : if X is small then Y is small if X is medium than Y is large if X is large than Y is small</formula><p>where small, medium and large are labels of fuzzy sets. In this representation, the collection in question may be viewed as mhprecisiand of f . When the collection is interpreted as a fuzzy graph ( <ref type="bibr" target="#b23">Zadeh 1974</ref><ref type="bibr" target="#b30">Zadeh , 1996</ref>) representation of f assumes the form.</p><formula xml:id="formula_1">f * : small ¡Á small + medium ¡Á large + large ¡Á small</formula><p>which is a disjunction of Cartesian products of small, medium and large. This representation is mm-precisiand of f .</p><p>In general, a precisiend may have many precisiands. As an illustration, consider the proposition "X is approximately a," or "X is * a" for short, where a is a real number. How can "X is * a" be precisiated? The simplest precisiand of "X is * a" is "X = a," [Figures 10(a) and 10(b)]. This mode of precisiation is referred to as sprecisiation, with s standing for singular. This is a mode of precisiation which is widely used in science and especially in probability theory. In the latter case, most real-world probabilities are not known exactly but in practice are frequently computed with as if they are exact numbers. For example, if the probability of an event is stated to be 0.7, then it should be understood that 0.7 is actually * 0.7, that is, approximately 0.7. A standard practice is to treat * 0.7 as 0.7000¡­, that is, as an exact number.</p><p>Next in simplicity is representation of * a is</p><p>In dealing with meaning, it is necessary to differentiate between this intension or, equivalently, the intensional meaning, i-meaning, of p, and the extension, or, equivalently, the extensional, e-meaning of p. The concepts of extension and intension are drawn from logic and, more particularly, from modal logic and possible world semantics ( <ref type="bibr" target="#b2">Cresswell 1973</ref><ref type="bibr" target="#b12">, Lambert 1970</ref><ref type="bibr" target="#b0">, Belohlavek 2006</ref>). Basically, e -meaning is attribute-free and i-meaning is attribute-based. As a simple illustration, if A is a finite set in a universe of discourse, U , then the e-meaning of A, that is, its extension is the list of elements of A, {u 1 , ¡­, u n }, u i being the name of ith element of A, with no attributes associated with the u i . Let a(u i ) be an attribute-vector associated with each u i . Then the intension of A is a recognition algorithm which, given a(u i ), recognizes whether u i is or is not an element of A. If A is a fuzzy set with membership function ¦Ì A then the e-meaning and i-meaning of A may be expressed compactly as</p><formula xml:id="formula_2">e-meaning of A : A = {¦Ì A (u i )/u i }</formula><p>where ¦Ì A (u)/u means that ¦Ì A (u) is the grade of membership of u i in A; and an interval centering on a. This mode of precisiation is referred to c g-precisiation, with c g standing for crisp-granular. Next is f g-precisiation of * a, with the precisiand being a fuzzy interval centering on a. Next is p-precisiation of * a, with the precisiand being a probability distribution centering on a. And so on.</p><p>An analogy is helpful in understanding the relationship between a precisiend and its precisiands. More specifically, a mm-precisiand, p * , may be viewed as a model of precisiend, p, in the same sense as a differential equation may be viewed as a model of a physical system.</p><p>In the context of modeling, an important characteristic of a model is its "closeness of fit." In the context of NLComputation, an analogous concept is that of cointension. The concept is discussed in the following. Precisiation is a prerequisite to computation with information described in natural language. To be useful, precisiation of a precisiend, p, should result in a precisiand, p * , whose meaning, in some specified sense, should be close to that of p. Basically, cointension of p * and p is the degree to which the meaning of p   </p><formula xml:id="formula_3">i-meaning of A : ¦ÌA = {¦Ì A (a(u i ))/u i },</formula><p>with the understanding that in the i-meaning of A the membership function, ¦Ì A is defined on the attribute space. It should be noted that when A is defined through exemplification, it is said to be defined ostensively. Thus, o-meaning of A consists of exemplars of A. An ostensive definition may be viewed as a special case of extensional definition. A neural network may be viewed as a system which derives i-meaning from o-meaning.</p><p>Clearly, i-meaning is more informative than e-meaning. For this reason, cointension is defined in terms of intensions rather than extensions of precisiend and precisiand. Thus, meaning will be understood to be i-meaning, unless stated to the contrary. However, when the precisiend is a concept which plays the role of definiendum and we know its extension but not its intension, cointension has to involve the extension of the definiendum (precisiend) and the intension of the definiens <ref type="bibr">(precisiand)</ref>.</p><p>As an illustration, let p be the concept of bear market. A dictionary definition of p-which may be viewed as a mh-precisiand of preads "A prolonged period in which investment prices fall, accompanied by widespread pessimism." A widely accepted quantitative definition of bear market is: We classify a bear market as a 30 percent decline after 50 days, or a 13 percent decline after 145 days. (Shuster) This definition may be viewed as a mm-precisiand of bear market. Clearly, the quantitative definition, p * , is not a good fit to the perception of the meaning of bear market which is the basis for the dictionary definition. In this sense, the quantitative definition of bear market is not cointensive.</p><p>Intensions are more informative than extensions in the sense that more can be inferred from propositions whose meaning is expressed intensionally rather than extensionally. The assertion will be precisiated at a later point. For the present, a simple example will suffice.</p><p>Consider the proposition p: Most Swedes are tall. Let U be a population of n Swedes, U = (u 1 , . . . , u n ), u 1 = name of ith Swede.</p><p>A precisiand of p may be represented as</p><formula xml:id="formula_4">1 n Count(tall.Swedes) is most,</formula><p>where most is a fuzzy quantifier which is defined as a fuzzy subset of the unit interval (Zadeh 1983). Let ¦Ì tall (u i ), i = 1, . . . , n) be the grade of membership of u i in the fuzzy set of tall Swedes. Then the e-meaning of tall Swedes may be expressed in symbolic form as</p><formula xml:id="formula_5">Communication HHC HMC tall.Swedes = ¦Ì tall (u 1 )/u 1 + ¡¤ ¡¤ ¡¤ + ¦Ì tall (u n )/u n .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human-Human Communication</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human-Machine Communication</head><p>Accordingly, the i-precisiand of p may be expressed as 1 n (¦Ì tall (u 1 )) + ¡¤ ¡¤ ¡¤ + ¦Ì tall (u n ) is most.</p><p>? mm-precisiation is desirable but not mandatory.</p><p>? mm-precisiation is mandatory.</p><p>Similarly, the i-precisiand of p may be represented as 1</p><formula xml:id="formula_6">n (¦Ì tall (h 1 )) + ¡¤ ¡¤ ¡¤ + ¦Ì tall (h n ) is most.</formula><p>? Humans can understand unprecisiated natural language. Machines cannot.</p><p>As will be seen later, given the e-precisiend of p we can compute the answer to the query: How many Swedes are not tall?</p><p>The answer is 1-most. However, we cannot compute the Scientific Progress</p><p>? mh-Precisiation mm-Precisiation answer to the query: How many Swedes are short? The same applies to the query: What is the average height of Swedes? As will be shown later, the answers to these queries can be computed given the i-precisiand of p. The concept of cointensive precisiation has important implications for the way in which scientific concepts are defined. The standard practice is to define a concept within the conceptual structure of bivalent logic, leading to a bivalent definition under which the universe of discourse is partitioned into two classes: objects which fit the concept and those which do not, with no shades of gray allowed. Such definition is valid when the concept that is defined, the definiendum, is crisp, that is, bivalent. The problem is that in reality most scientific concepts are fuzzy, that is, are a matter of degree. Familiar examples are the concepts of causality, relevance, stability, independence and bear market. In general, when the definiendum (precisiend) is a fuzzy concept, the definiens (precisiand) is not cointensive, which is the case with the bivalent definition of bear market. More generally, bivalent definitions of fuzzy concepts are vulnerable to the Sorites (heap) paradox <ref type="bibr" target="#b17">(Sainsbury 1995)</ref>. between humans, HHC, precisiation of meaning is desirable but not mandatory. In communication between a human and machine, HMC, precisiation is mandatory because a machine cannot understand unprecisiated natural language. In the case of HMC, an important issue relates to whether the precisiator is the sender (human, s-precisiation) or the recipient (machine, rprecisiation) <ref type="figure" target="#fig_1">(Figure 12)</ref>. In most applications of fuzzy logic, the precisiator is the sender (human), an example is the Honda fuzzy logic transmission ( <ref type="figure" target="#fig_1">Figure 13)</ref>. In the case of s-precisiation, context-dependence is not a problem. As a consequence, precisiation is a much simpler function than it is in the case of rprecisiation. It should be noted that mechanization of natural language understanding involves for the most part r-precisiation.</p><p>In HHC, mm-precisiation is a major application area for generalized-constraint-based semantics <ref type="bibr" target="#b37">(Zadeh 2008)</ref>. Generalized-constraint-based semantics provides a basis for reformulation of bivalent-logic-based definitions of scientific concepts, associating Richter-like scales with concepts which are traditionally defined as bivalent concepts but in reality are fuzzy concepts. Examples: recession, civil war, arthritis, randomness, causality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">A Key Idea-the Meaning Postulate</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">The Concept of a Generalized Constraint</head><p>In fuzzy logic, a proposition, p, is viewed as an answer to a question, q, of the form "What is the value of X ?" Thus p is a carrier of information about X . In this perspective, the meaning of p, M (p), is the information which p carries about X . An important consequence of the fundamental thesis of fuzzy logic is what is referred to as the meaning postulate. In symbolic form, the postulate is expressed as M (p) = GC(X (p)), where GC(X (p)) is a generalized constraint on the variable which is constrained by p. In plain words, the meaning postulate assents that the meaning of a proposition may be represented as a generalized constraint. It is this postulate that makes the concept of a generalized constraint a cornerstone of fuzzy logic. By providing a mechanism for precisiating the meaning of a proposition, the concept of a generalized constraint opens the door to a wide-ranging enlargement of the role of natural languages in scientific theories. What is referred to as PNL, Precisiated Natural Language, serves this purpose <ref type="bibr" target="#b33">(Zadeh 2004</ref>).</p><p>A point which should be noted is that the question to which p is an answer is not uniquely determined by p; hence X (p) is not uniquely defined by p. Generally, however, among the possible questions there is one which is most likely. For example, if p is "Monika is young," then the most likely question is "How old is Monika?" In this example, X is Age(Monika).</p><p>The concept of precisiation has a direct bearing on communication in the context of human level machine intelligence ( <ref type="figure" target="#fig_1">Figure 11</ref> ? Sender: (a) I will be pleased to do so (s-precisiation) (b) sorry, it is your problem (r-precisiation)  C is the set of values which X is allowed to take. A typical constraint is hard (inelastic) in the sense that if u is a value of X then u satisfies the constraint if and only if u ¡Ê C . The problem with hard constraints is that most real-world constraints are not hard, meaning that most real-world constraints have some degree of elasticity. For example, the constraints "check-out time is 1 pm," and "speed limit is 100 kmh," are, in reality, not hard. How can such constraints be defined? The concept of a generalized constraint is motivated by questions of this kind <ref type="bibr" target="#b37">(Zadeh 2008)</ref>.</p><p>Real-world constraints may assume a variety of forms. They may be simple in appearance and yet have a complex structure. Reflecting this reality, a generalized constraint, GC (X ), is defined as an expression of the form.</p><p>? X is an n-ary variable, X = (X 1 , . . . , X n ) ? X is a proposition, e.g., X = Leslie is tall ? X is a function ? X is a function of another variable, X = f (Y ) ? X is conditioned on another variable, X /Y ? X has a structure, e.g., X = Location(Residence(Carol)) ? X is a group variable. In this case, there is a group, G <ref type="bibr">[A]</ref>;</p><p>with each member of the group, Name i , i = 1, . . . , n, associated with an attribute-value, A i . A i may be vectorvalued. Symbolically</p><formula xml:id="formula_7">G [A] : Name 1 /A 1 + . . . + Name n /A n . GC(X ) : X isr R,</formula><p>where X is the constrained variable; R is a constraining relation which, in general, is non-bivalent; and r is an indexing variable which identifies the modality of the constraint, that is, its semantics. The constrained variable, X , may assume a variety of forms. In particular,</p><formula xml:id="formula_8">Basically, G [A] is a relation. ? X is a generalized constraint, X = Y isr R.</formula><p>A generalized constraint is associated with a test-score function, ts(u), <ref type="bibr" target="#b27">(Zadeh 1982)</ref> which associates with each object, u, to which the constraint is applicable, the degree to which u satisfies the constraint. Usually, ts(u) is a point in the unit interval. However, if necessary, the test-score may be a vector, an element of a semiring <ref type="bibr" target="#b16">(Rossi 2003)</ref>, an element of a lattice <ref type="bibr" target="#b7">(Goguen 1969)</ref> or, more generally, an element of a partially ordered set, or a bimodal distribution-a constraint which will be described later. The test-score function defines the semantics of the constraint with which it is associated.</p><p>The constraining relation, R, is, or is allowed to be, nonbivalent (fuzzy). The principal modalities of generalized constraints are summarized in the following. X is small.</p><p>In this case, the fuzzy set labeled small is the possibility distribution of X (Zadeh 1978; <ref type="bibr" target="#b5">Dubois and Prade 1988)</ref>. If ¦Ì small is the membership function of small, then the semantics of "X is small" is defined by</p><formula xml:id="formula_9">Y *f = i A i ¡ÁB j(i) ¦² Pross{X = u} = ¦Ì small (u), B f</formula><p>where u is a generic value of X . with R playing the role of the probability distribution of X . For example.</p><formula xml:id="formula_10">A i A i ¡ÁB j(i) *f : ¦² X is N (m, ¦Ò 2 ) FIGURE 15 Fuzzy-graph extension principle. B = * f (A).</formula><p>means that X is a normally distributed random variable with mean m and variance ¦Ò 2 . If X is a random variable which takes values in a finite set {u 1 , . . . , u n } with respective probabilities p 1 , . . . , p n , then X may be expressed symbolically as</p><formula xml:id="formula_11">Ver(X is R) is t ?¡ú X is ¦Ì ?1 R (t),</formula><p>where ¦Ì ?1 R is inverse of the membership function of R, and t is a fuzzy truth value which is a subset of <ref type="bibr">[0,</ref><ref type="bibr" target="#b34">1]</ref>, <ref type="figure" target="#fig_1">Figure 14</ref>.</p><formula xml:id="formula_12">X isp (p 1 \u 1 + ¡¤ ¡¤ ¡¤ + p n \u n ), (d) Usuality ( r = u)</formula><p>with the semantics X isu R.</p><formula xml:id="formula_13">Prob(X = u i ) = p i , i = 1, . . . , n.</formula><p>What is important to note is that in fuzzy logic a probabilistic constraint is viewed as an instance of a generalized constraint.</p><p>When X is a generalized constraint, the expression</p><p>The usuality constraint presupposes that X is a random variable, and that probability of the event {X isu R} is usually, where usually plays the role of a fuzzy probability which is a fuzzy number <ref type="bibr">(Kaufman and Gupta 1985)</ref>. For example.</p><p>X isu small X isp R means that "usually X is small" or, equivalently, is interpreted as a probability qualification of X , with R being Prob{X is small} is usually. the probability of X , <ref type="bibr" target="#b24">(Zadeh 1979a</ref><ref type="bibr" target="#b26">(Zadeh , 1981</ref>. For example.</p><p>(X is small) isp likely, where small is a fuzzy subset of the real line, means that probability of the fuzzy event {X is small} is likely. More specifically, if X takes values in the interval <ref type="bibr">[a, b]</ref> and g is the probability density function of X , then the probability of the fuzzy event "X is small" may be expressed as <ref type="bibr" target="#b21">(Zadeh 1968)</ref> In this expression, small may be interpreted as the usual value of X . The concept of a usual value has the potential of playing a significant role in decision analysis, since it is more informative than the concept of an expected value.</p><formula xml:id="formula_14">b (e) Random-set ( r = v s) In X isrs R, Prob(X is small) = ¦Ì small (u)g(u)du. a Hence a ts(g) = ¦Ì likely ( g(u)¦Ì small (u)du). b</formula><p>This expression for test-score function defines the semantics of probability qualification of a possibilistic constraint.</p><p>X is a fuzzy-set-valued random variable and R is a fuzzy random set (f) Fuzzy-graph ( r = f q)</p><p>In</p><formula xml:id="formula_15">X isfg R, (c) Veristic ( r = v) X isv R,</formula><p>X is a function, f , and R is a fuzzy graph ( <ref type="bibr" target="#b23">Zadeh 1974</ref><ref type="bibr" target="#b30">Zadeh , 1996</ref> which constrains f <ref type="figure" target="#fig_1">(Figure 15)</ref>. A fuzzy graph is a disjunction of Cartesian granules expressed as where R plays the role of a verity (truth) distribution of X . In particular, if X takes values in a finite set {u 1 , . . . , u n } with respective verity (truth) values t 1 , . . . , t n , then X may be expressed as</p><formula xml:id="formula_16">R = A 1 ¡Á B 1 + ¡¤ ¡¤ ¡¤ + A n ¡Á B n , X isv (t 1 |u 1 + ¡¤ ¡¤ ¡¤ + t n |u n ),</formula><p>where the A i and B i , i = 1, ¡­, n, are fuzzy subsets of the real line, and ¡Á is the Cartesian product. A fuzzy graph is frequently described as a collection of fuzzy if-then rules ( <ref type="bibr" target="#b22">Zadeh 1973</ref><ref type="bibr" target="#b30">Zadeh , 1996</ref><ref type="bibr" target="#b15">Pedrycz and Gomide 1998;</ref><ref type="bibr" target="#b35">Bardossy and Duckstein 1995)</ref>.</p><p>meaning that Ve r(X = u i ) = t i , i = 1, . . . , n For example, if Robert is half German, quarter French and quarter Italian, then</p><formula xml:id="formula_17">R : if X is A i then Y is B i , i = 1, . . . , n. Ethnicity(Robert) isv 0.5|German + 0.25|French + 0.25|Italian</formula><p>The concept of a fuzzy-graph constraint plays an important role in applications of fuzzy logic ( <ref type="bibr" target="#b35">Bardossy and Duckstein 1995;</ref><ref type="bibr" target="#b6">Filev and Yager 1994;</ref><ref type="bibr" target="#b10">Jamshidi, Titli, Zadeh and Boverie 1997;</ref><ref type="bibr" target="#b19">Yen, Langari and Zadeh 1995)</ref>.</p><p>When X is a generalized constraint, the expression X isv R</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">The Concept of Bimodal Constraint/Distribution</head><p>In the bimodal constraint, is interpreted as verity (truth) qualification of X . For example, X isbm R, (X is small) isv very.true, R is a bimodal distribution of the form should be interpreted as "It is very true that X is small." The semantics of truth qualification is defined by <ref type="bibr" target="#b25">(Zadeh 1979b</ref>)</p><formula xml:id="formula_18">R : i P i \A i , i = 1, . . . , n.</formula><p>with the understanding that Prob(X is A i ) is P i . <ref type="bibr" target="#b32">(Zadeh 2002)</ref>, that is, P i is a granular value of Prob (X is A i ), i = 1, . . . , n. (See next section for definition of granular value).</p><p>To clarify the meaning of a bimodal distribution it is expedient to start with an example. I am considering buying Ford stock. I ask my stockbroker, "What is your perception of the near-term prospects for Ford stock?" He tells me, "A moderate decline is very likely; a steep decline is unlikely; and a moderate gain is not likely." My question is: What is the probability of a large gain?</p><p>Information provided by my stock broker may be represented as a collection of ordered pairs: ? Price: (unlikely, steep.decline), (very.likely, moderate. decline), (not.likely, moderate.gain)) In this collection, the second element of an ordered pair is a fuzzy event or, generally, a possibility distribution, and the first element is a fuzzy probability. The expression for Price is an example of a bimodal distribution.</p><p>The importance of the concept of a bimodal distribution derives from the fact that in the context of human-centric systems, most probability distributions are bimodal. Bimodal distributions can assume a variety of forms. The principal types are Type 1, Type 2 and Type 3 <ref type="bibr" target="#b24">(Zadeh 1979a</ref><ref type="bibr" target="#b26">(Zadeh , 1981</ref>. Type 1, 2 and 3 bimodal distributions have a common framework but differ in important detail <ref type="figure" target="#fig_1">(Figure 16</ref>). A bimodal distribution may be viewed as an important generalization of standard probability distribution. For this reason, bimodal distributions of Type 1, 2, 3 are discussed in greater detail in the following. ? Type 1 (default):</p><p>X is a random variable taking values in U A 1 , . . . ,A n , A are events (fuzzy sets) p i = Prob(X is A i ), i = 1, . . . , n i p i is unconstrained P i = granular value of P i BD: bimodal distribution: ((P 1 , A 1 ), ¡­, (P n , A n )) or, equivalently,</p><formula xml:id="formula_19">X isbm (P 1 \A 1 + ¡¤ ¡¤ ¡¤ + P n \A n )</formula><p>Problem: What is the granular probability, P, of A? In general, this probability is fuzzy-set-valued. ? Type 2 (fuzzy random set): X is a fuzzy-set-valued random variable with values A 1 , ¡­, A n (fuzzy sets) P i = Prob(X = A i ), i = 1, . . . , n P i : granular value of P i BD:</p><p>X isrs (P 1 \A 1 + ¡¤ ¡¤ ¡¤ + P n \A n ) i p i = 1 Problem: What is the granular probability, P, of A? P is not definable. What are definable are (a) the expected value of the conditional possibility of A given BD, and (b) the expected value of the conditional necessity of A given BD ? Type 3 (Dempster-Shafer) <ref type="bibr" target="#b3">(Dempster 1967</ref><ref type="bibr" target="#b18">, Shafer 1976</ref>:</p><p>X is a random variable taking values X 1 , . . . , X n with probabilities p 1 , . . . , p n X i is a random variable taking values in</p><formula xml:id="formula_20">A i , i = 1, . . . , n Probability distribution of X i in A i , i = 1, . . . , n , is not specified X isp (p 1 \X 1 + ¡¤ ¡¤ ¡¤ + p n \X n ) Problem: What is the probability, p, that X is in A ?</formula><p>Because probability distributions of the X i in the A i are not specified, p is interval-valued. What is important to note is that the concepts of upper and lower probabilities break down when the A i are fuzzy sets (Zadeh 1979a). Note: In applying Dempster-Shafer theory it is important to check on whether the data fit Type 3 model. In many cases, the correct model is Type 1 rather than Type 3.</p><p>The importance of bimodal distributions derives from the fact that in many realistic settings a bimodal distribution is the best approximation to our state of knowledge. An example is assessment of degree of relevance, since relevance is generally not well defined. If I am asked to assess the degree of relevance of a book on knowledge representation to summarization, my state of knowledge about the book may not be sufficient to justify an answer such as 0.7. A better approximation to my state of knowledge may be "likely to be high." Such an answer is an instance of a bimodal distribution. A special case of primary constraints is what may be called standard constraints: bivalent possibilistic, probabilistic and bivalent veristic. Standard constraints form the basis for the conceptual framework of bivalent logic and probability theory.</p><p>A generalized constraint is composite if it can be generated from other generalized constraints through conjunction, and/or projection and/or constraint propagation and/or qualification and/or possibly other operations. For example, a random-set constraint may be viewed as a conjunction of a probabilistic constraint and either a possibilistic or veristic constraint. The DempsterShafer theory of evidence is, in effect, a theory of possibilistic random-set constraints. The derivation graph of a composite constraint defines how it can be derived from primary constraints.</p><p>The three primary constraints-possibilistic, probabilistic and veristic-are closely related to a concept which has a position of centrality in human cognition-the concept of partiality. In the sense used here, partial means: a matter of degree or, more or less equivalently, fuzzy. In this sense, almost all human concepts are partial (fuzzy). Familiar examples of fuzzy concepts are: knowledge, understanding, friendship, love, beauty, intelligence, belief, causality, relevance, honesty, mountain and, most important, truth, likelihood and possibility. Is a specified concept, C , fuzzy? A simple test is: If C can be hedged, then it is fuzzy. For example, in the case of relevance, we can say: very relevant, quite relevant, slightly relevant, etc. Consequently, relevance is a fuzzy concept.</p><p>The three primary constraints may be likened to the three primary colors: red, blue and green. In terms of this analogy, existing theories of uncertainty may be viewed as theories of different mixtures of primary constraints. For example, the Dempster-Shafer theory of evidence is a theory of a mixture of probabilistic and possibilistic constraints. The Generalized Theory of Uncertainty (GTU) <ref type="bibr" target="#b36">(Zadeh 2006</ref>  A very simple example of a semantic rule is:</p><formula xml:id="formula_21">(X is A) ¡Ä (Y is B) ?¡ú Poss(X is A) ¡Ä Poss(Y is B ), = ¦Ì A (u) ¡Ä ¦Ì B (v),</formula><p>where u and v are generic values of X , Y ; and ¦Ì A and ¦Ì B are the membership functions of A and B, respectively. In principle, GCL is an infinite set. However, in most applications only a small subset of GCL is likely to be needed.</p><p>A key idea which underlies NL-Computation is embodied in the meaning postulate-a postulate which asserts that the meaning of a proposition, p, drawn from a natural language is representable as a generalized constraint. In the context of GCL, the meaning postulate asserts that p may be precisiated through translation into GCL. Transparency of translation may be enhanced through annotation. Simple example of annotation, Monika is young ?¡ú X /Age (Monika) is R/young.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">The Generalized Constraint Language and Standard Constraint Language</head><p>A concept which has a position of centrality in GTU is that of Generalized Constraint Language (GCL). Informally, GCL is the set of all generalized constraints together with the rules governing syntax, semantics and generation. Simple examples of elements of GCL are:</p><formula xml:id="formula_22">(X is small ) is likely ((X , Y ) isp A) ¡Ä (X is B) (X isp A) ¡Ä ((X , Y ) isv B) Proj Y ((X is A) ¡Ä (X , Y ) isp B),</formula><p>where ¡Ä is conjunction.</p><p>In fuzzy logic, the set of all standard constraints together with the rules governing syntax, semantics and generation constitute the Standard Constraint Language (SCL). SCL is a subset of GCL.</p><p>In previous sections, we have employed the concept of a granular value in an informal fashion, without formulating a definition. The concept of a generalized constraint makes it possible to define a granular value more precisely. Let X be a variable taking values in a universe of discourse U, U = {u}. If a is an element of U , and it is known that the value of X is a, then a is referred to as a singular value of X . If there is some uncertainty about the value of X , the available information induces a restriction on the possible values of X which may be represented as a generalized constraint GC(X ), X isr R. Thus a generalized constraint defines a granule which is referred to as a granular value of X , G r(X ) <ref type="figure" target="#fig_1">(Figure 17</ref>). For example, if is known to lie in the interval [a h], then <ref type="bibr">[a, h]</ref> is a granular value of X . Similarly, if X isp N (m, ¦Ò 2 ), then N (m, ¦Ò 2 ) is a granular value of X . What is important to note is that defining a granular value in terms of a generalized constraint makes a granular value mm-precise. It is this characteristic of granular values that underlies the concept of a linguistic variable <ref type="bibr" target="#b22">(Zadeh 1973)</ref>. Symbolically, representing a granular value as a generalized constraint may be expressed as Gr(X ) = GC(X ). It should be noted that, in general, perception-based information is granular <ref type="figure" target="#fig_1">(Figure 17</ref>.</p><p>The importance of the concept of a granular value derives from the fact that it plays a central role in computation with information described in natural language. More specifically, when a proposition expressed in a natural language is represented as a system of generalized constraints, it is, in effect, a system of granular values. Thus, computation with information described in natural language ultimately reduces to computation with granular values. Such computation is the province of Granular Computing <ref type="bibr" target="#b24">(Zadeh 1979a</ref><ref type="bibr" target="#b31">(Zadeh , 1998</ref><ref type="bibr" target="#b34">Bargiela and Pedrycz 2002)</ref>. <ref type="bibr">[15]</ref> R. Kurzweil, Singularity is Near. Viking Press, New <ref type="bibr">York, 2005.</ref> There are many reasons why achievement of human level machine intelligence is a challenge that is hard to meet. One of the principal reasons is the need for mechanization of two remarkable human capabilities. First, the capability to converse, communicate, reason and make rational decisions in an environment of imprecision, uncertainty, incompleteness of information, partiality of truth and partiality of possibility. And second, the capability to perform a wide variety of physical and mental tasks-such as driving a car in heavy city traffic-without any measurements and any computations. What is well understood is that a prerequisite to mechanization of these capabilities is mechanization of natural language understanding. But what is widely unrecognized is that mechanization of natural language understanding is beyond the reach of methods based on bivalent logic and bivalent-logic-based probability theory. In addition, what is widely unrecognized is that mechanization of natural language understanding is contingent on precisiation of meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Concluding Remarks</head><p>Humans can understand unprecisiated natural language but machines cannot. Natural languages are intrinsically imprecise. Basically, a natural language is a system for describing perceptions. Perceptions are intrinsically imprecise. Imprecision of natural languages is rooted in imprecision of perceptions.</p><p>The principal thesis of this paper is that to address the problem of precisiation of meaning it is necessary to employ the machinery of fuzzy logic. In addition, the machinery of fuzzy logic is needed for mechanization of human reasoning. In this perspective, fuzzy logic is of direct relevance to achievement of human level machine intelligence. The cornerstones of fuzzy logic are the concepts of graduation, granulation, precisiation and generalized constraint.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIGURE 1</head><label>1</label><figDesc>FIGURE 1 Principal facets of fuzzy logic (FL). The core of FL is graduation/granulation (G/G).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 2</head><label>2</label><figDesc>FIGURE 2 The cornerstones of a nontraditional view of fuzzy logic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 3</head><label>3</label><figDesc>FIGURE 3 Imprecision of meaning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>FIGURE 4</head><label>4</label><figDesc>FIGURE 4 HLMI-Principal concepts and ideas.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>FIGURE 5</head><label>5</label><figDesc>FIGURE 5 Achievement of human level machine intelligence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>?</head><label></label><figDesc>Precisiand = Model of Meaning ? Intension = Attribute-Based Meaning ? Cointension = Measure of Closeness of Meanings = Measure of Goodness of Model ? A precisiend has many precisiands. Precisiation = Translation into a Precisiation Language</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>FIGURE 6</head><label>6</label><figDesc>FIGURE 6 Basic concepts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fuzzy</head><label></label><figDesc>FIGURE 8 The fuzzy logic gambit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>If X Is Small then Y Is Small f *f : Granulation If X Is Medium then Y Is Large Summarization If X Is Large then Y Is Small * fits the meaning of p.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>FIGURE 9</head><label>9</label><figDesc>FIGURE 9 Granulation of a function. S (small), M (medium) and L (large) are fuzzy sets. The granuland of f, *f, may be viewed as a summary of f.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>FIGURE 10 (</head><label>10</label><figDesc>FIGURE 10 (a) Alternative modes of mm-precisiation of "approximately a," *a, within the framework of bivalent logic. (b) Alternative modes of mm-precisiation of "approximately a," *a, within the framework of fuzzy logic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>FIGURE 11 Precisiation in communication.</head><label>11</label><figDesc>FIGURE 11 Precisiation in communication.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>). In communication Constraints are ubiquitous. A typical constraint is an expression of the form X ¡Ê C , where X is the constrained variable and Human (H) Human (H) or Machine (M) Sender Recipient Proposition Command Question ? Recipient: I understand what you sent, but could you precisiate what you mean, using ¡­ (restrictions)?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>FIGURE 12</head><label>12</label><figDesc>FIGURE 12 Precisiation in communication-Basic idea.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>FIGURE 13 Honda fuzzy logic transmission.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>FIGURE 14 Truth-qualification: (X is small) is t.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>(</head><label></label><figDesc>b) Probabilistic ( r = p) X isp R, 0 X</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>FIGURE 17</head><label>17</label><figDesc>FIGURE 17 Singular and granular values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>1 P 2 P P n Granules 0 X A 1 A 2 A A nis R, Probabilistic constraint: X isp R, U and Veristic constraint: X isv R. A Granular Value of X u Singular Value of X</head><label></label><figDesc></figDesc><table>Distribution 

p 1 

P 

p n 

g(u): Probability 
Density of X 

¡­ 

8. Primary Constraints, 
Composite Constraints 
and Standard Constraints 

P Among the principal generalized con-
straints there are three that play the 
role of primary generalized con-
straints. They are: 

Possibility Distribution of 
Probability Distributions 

Probability Distribution of 
Possibility Distributions 

FIGURE 16 Bimodal distributions. Granular versus granule-valued distributions. Possibilistic constraint: 
X </table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head></head><label></label><figDesc>) embraces all possible mixtures.</figDesc><table>Universe of Discourse 

Singular 
Granular 

7.3% 
High 

Unemployment 

102.5 
Very High 

Temperature 

160/80 
High 

Blood Pressure 

</table></figure>

			<note place="foot" n="14"> IEEE COMPUTATIONAL INTELLIGENCE MAGAZINE | AUGUST 2008</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>Research is supported in part by ONR N00014-02-1-0294, BT Grant CT1080028046, Omron Grant, Tekes Grant, Chevron Texaco Grant, and the BISC Program of UC Berkeley.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Attribute Implications in a Fuzzy Setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Belohlavek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vychodil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICFCA 2006</title>
		<editor>B. Ganter and L. Kwuida</editor>
		<imprint>
			<publisher>Heidelberg</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">3874</biblScope>
			<biblScope unit="page" from="45" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The Logical Foundations of Probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Carnap</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1950" />
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Logic and Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Cresswell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<pubPlace>Methuen, London, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Upper and Lower Probabilities Induced by a Multivalued Mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math Statist</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="325" to="329" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Mind and Machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dreyfus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dreyfus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Free Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Representation and combination of uncertainty with belief functions and possibility measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Prade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="244" to="264" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Filev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Yager</surname></persName>
		</author>
		<title level="m">Essentials of Fuzzy Modeling and Control</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The logic of inexact concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Goguen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="325" to="373" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Enabling agents to work together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Lenat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="126" to="142" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Super Intelligent Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hibbard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Applications of Fuzzy Logic-Towards High Machine Intelligence Quotient Systems, Environmental and Intelligent Manufacturing Systems Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jamshidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Titli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boverie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Prentice Hall</publisher>
			<biblScope unit="volume">9</biblScope>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Introduction to Fuzzy Arithmetic: Theory and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Gupta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>Von Nostrand</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Meaning relations, possible objects and possible worlds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Van Fraassen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
	<note>Philosophical Problems in Logic</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">From here to human-level AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="1174" to="1182" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The St. Thomas Common sense symposium: Designing architectures for human-level intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sloman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="124" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Introduction to Fuzzy Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gomide</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Codognet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Constraints, Special issue on Constraints. Kluwer</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Sainsbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paradoxes</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A Mathematical Theory of Evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shafer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<publisher>Princeton University Press</publisher>
			<pubPlace>Princeton, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Industrial Applications of Fuzzy Logic and Intelligent Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Langari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Langari</surname></persName>
		</author>
		<title level="m">Fuzzy Logic: Intelligence, Control and Information</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Probability measures of fuzzy events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jour. Math. Analysis and Appl</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="421" to="427" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Outline of a new approach to the analysis of complex systems and decision processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Systems, Man and Cybernetics SMC</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="28" to="44" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Systems Approaches and Environment Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vandenhoeck and Ruprecht</title>
		<editor>H. Gottinger</editor>
		<meeting><address><addrLine>Gottingen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="page" from="23" to="37" />
		</imprint>
	</monogr>
	<note>On the analysis of large scale systems</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fuzzy sets and information granularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Fuzzy Set Theory and Applications</title>
		<editor>M. Gupta, R. Ragade and R. Yager</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>North-Holland Publishing Co</publisher>
			<date type="published" when="1979" />
			<biblScope unit="page" from="3" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A theory of approximate reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
		<editor>J. Hayes, D. Michie, and L. I. Mikulich</editor>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Halstead Press</publisher>
			<biblScope unit="page" from="149" to="194" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Machine Intelligence 9</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Possibility theory and soft data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Frontiers of the Social and Policy Sciences</title>
		<editor>L. Cobb and R.M. Thrall</editor>
		<imprint>
			<biblScope unit="page" from="69" to="129" />
			<date type="published" when="1981" />
			<publisher>Westview Press, CO</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Test-score semantics for natural languages and meaning representation via PRUF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Empirical Semantics</title>
		<editor>B. Rieger</editor>
		<imprint>
			<biblScope unit="page" from="281" to="349" />
			<date type="published" when="1982" />
			<publisher>Brockmeyer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A computational approach to fuzzy quantifiers in natural languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Mathematics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="149" to="184" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Outline of a computational approach to meaning and knowledge representation based on the concept of a generalized assignment statement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Seminar on Artificial Intelligence and Man-Machine Systems</title>
		<editor>M. Thoma and A. Wyner</editor>
		<meeting>the International Seminar on Artificial Intelligence and Man-Machine Systems<address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="198" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fuzzy logic and the calculi of fuzzy rules and fuzzy graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Multiple-Valued Logic</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Some reflections on soft computing, granular computing and their roles in the conception, design and utilization of information/intelligent systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soft Computing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="23" to="25" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Toward a perception-based theory of probabilistic reasoning with imprecise probabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="233" to="264" />
			<date type="published" when="2002" />
			<publisher>Elsevier Science</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Precisiated natural language (PNL)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="74" to="91" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bargiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Granular</forename><surname>Computing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fuzzy Rule-Based Modelling with Application to Geophysical, Biological and Engineering Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bardossy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duckstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Generalized theory of uncertainty (GTU)-principal concepts and ideas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Statistics &amp; Data Analysis</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="15" to="46" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Is there a need for fuzzy logic?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Zadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="2751" to="2779" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
