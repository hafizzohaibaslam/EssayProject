<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-17T00:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Preference Networks: Probabilistic Models for Recommendation Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tran</forename><surname>The Truyen</surname></persName>
							<email>?thetruyen.tran@postgrad.curtin.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Curtin University of Technology GPO Box U 1987</orgName>
								<address>
									<settlement>Perth</settlement>
									<region>WA</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><forename type="middle">Q</forename><surname>Phung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Curtin University of Technology GPO Box U 1987</orgName>
								<address>
									<settlement>Perth</settlement>
									<region>WA</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetha</forename><surname>Venkatesh</surname></persName>
							<email>s.venkatesh@curtin.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Curtin University of Technology GPO Box U 1987</orgName>
								<address>
									<settlement>Perth</settlement>
									<region>WA</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Preference Networks: Probabilistic Models for Recommendation Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Hybrid Recommender Systems</term>
					<term>Collaborative Filtering</term>
					<term>Preference Networks</term>
					<term>Conditional Markov Net- works</term>
					<term>Movie Rating</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Recommender systems are important to help users select relevant and personalised information over massive amounts of data available. We propose an unified framework called Preference Network (PN) that jointly models various types of domain knowledge for the task of recommendation. The PN is a probabilistic model that systematically combines both content-based filtering and collab-orative filtering into a single conditional Markov random field. Once estimated, it serves as a probabilistic database that supports various useful queries such as rating prediction and top-N recommendation. To handle the challenging problem of learning large networks of users and items, we employ a simple but effective pseudo-likelihood with regularisation. Experiments on the movie rating data demonstrate the merits of the PN.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the explosive growth of the Internet, users are currently overloaded by massive amount of media, data and services.</p><p>Thus selective delivery that matches personal needs is very critical. Automated recommender systems have been designed for this purpose, and they are deployed in major online stores such as Amazon Two most common tasks in recommender systems are predicting the score the user might give for a product (the rating prediction task), and recommending a ranked list of most relevant items (the top-N recommendation task). The recommendations are made on the basis of the content of products and services (content-based), or based on collective preferences of the crowd (collaborative filtering), or both (hybrid methods). Typically, content-based methods work by matching product attributes to user-profiles using classification techniques. Collaborative filtering, on the other hand, relies on preferences over a set products that a given user and others have expressed. From the preferences, typically in term of numerical ratings, correlation-based methods measure similarities between users ( <ref type="bibr" target="#b7">Resnick et al. 1994</ref>) (user-based methods) and products ( <ref type="bibr" target="#b9">Sarwar et al. 2001</ref>) (item-based methods). As content and preferences are complementary, hybrid methods often work best when both types of information is available <ref type="bibr">(Balabanovi?cBalabanovi?c &amp; Shoham 1997</ref><ref type="bibr" target="#b0">, Basu et al. 1998</ref><ref type="bibr">, Paz- zani 1999</ref><ref type="bibr" target="#b10">, Schein et al. 2002</ref><ref type="bibr">, Basilico &amp; Hofmann 2004</ref>.</p><p>Probabilistic modeling ( <ref type="bibr">Breese et al. 1998</ref><ref type="bibr">, Hecker- man et al. 2001</ref><ref type="bibr">, Hofmann 2004</ref><ref type="bibr">, Marlin 2004</ref>) has been applied to the recommendation problem to some degree and their success has been mixed. Generally, they build probabilistic models that explain data. Earlier methods include Bayesian networks and dependency networks ( <ref type="bibr">Breese et al. 1998</ref><ref type="bibr">, Heckerman et al. 2001</ref>) have yet to prove competitive against well-known correlation-based counterparts. The more recent work attempts to perform clustering. Some representative techniques are mixture models, probabilistic latent semantic analysis (pLSA) <ref type="bibr">(Hofmann 2004</ref>) and latent Dirichlet allocation (LDA) <ref type="bibr">(Marlin 2004</ref>). These methods are generative in the sense that it assumes some hidden process that generates observed data such as items, users and ratings. The generative assumption is often made for algorithmic convenience and but it does not necessarily reflect the true process of the real data.</p><p>Machine learning techniques <ref type="bibr" target="#b4">(Billsus &amp; Pazzani 1998</ref><ref type="bibr" target="#b0">, Basu et al. 1998</ref><ref type="bibr">, Basilico &amp; Hofmann 2004</ref>) address the rating prediction directly without making the generative assumption. Rather, they map the recommendation into a classification problem that existing classifiers can solve ( <ref type="bibr" target="#b0">Basu et al. 1998</ref><ref type="bibr" target="#b1">, Zhang &amp; Iyengar 2002</ref>. The map typically considers each user or each item as an independent problem, and ratings are training instances. However, the assumption that training instances are independently generated does not hold in collaborative filtering. Rather all the ratings are interconnected directly or indirectly through common users and items.</p><p>To sum up, it is desirable to build a recommendation system that can seamlessly integrate content and correlation information in a disciplined manner. At the same time, the system should address the prediction and recommendation tasks directly without replying on strong prior assumptions such as generative process and independence. To that end, we propose a probabilistic graphical formulation called Preference Network (PN) that has these desirable properties. The PN is a graph whose vertexes represent ratings (or preferences) and edges represent dependencies between ratings. The networked ratings are treated as random variables of conditional Markov random fields ( <ref type="bibr">Lafferty et al. 2001</ref>). Thus the PN is a formal and expressive formulation that supports learning from existing data and various inference tasks to make future prediction and recommendation. The probabilistic dependencies between ratings capture the correlations between co-rating users (as used in <ref type="bibr" target="#b7">(Resnick et al. 1994)</ref>) and between corated items (as used in <ref type="bibr" target="#b9">(Sarwar et al. 2001)</ref>).</p><p>Different from previous probabilistic models, the PN does not make any generative assumption. Rather, prediction of preferences is addressed directly based on the content and prior ratings available in the database. It also avoids the independence assumption made in the standard machine learning approach by supporting collective clas-sification of preferences. The nature of graphical modeling enables PN to support missing ratings and joint predictions for a set of items and users. It provides some measure of confidence in each prediction made, making it easy to assess the nature of recommendation and rank results. More importantly, our experiments show that the PNs are competitive against the well-known user-based method <ref type="bibr" target="#b7">(Resnick et al. 1994</ref>) and the item-based method <ref type="bibr" target="#b9">(Sarwar et al. 2001</ref>). a user). Identifying the most relevant entries and ranking them are the goal of top-N recommendation.</p><p>Recommender techniques often fall into three groups: content-based, collaborative filtering, and hybrid methods that combines the former two groups. Content-based methods rely on the content of items that match a user's profile to make recommendation using some classification techniques (e.g. see <ref type="bibr">(Mooney &amp; Roy 2000)</ref>). The content of an item is often referred to the set of attributes that characterise it. For example, in movie recommendation, item attributes include movie genres, release date, leading actor/actress, director, ratings by critics, financial aspects, movie description and reviews. Similarly, user attributes include static information such as age 1 , sex, location, language, occupation and marriage status and dynamic information such as watching time (day/night/late night), context of use (e.g. home/theater/family/dating/group/company), and in case of on-demand videos, what other TV channels are showing, what the person has been watching in the past hours, days or weeks.  Collaborative filtering takes a different approach in that recommendation is based not only on the usage history of the user but also on experience and wisdom of related people in the user-item network. Most existing algorithms taking some measure of correlation between co-rating users or co-rated items. One family, known as user-based (sometimes memory-based) methods <ref type="bibr" target="#b7">(Resnick et al. 1994)</ref>, predicts a new rating of an item based on existing ratings on the same item by other users:  where s(u, v) is the similarity between user u and user v, U (i) is the set of all users who rate item i, and ? r u is the average rating by user u. The similarity s(u, v) is typically measured using Pearson's correlation: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Recommender Systems</head><formula xml:id="formula_0">r ui = ? r u + v¡ÊU (i) s(u, v)(r ui ? ? r v ) v¡ÊU (i) |s(u, v)|</formula><formula xml:id="formula_1">(a) (b) i¡ÊI(u,v) (r ui ? ? r u )(r vi ? ? r v ) 2</formula><p>Figure 2: User-based correlation (a) and Item-based cor-</p><formula xml:id="formula_2">relation (b). i¡ÊI(u,v) (r ui ? ? r u ) 2 1 2 j¡ÊI(u,v) (r vj ? ? r v ) 2 1</formula><p>This section provides some background on recommender systems and we refer readers to <ref type="bibr">(Adomavicius &amp; Tuzhilin 2005</ref>) for a more comprehensive survey. Let us start with some notations. Let U = {u 1 , . . . , u M } be the set of M users (e.g. service subscribers, movie viewers, Website visitors or product buyers), and I = {i 1 , . . . , i L } be the set of L products or items (e.g. services, movies, Webpages or books) that the user can select from. Let us further denote M = {r ui } the preference matrix where u is the user index, i is the item index, and r ui is the preference or the numerical rating of user u over item i (see <ref type="figure" target="#fig_3">Figure 1</ref> for an illustration). In this paper, we assume that ratings have been appropriately transformed into integers, i.e. r ui ¡Ê {1, 2, ..., S}.</p><p>Typically, a user usually rates only a small number of items and thus making the preference matrix M extremely sparse. For example, in the MovieLens dataset that we use in our experiments (Section 4), only about 6.3% entries in the M matrix are filled, and in large e-commerce sites, the sparsity can be as small as 0.001%. The rating prediction task in recommender systems can be considered as filling the empty cells in the preference matrix. Of course, due to the data sparsity, filling all the cells is impractical and often unnecessary because each user will be interested in a very small set of items. Rather, it is only appropriate for a limited set of entries in each row (corresponding to where I(u, v) is the set of all items co-rated by users u and v. See <ref type="figure">Figure 2a</ref> for illustration. This similarity is computed offline for every pair of users who co-rate at least one common item.</p><p>The main drawback of user-based methods is in its lack of efficiency at prediction time because each prediction require searching and summing over all users who rate the current item. The set of such users is often very large for popular items, sometimes including all users in the database. In contrast, each user typically rates only a very limited number of items. Item-based methods <ref type="bibr">(Sar- war et al. 2001)</ref> exploit that fact by simply exchanging the role of user and item in the user-based approach. Similarity between items s(i, j) can be computed in several ways including the (adjusted) cosine between two item vectors, and the Pearson correlation. For example, the adjusted cosine similarity is computed as</p><formula xml:id="formula_3">u¡ÊU (i,j) (r ui ? ? r u )(r uj ? ? r u ) u¡ÊU (i,j) (r ui ? ? r u ) 2 1 2 v¡ÊU (i,j) (r vj ? ? r v ) 2 1 2</formula><p>where U (i, j) is the set of all users who co-rate both items i and j. See <ref type="figure">Figure 2b</ref> for illustration. The new rating is predicted as</p><formula xml:id="formula_4">r ui = ? r i + j¡ÊI(u) s(i, j)(r uj ? ? r j ) j¡ÊI(u) |s(i, j)|</formula><p>a collaborative filtering method and then combining the results ( <ref type="bibr">Claypool et al. 1999</ref>). Others (e.g. <ref type="bibr">(Basilico &amp; Hofmann 2004)</ref>) create joint representation of content and collaborative features. We follow the latter approach.</p><p>where I(u) is the set of items rated by user u.</p><p>Many other methods attempt to build a model of training data that then use the model to perform prediction on unseen data. One class of methods employ probabilistic graphical models such as Bayesian networks ( <ref type="bibr">Breese et al. 1998</ref>), dependency networks ( <ref type="bibr">Heckerman et al. 2001)</ref>, and restricted Boltzmann machines ( <ref type="bibr" target="#b8">Salakhutdinov et al. 2007</ref>). Our proposed method using Markov networks fall under the category of undirected graphical models. It resembles dependency networks in the way that pseudolikelihood (Besag 1974) learning is employed, but dependency networks are generally inconsistent probabilistic models. In ( <ref type="bibr" target="#b8">Salakhutdinov et al. 2007)</ref>, the authors build a generative Boltzmann machine for each user with hidden variables, while our method constructs a single discriminative Markov network for the whole database of all ratings.</p><p>Much of other probabilistic work attempts to perform clustering. This is an important technique for reducing the dimensionality and noise, dealing with data sparsity and more significantly, discovering latent structures. Here the latent structures are either communities of users with similar tastes or categories of items with similar features. Some representative techniques are mixture models, probabilistic latent semantic analysis (pLSA) <ref type="bibr">(Hof- mann 2004</ref>) and latent Dirichlet allocation (LDA) <ref type="bibr">(Marlin 2004</ref>). These methods try to uncover some hidden process which is assumed to generate items, users and ratings. In our approach, no such generation is assumed and ratings are modeled conditionally given items and users and prior knowledge.</p><p>Statistical machine learning techniques <ref type="bibr" target="#b4">(Billsus &amp; Pazzani 1998</ref><ref type="bibr" target="#b0">, Basu et al. 1998</ref><ref type="bibr" target="#b1">, Zhang &amp; Iyengar 2002</ref><ref type="bibr">, Basilico &amp; Hofmann 2004</ref><ref type="bibr" target="#b3">, Zitnick &amp; Kanade 2004</ref>) have also been used to some extent. One of the key observations made is that there is some similarity between text classification and rating prediction <ref type="bibr" target="#b1">(Zhang &amp; Iyengar 2002)</ref>. However, the main difficulty is that the features in collaborative filtering are not rich and the nature of prediction is different. There are two ways to convert collaborative filtering into a classification problem <ref type="bibr" target="#b4">(Billsus &amp; Pazzani 1998</ref>). The first is to build a model for each item, and ratings by different users are treated as training instances. The other builds a model for each user, and ratings on different items by this user are considered as training instances ( <ref type="bibr">Breese et al. 1998</ref>). These treatments, however, are complementary, and thus, there should be a better way to systematically unify them ( <ref type="bibr" target="#b0">Basu et al. 1998</ref><ref type="bibr">, Basilico &amp; Hofmann 2004</ref>). That is, the pairs (user,item) are now as independent training instances. Our approach, on the other hand, considers the pair as just a node in the network, thus relaxing the independence assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preference Networks for Hybrid Recommendation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model Description</head><p>Let us start with the preference matrix M = {r ui } discussed previously (cf. Sec. 2), where we treat each entry r ui in M as a random variable, and thus ideally we would be interested in a single joint model over KM variables for both the learning phase and the prediction/recommendation phase. However, in practice, KM is extremely large (e.g., <ref type="bibr">10</ref> 6 ¡Á 10 6 ) making computation intractable. In addition, such a modeling is unnecessary, because, as we have mentioned earlier in Section 2, a user is often interested in a moderate number of items. As a result, we adopt a two-step strategy. During the learning phase, we limit to model the joint distribution over existing ratings. And then during the prediction/recommendation phase, we extend the model to incorporate to-be-predicted entries. Hybrid methods exploit the fact that content-based and collaborative filtering methods are complementary <ref type="bibr">(Balabanovi?cBalabanovi?c &amp; Shoham 1997</ref><ref type="bibr" target="#b0">, Basu et al. 1998</ref><ref type="bibr" target="#b5">, Pazzani 1999</ref><ref type="bibr" target="#b10">, Schein et al. 2002</ref><ref type="bibr">, Basilico &amp; Hofmann 2004</ref>). For example, the content-based methods do not suffer from the so-called cold-start problem ( <ref type="bibr" target="#b10">Schein et al. 2002</ref>) in standard collaborative filtering. The situation is when new user and new item are introduced to the database, as no previous ratings are available, purely correlation-based methods cannot work. On the other hand, content information available is sometimes very limited to basic attributes that are shared by many items or users. Prediction by pure content-based methods in that case cannot be personalised and may be inaccurate. Some work approaches the problem by making independent predictions separately using a content-based method and We build the model by first representing the ratings and their relations using an undirected graph and then defining a joint distribution over the graph. Denote by G = (V, E) an undirected graph that has a set of vertexes V and a set of edges E. Each vertex in V in this case represents a rating r ui of user u over item i and each edge in E capture a relation between two ratings. The set E defines a topological structure for the network, and specify how ratings are related.</p><p>We define the edges as follows. There is an edge between any two ratings by the same user, and an edge between two ratings on the same item. As a result, a vertex of r ui will be connected with U (i) + I(u) ? 2 other vertices. Thus, for each user, there is a fully connected subnetwork of all ratings she has made, plus connections to ratings by other users on these items. Likewise, for each item, there is a fully connected subnetwork of all ratings by different users on this item, plus connections to ratings on other items by these users. The resulting network G is typically very densely connected because U (i) can be potentially very large (e.g. 10 6 ). Let us now specify the probabilistic modeling of the ratings and their relations that respect the graph G. Denote t = (u, i) and let T = {t} be the set of a pair index (user, item), which corresponds to entries used in each phase. For notation convenience let X = {r ui | (u, i) ¡Ê T } denote the joint set of all variables, and the term 'preference' and 'rating' will be used interchangeably. When there is no confusion, we use r u to denote ratings related to user u and r i denotes ratings related to item i.</p><p>In our approach to the hybrid recommendation task, we consider attributes of items {a i } L i=1 , and attributes of users</p><formula xml:id="formula_5">{a u } M i=u . Let o = {{a i } L i=1 , {a u } M i=u</formula><p>}, we are interested in modeling the conditional distribution P (X|o) of all user ratings X given o. We employ the conditional Markov random field ( <ref type="bibr">Lafferty et al. 2001</ref>) as the underlying inference machinery. As X collectively represents users' preferences, we refer this model as Preference Network.</p><note type="other">Preference Network (PN) is thus a conditional Markov random field that defines a distribution P (X|o) over the graph G: two items then after offsetting the goodness of each item, the ratings may be similar</note><formula xml:id="formula_6">f i,j (r ui , r uj ) = g(|(r ui ? ? r i ) ? (r uj ? ? r j )|) P (X|o) = 1 Z(o) ¦·(X, o),</formula><p>where</p><formula xml:id="formula_7">¦·(X, o) = ¦× t,t (r t , r t , o) (1)</formula><p>Likewise, the user-user f u,v (¡¤) features capture the idea that if two users rate the same item then the ratings, after offset by user's own scale, should be similar:</p><formula xml:id="formula_8">t¡ÊV ¦× t (r t , o) (t,t )¡ÊE f u,v (r ui , r vi ) = g(|(r ui ? ? r u ) ? (r vi ? ? r v )|)</formula><p>where Z(o) is the normalisation constant to ensure that X P (X|o) = 1, and ¦×(.) is a positive function, often known as potential. More specifically, ¦× t (r t , o) encodes the content information associated with the rating r t including the attributes of the user and the item. On the other hand, ¦× t,t (r t , r t , o) captures the correlations between two ratings r t and r t . Essentially, when there are no correlation potentials, the model is purely content-based, and when there are no content potentials, the model is purely collaborative-filtering. Thus the PN integrates both types of recommendation in a seamlessly unified framework.</p><p>The contribution of content and correlation potentials to the joint distribution will be adjusted by weighting parameters associated with them. Specifically, the parameters are encoded in potentials as follows</p><p>Since the number of correlation features can be large, making model estimation less robust, we select only itemitem features with positive correlation (given in Equation 1), and user-user features with positive correlations (given in Equation 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Estimation</head><formula xml:id="formula_9">¦× t (r t , o) = exp w v f v (r t , o)<label>(2)</label></formula><p>Since the network is densely connected, learning methods based on the standard log-likelihood log P (X|o) are not applicable. This is because underlying inference for computing the log-likelihood and its gradient is only tractable for simple networks with simple chain or tree structures <ref type="bibr" target="#b6">(Pearl 1988)</ref>. As a result, we resort to the simple but effective pseudo-likelihood learning method <ref type="bibr">(Be- sag 1974)</ref>. Specifically, we replace the log likelihood by the regularised sum of log local likelihoods</p><formula xml:id="formula_10">¦× t,t (r t , r t , o) = exp w e f e (r t , r t , o)<label>(3)</label></formula><p>where f (.) is the feature vector and w is the corresponding weight vector. Thus together with their weights, the features realise the contribution of the content and the strength of correlations between items and users. The design of features will be elaborated further in Section 3.2.</p><p>Parameter estimation is described in Section 3.3.</p><formula xml:id="formula_11">L(w) = log P (r ui |N (u, i), o) ? 1 2 ? w ? w (4) (u,i)¡ÊT</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Design and Selection</head><p>Corresponding to the potentials in Equations 2 and 3, there are attribute-based features and correlation-based features.</p><p>Attribute-based features include user/item identities and contents. Identity Features. Assume that the ratings are integer, ranging from 1 to S. We know from the database the average rating ? r i of item i which roughly indicates the general quality of the item with respect to those who have rated it. Similarly, the average rating ? r u by user u over items she has rated roughly indicates the user-specific scale of the rating because the same rating of 4 may mean 'OK' for a regular user, but may mean 'excellent' for a critic. We use two features item-specific f i (r ui , i) and user-specific f u (r ui , u):</p><p>where, N (u, i) is the set of neighbour ratings that are connected to r ui . As we mentioned earlier, the size of the neighbourhood is |N (u, i)| = U (i) + I(u) ? 2. In the second term in the RHS, ? w = w/¦Ò (element-wise division, regularised by a prior diagonal Gaussian of mean 0 and standard deviation vector ¦Ò).</p><p>Finally, the parameters are estimated by maximising the pseudo-likelihood?w</p><formula xml:id="formula_12">likelihood? likelihood?w = arg max w L(w)<label>(5)</label></formula><p>Not only is this regularised pseudo-likelihood simple to implement, it makes sense since the local conditional distribution P (r ui |N (u, i), o) is used in prediction (Equation 7). We limit ourselves to supervised learning in that all the ratings {r ui } in the training data are known. Thus, L(w) is a concave function of w, and thus has a unique maximum.</p><p>To optimise the parameters, we use a simple stochastic gradient ascent procedure that updates the parameters after passing through a set of ratings by each user:</p><formula xml:id="formula_13">f i (r ui , i) = g(|r ui ? ? r i |), f u (r ui , u) = g(|r ui ? ? r u |) w u ¡û w u + ¦Ë?L(w u )<label>(6)</label></formula><p>where g(¦Á) = 1 ? ¦Á/(S ? 1) is used to ensure that the feature values is normalized to <ref type="bibr">[0,</ref><ref type="bibr">1]</ref>, and when ¦Á plays the role of rating deviation, g(¦Á) = 1 for ¦Á = 0. Content Features. For each rating by user u on item i, we have a set of item attributes a i and set of user attributes a u . Mapping from item attributes to user preference can be carried out through the following feature where w u is the subset of parameters that are associated with ratings by user u, and ¦Ë &gt; 0 is the learning rate. Typically, 2-3 passes through the entire data are often enough in our experiments. Further details of the computation are included in Appendix A.</p><formula xml:id="formula_14">f u (r ui ) = a i g(|r ui ? ? r u |)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Preference Prediction</head><p>Similarly, we are also interested in seeing the classes of users who like a given item through the following mapping</p><formula xml:id="formula_15">f i (r ui ) = a u g(|r ui ? ? r i |)</formula><p>Correlation Features. We design two features to capture correlations between items or users. Specifically, the item-item f i,j (¡¤) features capture the fact that if a user rates Recall from Section 3.1 that we employ a two-step modeling. In the learning phase (Section 3.3), the model includes all previous ratings. Once the model has been estimated, we extend the graph structure to include new ratings that need to be predicted or recommended. Since the number of ratings newly added is typically small compared to the size of existing ratings, it can be assumed that the model parameters do not change.</p><p>The prediction of the rating r ui for user u over item i is given as?r as? as?r ui = arg max rui P (r ui | N (u, i), o)</p><p>The probability P (? r ui |N (r ui ), o) is the measure of the confidence or ranking level in making this prediction. This can be useful in practical situations when we need high precision, that is, only ratings with the confidence above a certain threshold are presented to the users. We can jointly infer the ratings r u of given user u on a subset of items i = (i 1 , i 2 , ..) as follows items. The correlation is in turn captured by the corresponding correlation parameters. Thus, we can use either the user-user correlation or item-item correlation to identify the candidate set. Furthermore, we can also use both the correlation types and take the union of the two candidate sets.</p><formula xml:id="formula_17">? r u = arg max ru P (r u | N (u), o)<label>(8)</label></formula><p>where N (u) is the set of all existing ratings that share the common cliques with ratings by user u. In another scenario, we may want to recommend a relatively new item i to a set of promising users, we can make joint predictions r i as follows</p><p>Ranking the candidate set. The second step in the top-N recommendation is to rank these C candidates according to some scoring methods. Ranking in the user-based methods is often based on item popularity, i.e. the number of users in the neighbourhood who have rated the item. Ranking in the item-based methods <ref type="bibr">(Deshpande &amp; Karypis 2004</ref>) is computed by considering not only the number of raters but the similarity between the items being ranked and the set of items already rated by the user. Under our Preference Networks formulation, we propose to compute the change in system energy and use it as ranking measure. Our PN can be thought as a stochastic physical system whose energy is related to the conditional distribution as follows?r</p><formula xml:id="formula_18">follows? follows?r i = arg max ri P (r i | N (i), o)<label>(9)</label></formula><formula xml:id="formula_19">P (X|o) = 1 Z(o) exp(?E(X, o))<label>(10)</label></formula><p>where N (i) is the set of all existing ratings that share the common cliques with ratings of item i. It may appear nonobvious that a prediction may depend on unknown ratings (other predictions to be made) but this is the advantage of the Markov networks. However, joint predictions for a user are only possible if the subset of items is small (e.g. less than 20) because we have a completely connected subnetwork for this user. This is even worse for joint prediction of an item because the target set of users is usually very large.</p><p>where E(X, o) = ? log ¦·(X, o) is the system energy.</p><p>Thus the lower energy the system state X has, the more probable the system is in that state. Let t = (u, i), from Equations 2 and 3, we can see that the system energy is the sum of node-based energy and interaction energy</p><formula xml:id="formula_20">E(X, o) = E(r t , r t o) t¡ÊV E(r t , o) + (t,t )¡ÊE</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Top-N recommendation</head><p>where In order to provide a list of top-N items to a given user, the first step is usually to identify a candidate set of C promising items, where C ¡Ý N . Then in the second step, we rank and choose the best N items from this candidate set according to some measure of relevance.</p><formula xml:id="formula_21">E(r t , o) = ?w v f v (r t , o)<label>(11)</label></formula><formula xml:id="formula_22">E(r t , r t , o) = ?w e f e (r t , r t , o)<label>(12)</label></formula><p>Identifying the candidate set. This step should be as efficient as possible and C should be relatively small compared to the number of items in the database. There are two common techniques used in user-based and item-based methods, respectively. In the user-based technique, first we identify a set of K most similar users, and then take the union of all items co-rated by these K users. Then we remove items that the user has previously rated. In the item-based technique <ref type="bibr">(Deshpande &amp; Karypis 2004</ref>), for each item the user has rated, we select the K best similar items that the user has not rated. Then we take the union of all of these similar items. Indeed, if K ¡ú ¡Þ, or equivalently, we use all similar users and items in the database, then the item sets returned by the item-based and user-based techniques are identical. To see why, we show that every candidate j returned by the item-based technique is also the candidate by the userbased technique, and vice versa. Recall that a pair of items is said to be similar if they are jointly rated by the same user. Let I(u) be the set of items rated by the current user u. So for each item j / ¡Ê I(u) similar to item i ¡Ê I(u), there must exist a user v = u so that i, j ¡Ê I(v). Since u and v jointly rate i, they are similar users, which mean that j is also in the candidate set of the user-based method. Analogously, for each candidate j rated by user v, who is similar to u, and j / ¡Ê I(u), there must be an item i = j jointly rated by both u and v. Thus i, j ¡Ê I(v), and therefore they are similar. This means that j must be a candidate by the item-based technique.</p><p>In our Preference Networks, the similarity measure is replaced by the correlation between users or between Recommending a new item i to a given user u is equivalent to extending the system by adding new rating node r ui . The change in system energy is therefore the sum of node-based energy of the new node, and the interaction energy between the node and its neighbours.</p><formula xml:id="formula_23">?E(r t , o) = E(r t , o) + E(r t , r t , o) t ¡ÊN (t)</formula><p>For simplicity, we assume that the state of the existing system does not change after node addition. Typically, we want the extended system to be in the most probable state, or equivalently the system state with lowest energy. This means that the node that causes the most reduction of system energy will be preferred. Since we do not know the correct state r t of the new node t, we may guess by predicting?rpredicting? predicting?r t using Equation 7. Let us call the energy reduction by this method the maximal energy change. Alternatively, we may compute the expected energy change to account for the uncertainty in the preference prediction</p><formula xml:id="formula_24">E[?E(r t , o)] = P (r t |N (t), o)?E(r t , o) (13) rt</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate our Preference Network against well-established correlation methods on the movie recommendation tasks, which include rate prediction and top-N item recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data and Experimental Setup</head><p>We use the MovieLens data 2 , collected by the GroupLens Research Project at the University of Minnesota from September 19th, 1997 through April 22nd, 1998. We use the dataset of 100,000 ratings in the 1-5 scale. This has 943 users and 1682 movies. The data is divided into a training set of 80,000 ratings, and the test set of 20,000 ratings. The training data accounts for 852,848 and 411,546 user-based item-based correlation features.</p><p>We transform the content attributes into a vector of binary indicators. Some attributes such as sex are categorical and thus are dimensions in the vector. Age requires some segmentation into intervals: under 18, <ref type="bibr">18-24, 25-34, 35-44, 45-49, 50</ref>-55, and 56+. We limit user attributes to age, sex and 20 job categories 3 , and item attributes to 19 film genres <ref type="bibr">4</ref> . Much richer movie content can be obtained from the Internet Movie Database (IMDB) <ref type="bibr">5</ref> . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Accuracy of Rating Prediction</head><p>In the training phrase, we set the learning rate ¦Ë = 0.001 and the regularisation term ¦Ò = 1. We compare our method with well-known user-based ( <ref type="bibr" target="#b7">Resnick et al. 1994)</ref> and item-based ( <ref type="bibr" target="#b9">Sarwar et al. 2001</ref>) techniques (see Section 2). Two metrics are used: the mean absolute error (MAE) <ref type="figure">Figure 4</ref>: The mean absolute error of recommendation methods (Item: item-based method, Item-R: item-based method with rounding, User: user-based method, and User-R: user-based method with rounding). In general, the MAE is more desirable than the 0/1 error because making exact prediction may not be required and making 'closed enough' predictions is still helpful. As item-based and user-used algorithms output real ratings, we round the numbers before computing the errors. Results shown in <ref type="figure">Figure 4</ref> demonstrate that the PN outperforms both the item-based and user-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>portion of training data</head><p>Sensitivity to Data Sparsity. To evaluate methods against data sparsity, we randomly subsample the training set, but fix the test set. We report the performance of different methods using the MAE metric in <ref type="figure" target="#fig_11">Figure 5</ref> and using the mean 0/1 errors in <ref type="figure" target="#fig_14">Figure 6</ref>. As expected, the purely content-based method deals with the sparsity in the user-item rating matrix very well, i.e. when the training data is limited. However, as the content we use here is limited to a basic set of attributes, more data does not help the content-based method further. The correlation-based method (purely collaborative filtering), on the other hand, suffers severely from the sparsity, but outperforms all other methods when the data is sufficient. Finally, the hybrid method, which combines all the content, identity and correlation features, improves the performance of all the component methods, both when data is sparse, and when it is sufficient. When a recommended item is in the test set of a user, we call it is a hit. For evaluation, we employ two measures. The first is the expected utility of the ranked list ( <ref type="bibr">Breese et al. 1998)</ref>, and the second is the MAE computed over the hits. The expected utility takes into account of the position j of the hit in the list for each user u</p><formula xml:id="formula_25">R u = 1 2 (j?1)/(¦Á?1) (16) j</formula><p>where ¦Á is the viewing halflife. Following ( <ref type="bibr">Breese et al. 1998</ref>), we set ¦Á = 5. Finally, the expected utility for all users in the test set is given as</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Top-N Recommendation</head><formula xml:id="formula_26">R = 100 u R u u R max (17) u</formula><p>We produce a ranked list of items for each user in the test set so that these items do not appear in the training set.  </p><formula xml:id="formula_27">j¡ÊI (u)<label>(18)</label></formula><p>where I (u) is the set of items of user u in the test set. For comparison, we implement a user-based recommendation in that for each user, we choose 100 best (positively) correlated users and then rank the item based on the    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusions</head><p>number of times it is rated by them. We vary the rate of recall by varying the value of N , i.e. the recall rate typically improves as N increases. We are interested in how the expected utility and the MAE changes as a function of recall. The expected energy change is used as the ranking criteria for the Preference Network. <ref type="figure" target="#fig_17">Figure 7</ref> shows that the utility increases as a function of recall rate and reaches a saturation level at some point. <ref type="figure" target="#fig_15">Figure 8</ref> exhibits a similar trend. It supports the argument that when the recall rate is smaller (i.e. N is small), we have more confidence on the recommendation. For both measures, it is evident that the Preference Network has an advantage over the user-based method.</p><p>We have presented a novel hybrid recommendation framework called Preference Networks that integrates different sources of content (content-based filtering) and user's preferences (collaborative filtering) into a single network, combining advantages of both approaches, whilst overcoming shortcomings of individual approaches such as the cold-start problem of the collaborative filtering. Our framework, based on the conditional Markov random fields, are formal to characterise and amenable to inference. Our experiments show that PNs are competitive against both the well-known item-based and user-based collaborative filtering methods in the rating prediction task, and against the user-based method in the top-N recommendation task.</p><p>Once learned, the PN is a probabilistic database that allows interesting queries. For example, the set of most influential items for a particular demographic user group can be identified based on the corresponding energies. Moreover, the conditional nature of the PN supports fusion of varieties of information into the model through weighted feature functions. For example, the features can capture the assertion that if two people are friends, they are more likely to have similar tastes even though they have not explicitly provided any common preferences 6 . Finally, one main drawback the PNs inherit from the user-based methods is that it may be expensive at prediction time, because it takes into account all users who are related to the current one. On-going work will investigate clustering techniques to reduce the number of pair-wise connections between users.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[http://www.amazon.com], Net- flix [http://www.netfix.com] and new services such as Google News [http://news.google.com].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Copyright c 2007 ,</head><label>2007</label><figDesc>Australian Computer Society, Inc. This paper ap- peared at the Sixth Australasian Data Mining Conference (AusDM 2007), Gold Coast, Australia. Conferences in Research and Practice in Information Technology (CRPIT), Vol. 70, Peter Christen, Paul Kennedy, Jiuyong Li, Inna Kolyshkina and Graham Williams, Ed. Reproduction for academic, not-for profit purposes permitted provided this text is in- cluded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Preference matrix. Entries are numerical rating (or preference) and empty cells are to be filled by the recommender system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A fragment of the Preference Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: The mean absolute error (MAE) of recommendation methods with respect to training size of the MovieLens data. (Item-R: item-based method with rounding, User-R: user-based method with rounding, Content: PNs with content-based features, and C+I+CORR: PNs with content, identity and correlation features).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>0</head><label>0</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The mean 0/1 error of recommendation methods with respect to training size of the MovieLens data. (Item-R: item-based method with rounding, User-R: user-based method with rounding, Content: PNs with content-based features, and C+I+CORR: PNs with content, identity and correlation features).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: MAE as a function of recall. The smaller MAE, the better. PN = Preference Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>50 Adomavicius, G. &amp; Tuzhilin, A. (2005), 'Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions', Knowl- edge and Data Engineering, IEEE Transactions on 17(6), 734-749. 42 PN User?based Balabanovi?cBalabanovi?c, M. &amp; Shoham, Y. (1997), 'Fab: content- based, collaborative recommendation', Communica- tions of the ACM 40(3), 66-72.Basilico, J. &amp; Hofmann, T. (2004), 'Unifying collabo- rative and content-based filtering', Proceedings of the twenty-first international conference on Machine learn- ing .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Expected utility as a function of recall. The larger utility, the better. PN = Preference Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="true"><head>Table 1 reports</head><label>1</label><figDesc>results of Preference Network with ranking measure of maximal energy change and expected energy change in producing the top 20 item recommendations.</figDesc><table>Method 
MAE Expected Utility 
User-based 
0.669 
46.61 
PN (maximal energy) 0.603 
47.43 
PN (expected energy) 0.607 
48.49 

Table 1: Performance of top-20 recommendation. PN = 
Preference Network. 

</table></figure>

			<note place="foot" n="1"> Strictly speaking, age is not truly static, but it changes really slowly as long as selling is concerned.</note>

			<note place="foot" n="6"> Friends are a influential factor of consumer behaviour via the &apos;word-of-mouth&apos; process.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Markov Property and Learning Log-linear Models</head><p>Breese, J., Heckerman, D., <ref type="bibr">Kadie, C. et al. (1998)</ref> where</p><p>The parameter update rule in Equation 6 requires the computation of the gradient of the regularised log pseudolikelihood in Equation 4, and thus, the gradient of the log pseudo-likelihood L = log P (r t |N (t), o). Given the loglinear parameterisation in Equations 2 and 3, we have </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recommendation as classification: Using social and content-based information in recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hirsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth National Conference on Artificial Intelligence</title>
		<meeting>the Fifteenth National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recommender systems using linear classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iyengar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="313" to="334" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spatial interaction and the statistical analysis of lattice systems (with discussions)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Besag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="192" to="236" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Maximum entropy for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th conference on Uncertainty in artificial intelligence pp</title>
		<meeting>the 20th conference on Uncertainty in artificial intelligence pp</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="636" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning collaborative information filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Billsus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth International Conference on Machine Learning</title>
		<meeting>the Fifteenth International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="46" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Framework for Collaborative, Content-Based and Demographic Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pazzani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="393" to="408" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Probabilistic reasoning in intelligent systems: networks of plausible inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">GroupLens: An Open Architecture for Collaborative Filtering of Netnews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Iacovou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suchak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergstorm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM 1994 Conference on Computer Supported Cooperative Work</title>
		<meeting>ACM 1994 Conference on Computer Supported Cooperative Work<address><addrLine>ACM, Chapel Hill, North Carolina</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="175" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Restricted Boltzmann machines for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Reidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international</title>
		<meeting>the 10th international</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Methods and metrics for cold-start recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pennock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th annual international ACM SI-GIR conference on Research and development in information retrieval pp</title>
		<meeting>the 25th annual international ACM SI-GIR conference on Research and development in information retrieval pp</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="253" to="260" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
