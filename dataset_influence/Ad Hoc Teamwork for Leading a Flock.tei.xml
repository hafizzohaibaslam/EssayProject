<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-16T23:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ad Hoc Teamwork for Leading a Flock</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-05">May 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Genter</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
							<email>pstone@cs.utexas.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Dept. of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. of Computer Science</orgName>
								<orgName type="institution" key="instit1">Noa Agmon</orgName>
								<orgName type="institution" key="instit2">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computer Science</orgName>
								<orgName type="institution">Bar Ilan University Ramat Gan</orgName>
								<address>
									<postCode>52900</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of Texas at Austin Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ad Hoc Teamwork for Leading a Flock</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the Twelfth International Conference on Autonomous Agents and Multiagent Systems (AAMAS-13)</title>
						<meeting>the Twelfth International Conference on Autonomous Agents and Multiagent Systems (AAMAS-13) <address><addrLine>Saint Paul, MN, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published" when="2013-05">May 2013</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I211 [Distributed Artificial Intelligence]: Multiagent systems General Terms Algorithms</term>
					<term>Experimentation Keywords Ad Hoc Teamwork</term>
					<term>Agent Cooperation</term>
					<term>Coordination</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Designing agents that can cooperate with other agents as a team, without prior coordination or explicit communication , is becoming more desirable as autonomous agents become more prevalent. In this paper we examine an aspect of the problem of leading teammates in an ad hoc teamwork setting, where the designed ad hoc agents lead the other teammates to a desired behavior that maximizes team utility. Specifically, we consider the problem of leading a flock of agents to a desired orientation using a subset of ad hoc agents. We examine the problem theoretically, and set bounds on the extent of influence the ad hoc agents can have on the team when the agents are stationary. We use these results to examine the complicated problem of orienting a stationary team to a desired orientation using a set of non-stationary ad hoc agents. We then provide an empirical evaluation of the suggested solution using our custom-designed simulator FlockSim.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The growing use of agents in various cooperative domains has emphasized the importance of designing agents capable of reasoning about ad hoc teamwork <ref type="bibr" target="#b9">[10]</ref>. Such agents can cooperate within a team without using explicit communication or previously coordinating behaviors among teammates. One aspect of ad hoc teamwork involves leading teammates. Consider a case in which we want to influence a given team of agents to alter their actions in order to maximize the team utility. One way of doing so is by adding agents to the team in order to lead them to perform the desired actions. While previous research on leading teammates in ad hoc settings concentrated on a game theoretic analysis of this problem <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b10">11]</ref>, in this work we consider a more practical aspect of the problem by concentrating on flocking agents.</p><p>Flocking is an emergent behavior that can be found in different species in nature including flocks of birds, schools of fish, and swarms of insects. In each of these cases the animals follow a simple local behavior rule that results in a stable, well defined, group behavior. Research on flocking behavior can be found in various disciplines, for example in physics <ref type="bibr" target="#b13">[14]</ref>, graphics <ref type="bibr" target="#b8">[9]</ref>, biology <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, and distributed control theory <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12]</ref>. The main focus of each of these research directions is to characterize the emergent behavior. In this paper we introduce the problem of leading a team of flocking agents in ad hoc teamwork settings. In this case, we are given a team of flocking agents following a known, well defined rule characterizing their flocking behavior, and we wish to examine to what extent it is possible to influence the team. Specifically, the question addressed in this paper is: is it possible for one or more agents to lead the team to a desired orientation, and if so -what is the most efficient way of doing so?</p><p>The ad hoc teamwork perspective of this problem is highlighted by two facts. Firstly, we do not explicitly control the behavior of the flocking agents, thus we can only try to influence them implicitly using the behavior of the ad hoc agents (which appear to be identical to the flocking agents). Secondly, all agents -both flocking and ad hoc -act as one team, and their only desire is to optimize team utility. The ad hoc agents cannot communicate with the flocking agents, but they can coordinate their actions among themselves.</p><p>The challenge of designing ad hoc agents in such a dynamic system is twofold: the action space is continuous and the set of optimal solutions is not discrete. We therefore analyze the system in two steps. First, we examine the problem of leading a team of stationary flocking agents, i.e., the agents are aligned in a formation and the ad hoc agents attempt to influence only their orientations while all of the agents maintain their current positions. In the second stage, we use these results for establishing the desired behavior when the ad hoc agents can move.</p><p>One of the main contributions of this paper is the problem definition provided in Section 2, as it contributes a specification of the flocking problem as a new scenario for studying ad hoc teamwork. Another major contribution of this paper is an initial theoretical and empirical analysis of the problem. Some foundational results that apply to all flocking scenarios are presented in Section 3. The analysis for stationary ad hoc agents is presented in Section 4, while the analysis for non-stationary ad hoc agents is presented in Section 5. We also describe our empirical evaluation using our customdesigned simulator FlockSim 1 in Section 5. Section 6 situates this research in the literature, and Section 7 concludes. Under our flocking model, the global orientation of agent ai at time step t + 1, ¦Èi(t + 1), is set to be the average orientation of all agents in Ni(t) (including itself) at time t. Formally,</p><formula xml:id="formula_0">¦Èi(t + 1) = ¦Èi(t) + 1 ni(t) X calcDiff(¦Èj(t), ¦Èi(t)) (1) 2. PROBLEM DEFINITION j¡ÊN i (t)</formula><p>In this work we introduce a flocking model inspired by <ref type="bibr">Vicsek et al. [14]</ref>. In our model, n homogeneous agents inhabit some environment where each agent ai moves with some velocity vi. Velocity vi is not a function of time and hence remains constant for each agent over time. At each time step t, each agent ai has a position pi(t) = (xi(t), yi(t)) in the environment and an orientation ¦Èi(t). Note that pi(t) and ¦Èi(t) are dependent on the time t and can be different for each agent ai. Each agent's position pi(t) at time t is updated after its orientation is updated, such that xi(t) = xi(t ? 1) + vi cos(¦Èi(t)) and yi(t) = yi(t ? 1) ? vi sin(¦Èi(t)).</p><p>We let Ni(t) be the set of ni(t) ¡Ü n agents (including agent ai) at time t which are visible to agent ai. An agent is visible to agent ai if its position is located within a visibility cone of angle ¦Á centered on orientation ¦Èi(t) and extending from agent ai for an unlimited distance (see <ref type="figure" target="#fig_1">Figure 1</ref> for an example). We say that angle ¦Á defines the visibility cone for each agent, and that this visibility cone defines each agent's neighborhood (i.e., the area in which the agent can see other agents). For example, assume an agent aj ¡Ê Ni(t) is in ai's neighborhood and hence a neighbor of ai.</p><p>Agent aj's position pj(t) = (xj(t), yj(t)) in the environment at time t is located at angle ¦Âj(i) with respect to agent ai's position pi(t) = (xi(t), yi(t)) and orientation ¦Èi(t). Agent aj is in ai's neighborhood at time t if angle ¦Âj(i) is less than or equal to We must use Equation 1 instead of merely taking the average orientation of all agents because of the special cases handled by Algorithm 1 (e.g. The average of 350</p><p>? and 10</p><p>? is 180</p><p>? , but by Algorithm 1 it is 0</p><p>? , as desired). Throughout this paper, we restrict ¦Èi(t) to be within <ref type="bibr">[0, 2¦Ð)</ref>. Likewise, the difference between the orientations of two agents is always within [?¦Ð, ¦Ð] since a difference of ¦Ð + ? is equivalent to a difference of ? ? ¦Ð in the opposite direction.</p><formula xml:id="formula_1">Algorithm 1 calcDiff(¦Èi(t), ¦Èj(t)) 1: if ((¦Èi(t) ? ¦Èj (t) ¡Ý ?¦Ð) ¡Ä (¦Èi(t) ? ¦Èj (t) ¡Ü ¦Ð)) then 2: return ¦Èi(t) ? ¦Èj (t) 3: else if ¦Èi(t) ? ¦Èj (t) &lt; ?¦Ð then 4: return 2¦Ð + (¦Èi(t) ? ¦Èj (t)) 5: else 6: return (¦Èi(t) ? ¦Èj (t)) ? 2¦Ð ¦Á 2 . aj</formula><p>The n homogeneous agents that comprise the flock consist of k ad hoc agents and m flocking agents, where k + m = n. The ad hoc agents {a0, . . . , a k?1 } are agents whose behavior we can control, while the flocking agents {a k , . . . , aN?1} are agents that we cannot directly control but that we know calculate their orientation according to Equation 1. In this paper, we make the simplification that although we can have many flocking agents, they all must have the same position p(t) in the environment. At each time step t, the number of ad hoc agents inside ai's neighborhood is denoted by ki(t) and the number of flocking agents inside the neighborhood is denoted by mi(t), where ki(t) + mi(t) = ni(t) (the total number of agents in ai's neighborhood). For simplicity, we use the visibility cone approach discussed above to define each agent's neighborhood. It should be noted, however, that this is not the exact approach real birds use to determine which neighboring birds influence their flight. For example, starlings are believed to consider the seven nearest birds in their flock as their neighborhood when performing orientation updates <ref type="bibr" target="#b1">[2]</ref>. However, it is generally accepted that birds do have a 'blind' angle behind them such that any neighboring birds within this 'blind' area are not considered when performing orientation updates <ref type="bibr" target="#b2">[3]</ref>. This 'blind' area was the motivation for our visibility cone approach.</p><p>We define the Agent Flock Orientation Manipulation Problem as follows: Given a target orientation ¦È * and a team of n homogeneous agents {a0, . . . , an?1}, where the flocking agents {a k , . . . an?1} calculate their orientation based on Equation 1, determine whether the ad hoc agents can influence the flocking agents to align to ¦È * , and if so, find the plan ¦Ð that does so with minimum cost c(¦Ð).</p><p>During each time step, the ad hoc agents first orient to their desired orientations based on some plan ¦Ð. Next, the flocking agents update their orientations based on the orientations of all the agents in their neighborhoods (using Equation 1). Finally, the positions of all the agents are updated.</p><p>An x-step plan specifies the orientations that each ad hoc agent {a0, a1, . . . a k?1 } will align to at each time step when given exactly x time steps in which the agents have to act. The x-step plan is denoted by ¦Ðx = (¦Ð </p><formula xml:id="formula_2">E(¦Ðx) = X |calcDiff(¦È * , ¦Èj(x))|<label>(2)</label></formula><p>j=k For each plan ¦Ð, performance error decreases when more time steps are available such that E(¦Ð0) ¡Ý E(¦Ð1) ¡Ý E(¦Ð2) ¡Ý . . . ¡Ý E(¦Ð¡Þ). Performance error never increases as more time steps are available because the optimal behavior given one additional time step is to either influence the same as with one fewer time step (and obtain the same performance error) or influence at least one flocking agent to orient itself closer to ¦È * (and obtain lower performance error). The cost of an x-step plan ¦Ðx is defined as</p><p>The first lemma we present in this section relates to the maximal amount the ki(t) ad hoc agents can influence the mi(t) flocking agents in a single time step.</p><p>Lemma 1. The ki(t) ad hoc agents can influence the mi(t) flocking agents to turn in a particular direction by any amount less than or equal to</p><formula xml:id="formula_3">k i (t)¦Ð m i (t)+k i (t)</formula><p>radians in one time step.</p><formula xml:id="formula_4">c(¦Ðx) = w1x + w2E(¦Ðx)<label>(3)</label></formula><p>Proof. When the difference between ¦Èj(t) and ¦Èi(t) is less than ¦Ð (or greater than ¦Ð, in which case the difference is less than ¦Ð in the opposite direction), then by Equation 1 where w1 is a weight that can be set to emphasize the importance of lesser time steps, x is a scalar representing the size of the plan ¦Ðx, and w2 is a weight that can be set to emphasize the importance of lower performance error. At the extremes, setting w1 &gt;&gt; w2 encourages finding reasonably low performance error in as few steps as possible, while setting w2 &gt;&gt; w1 encourages minimizing performance error using as many steps as are needed.</p><p>An optimal plan ¦Ð * is one with minimal cost c(¦Ð * ). The optimal number of time steps |x| for a task is the x at which c(¦Ðx) is minimal. Likewise, the optimal cost |c(¦Ð)| is equal to c(¦Ð |x| ).</p><p>In this work, we set w1 to a moderate number and set w2 to ¡Þ. With these settings for w1 and w2 we obtain the least-step plan in which all flocking agents orient to ¦È * , if such a plan exists. If such a plan does not exist, then we obtain a plan with low performance error that uses as few steps as possible.</p><formula xml:id="formula_5">¦Èi(t + 1) ? ¦Èi(t) = 1 ni(t) X (¦Èj(t) ? ¦Èi(t)) j¡ÊN i (t) ¡Ü ki(t)(¦Ð ? ?) mi(t) + ki(t) ¡Ü ki(t)¦Ð mi(t) + ki(t) ? ki(t)? mi(t) + ki(t) &lt; ki(t)¦Ð mi(t) + ki(t)</formula><p>When the difference between ¦Èj(t) and ¦Èi(t) is equal to ¦Ð, by Equation 1</p><formula xml:id="formula_6">¦Èi(t + 1) ? ¦Èi(t) = 1 ni(t) X (¦Èj(t) ? ¦Èi(t)) j¡ÊN i (t) = ki(t)¦Ð mi(t) + ki(t)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">GENERAL FLOCKING THEOREMS</head><p>In this paper we establish the building blocks towards examining a fully dynamic system of agents in which most agents base their behavior on the current behavior of neighboring agents and a few agents are controlled by our algorithms. However, the agents controlled by our algorithms do not appear any different to the other agents, and hence the other agents do not recognize that these agents are controlled by a different algorithm.</p><p>In this section, we present lemmas that are general in nature and will apply to both the stationary and non-stationary ad hoc agent cases examined in the later sections of this paper. In particular, in this section we consider the case in which there are ki(t) ad hoc agents and mi(t) flocking agents, where all mi(t) flocking agents are located at the same position pi(t) with identical orientations ¦Èi(t) (see <ref type="figure" target="#fig_4">Fig- ure 2</ref> for an example).</p><p>However, it is impossible to guarantee that the flocking agents turn in a particular direction when the difference between ¦Èj(t) and ¦Èi(t) is equal to ¦Ð. Hence, in this case the ad hoc agents set ¦Èj(t) such that the difference between ¦Èj(t) and ¦Èi(t) is ¦Ð ? ? or ¦Ð + ?. When the ad hoc agents do this, directionality can be guaranteed and</p><formula xml:id="formula_7">¦Èi(t + 1) ? ¦Èi(t) = ki(t)(¦Ð ? ?) mi(t) + ki(t) &lt; ki(t)¦Ð mi(t) + ki(t)</formula><p>The second lemma we present in this section states that all ki(t) ad hoc agents in a flocking agent's visibility cone can adopt the exact same orientation. We show that no extra influence can be obtained by some of the ad hoc agents adopting different orientations than the other ad hoc agents. Lemma 2. When ki(t) ad hoc agents work together to influence mi(t) flocking agents to align the team to some ¦È, it suffices to consider only algorithms that choose at each time step just one orientation for all of the ad hoc agents to adopt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a1</head><p>Flocking agents a4, a5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Position pi</head><p>Proof. Assume an algorithm makes the ad hoc agents adopt orientations ¦È0(t), . . . , ¦È k i (t)?1 (t), where some of these orientations may differ. Then, by Equation 1, the orientation of the flocking agents is </p><formula xml:id="formula_8">¦È f (t + 1) = ¦È f (t) + 1 n f (t) X calcDiff(¦Èj(t), ¦È f (t)) j¡ÊN i (t)</formula><p>Now, assume the ad hoc agents adopt an angle ¦Ò that is the average of ¦È0(t), . . . , ¦È k i (t)?1 (t). Then by Equation 1, the new orientation is</p><formula xml:id="formula_9">Border agent a1 ¦È * ¦È f (t + 1) = ¦È f (t) + ki(t) n f (t) (¦Ò) a2 a0</formula><p>Since ¦Ò is the average of ¦È0(t), . . . , ¦È k i (t)?1 (t),</p><formula xml:id="formula_10">Border influence orientation 1 n f (t) X calcDiff(¦Èj(t), ¦È f (t)) = kt(i) nt(f ) (¦Ò)</formula><p>Visibility cone</p><formula xml:id="formula_11">j¡ÊN i (t)</formula><p>Therefore, for every algorithm assigning different orientations, there is some algorithm assigning the same orientation, which concludes the proof. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">STATIONARY AGENTS</head><p>In this section we consider the case in which there are mi(t) flocking agents located at a single position pi with identical initial orientations and ki(t) ad hoc agents located at various arbitrary locations. Each agent ai has velocity vi = 0. This means that although an agent's orientation may change, its position will remain constant. An example is provided in <ref type="figure" target="#fig_6">Figure 3</ref>.</p><p>respect to agent ai's position pi(t) = (xi(t), yi(t)) and orientation ¦Èi(t).</p><p>The first lemma in this section puts a bound on the maximal amount the flocking agents can be influenced to turn and still have the same set of ad hoc agents and flocking agents within the flocking agents' visibility cone. </p><formula xml:id="formula_12">, k i (t)¦Ð m i (t)+k i (t) a2</formula><p>Ad hoc agents ? ?) radians in one time step and still have the same mi(t) flocking agents and ki(t) ad hoc agents within the flocking agents' neighborhood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a1 a5 a4</head><p>Flocking agents</p><p>Proof. In order for all the ki(t) agents to remain in the neighborhood of all mi(t) agents at time t + 1, it is necessary for the amount the mi(t) flocking agents turn by</p><formula xml:id="formula_13">(min(¦Âj(i) + ¦Á 2 , k i (t)¦Ð m i (t)+k i (t) Position pi a6,a7</formula><p>? ?)) plus the location of the current edge of the flocking agents' visibility cone (¦Èi(t) ? ¦Á 2</p><p>Figure 3: An example with two flocking agents (a 6 and a 7 ) located at the same position with identical initial orientations, four ad hoc agents (a 0 , a 1 , a 2 , and a 3 ) located at different locations within the visibility cone of the flocking agents, and two ad hoc agents (a 4 and a 5 ) located at different locations outside the current visibility cone of the flocking agents.</p><p>) to be less than or equal to the orientation of the position of the ad hoc agents with respect to the position of the flocking agents (¦Âj(i) + ¦Èi(t)). Hence,</p><formula xml:id="formula_14">min(¦Âj(i) + ¦Á 2 , ki(t)¦Ð mi(t) + ki(t) ? ?) + ¦Èi(t) ? ¦Á 2 ¡Ü (4) ¦Âj(i) + ¦Èi(t)</formula><p>As the flocking agents are influenced to turn towards ¦È * , different ad hoc agents become available to influence the flocking agents. This is because some ad hoc agents may no longer be within the flocking agents' visibility cone, while other ad hoc agents may enter the visibility cone. Hence, at each time step the ad hoc agents must consider the trade-off between moving the flocking agents maximally towards ¦È when mi(t) flocking agents and ki(t) ad hoc agents are in each flocking agents' neighborhood at time t + 1.</p><p>If </p><formula xml:id="formula_15">¦Âj(i) + ¦Á 2 &lt; k i (t)¦Ð m i (t)+k i (t) ? ?, then ¦Âj(i) + ¦Á 2 + ¦Èi(t) ? ¦Á 2 * ¡Ü ¦Âj(i) + ¦Èi(t).</formula><formula xml:id="formula_16">¡Ý k i (t)¦Ð m i (t)+k i (t) ??, then k i (t)¦Ð m i (t)+k i (t)</formula><p>? and keeping (or moving) ad hoc agents within the flocking agents' visibility cone for future time steps.</p><p>In this section, we introduce some new terminology. A border agent is an ad hoc agent that is located within the visibility cone of the flocking agents, on the edge of the visibility cone that is farther away from the target. A border influence orientation is a flocking agent orientation at which an ad hoc agent is a border agent. Clearly for each ad hoc agent, there are exactly two possible border influence orientations -one in which the border agent is located on the left hand side of the flocking agents' visibility cone and one in which the border agent is located on the right hand side of the visibility cone. See <ref type="figure" target="#fig_5">Figure 4</ref> for an example with a border agent.</p><p>Throughout this section, recall that ¦Á denotes the angle of the flocking agent ai's visibility cone. Additionally, remember that an ad hoc agent aj's location pj(t) = (xj(t), yj(t)) in the environment at time t is located at angle ¦Âj(i) with</p><formula xml:id="formula_17">?+¦Èi(t)? ¦Á 2 ¡Ü ¦Âj(i)+¦Èi(t). Since, ¦Âj(i)+ ¦Á 2 ¡Ý k i (t)¦Ð m i (t)+k i (t)</formula><p>?? in this case, the left side of Equation 4 is less than or equal to the right side.</p><p>The second lemma in this section sets a bound on the maximum number of time steps needed for the ad hoc agents to influence the flocking agents to reach ¦È * when ¦È * is reachable.</p><p>Lemma 4. The ki(t) ad hoc agents can influence the mi(t) flocking agents to align the team to ¦È * within</p><formula xml:id="formula_18">Z = 1 + ? min( ¦Ð 2</formula><p>, ¦Á)</p><formula xml:id="formula_19">k i (t)¦Ð m i (t)+k i (t) ? ? ?</formula><p>time steps when ¦È * is reachable (i.e. the difference between ¦Èi(t) and ¦È * is less than or equal to (Z ? 1)</p><formula xml:id="formula_20">k i (t)¦Ð m i (t)+k i (t) ? ? + ? ?). ¦Âj(i) + ¦Èi(t) ? ¦Èi(t + 1) + ¦Á 2 and ¦Á &gt; (Z ? 2) k i (t)¦Ð m i (t)+k i (t)</formula><note type="other">Proof. By Lemma 1, ki(t) ad hoc agents can influence mi(t) flocking agents to turn by In this case, the left of Equation 6 becomes</note><formula xml:id="formula_21">k i (t)¦Ð m i (t)+k i (t)</formula><p>? ? on each of the first Z ? 2 time steps. Additionally, by Lemma 3, ki(t) ad hoc agents can influence mi(t) flocking agents to turn by ¦Âj(i) + ¦Èi(t) ? ¦Èi(t + 1) + ( ¦Á</p><formula xml:id="formula_22">k i (t)¦Ð m i (t)+k i (t) ? ? )( ki(t)¦Ð mi(t) + ki(t) ? ?) = ¦Á = ¦Ð 2 ¦Á 2</formula><p>on the Z ? 1 time step and still have have mi(t) flocking agents and ki(t) ad hoc agents in each flocking agents' neighborhood. Finally, by Lemma 1 ki(t) ad hoc agents can influence mi(t) flocking agents to turn by any amount less than or equal to</p><formula xml:id="formula_23">Otherwise, if ¦Ð 2 ¡Ü ¦Á, then Z ¡ä ¡Ü ? ? k i (t)¦Ð m i (t)+k i (t)</formula><p>? ? on the last time step.</p><p>Influencing as described above must force the mi(t) flocking agents to align to ¦È * ; in other words, we must show that</p><formula xml:id="formula_24">¦Ð 2 k i (t)¦Ð m i (t)+k i (t)</formula><p>In this case, the left of Equation 6 becomes</p><formula xml:id="formula_25">( ¦Ð 2 k i (t)¦Ð m i (t)+k i (t) ? ? )( ki(t)¦Ð mi(t) + ki(t) ? ?) = ¦Ð 2 &lt; ¦Ð (Z ? 2) ki(t)¦Ð mi(t) + ki(t) ? ? + ¦Âj(i) + ¦Èi(t) ? ¦Èi(t + 1) + ¦Á 2 +</formula><p>leading to a contradiction.</p><formula xml:id="formula_26">ki(t)¦Ð mi(t) + ki(t) ? ? ¡Ý ¦Ð<label>(5)</label></formula><p>By definition we know that ¦Á &gt; (Z ? 2)</p><formula xml:id="formula_27">k i (t)¦Ð m i (t)+k i (t)</formula><p>? ? and ¦Á ¡Ü 2¦Ð, so the left side of Equation 5 simplifies to 3¦Ð + ¦Âj(i) + ¦Èi(t) ? ¦Èi(t + 1) + 2¦Ð Z?2 such that the left side of Equation 5 is greater than or equal to the right side.</p><p>The following theorem states that it is impossible to influence the flocking agents to orient themselves to ¦È * (assuming it is reachable) in fewer than Z time steps. Remember that Lemma 4 showed that ki(t) ad hoc agents can influence mi(t) flocking agents to align the team to ¦È * in Z time steps when ¦È * is reachable.</p><p>When determining how the ad hoc agents should orient themselves to optimally influence the flocking agents, we use a forward search approach (see <ref type="figure">Figure 5</ref>). Specifically, beginning at the initial flocking orientation, we consider each possible border influence orientation. If the border influence orientation is reachable from the initial flocking orientation, then we consider each possible border influence orientation from this point. If the border influence orientation is not reachable from the initial flocking orientation, then we turn to the farthest reachable point and then determine if the border influence orientation is now reachable (and repeat this process until the border influence orientation is reachable). We repeat this process until the target is within reach, and we select the plan that reaches the target in the fewest number of steps. , ¦Á)</p><formula xml:id="formula_28">k i (t)¦Ð m i (t)+k i (t) ? ? ?</formula><p>time steps are needed for the ki(t) ad hoc agents to influence the mi(t) flocking agents to align the team to ¦È * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a3</head><p>Proof. Assume, towards contradiction, that there exists an algorithm in which ki(t) ad hoc agents influence mi(t) flocking agents to align the team to ¦È * (when alignment is possible) in Z ¡ä &lt; Z time steps. By Lemmas 1, 3, and 4, ki(t) ad hoc agents can influence mi(t) flocking agents to turn </p><formula xml:id="formula_29">k i (t)¦Ð m i (t)+k i (t)</formula><p>? ? on time step Z ¡ä . Hence, <ref type="figure">Figure 5</ref>: An example of the possible subsequent flocking agent orientations for a given initial orientation. The ad hoc agents are labelled with a 0 , a 1 , and a 2 , while the flocking agent is labelled with a 3 . Note that turning to border agent a 2 is not possible in the first time step.</p><formula xml:id="formula_30">(Z ¡ä ? 1) ki(t)¦Ð mi(t) + ki(t) ? ? + ¦Âj(i) + ¦Èi(t) ? ¦Èi(t + 1) + ¦Á 2 ¡Ý ¦Ð<label>(6)</label></formula><p>when alignment of the team to ¦È * can be achieved in Z ¡ä time steps. By Lemmas 1 and 3, ¦Âj(i) + ¦Èi(t) ? ¦Èi(t + 1) +</p><formula xml:id="formula_31">¦Á 2 ¡Ü k i (t)¦Ð m i (t)+k i (t)</formula><p>? ? so the left side of Equation 6 becomes</p><formula xml:id="formula_32">Z ¡ä ( k i (t)¦Ð m i (t)+k i (t) ? ?). If ¦Ð 2 &gt; ¦Á, then Z ¡ä ¡Ü ¦Á k i (t)¦Ð m i (t)+k i (t) * ? ?</formula><p>A forward search such as this requires checking 2 k possible combinations of the number of ad hoc agents influencing the flocking agents at each time step. Consider the case where there are three ad hoc agents. The following eight combinations of targets covers all possible combinations:</p><formula xml:id="formula_33">[a0, a1, a2], [a0, a1], [a0, a2], [a0], [a1, a2], [a1], [a2], [].</formula><p>By convention, agent a0 will be oriented farther from the target than agent a1, which will be oriented farther from the target than agent a2, and so on. See <ref type="figure">Figure 6</ref> for an example with two ad hoc agents and one flocking agent.</p><p>Algorithm 2 uses such a forward search approach to calculate and return the number of steps needed to reach ¦È Initial Setup <ref type="table" target="#tab_2">After Step 3  After Step 2  After Step 1   a0   a0   a0   a0   a2   a2   a2   a2   a1   a1   a1   a1</ref> Algorithm 2 plan, steps = calcPlan() 1: for each possible ad hoc agent combination do 2: currentFSeq, currentAHPlan ¡û empty list 3: current ¡û initFOrient 4: for each borderTarget in this ad hoc agent combination do 5:</p><p>targetReachable ¡û false <ref type="figure">Figure 6</ref>: Example with two ad hoc agents (a 0 and a 1 ) and one flocking agent (a 2 ). On step 1, the flocking agent turns to have a 0 as a border agent. Then on step 2, the flocking agent turns as much as possible towards ¦È * . Finally, on step 3 the flocking agent turns to ¦È * .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>while targetReachable == false ¡Ä currentFSeq.size() &lt; maxSteps ¡Ä bestFSeq.size() &gt; currentFSeq.size() do </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>targetReachable ¡û false and the necessary orientations for each of the ad hoc agents for each of these steps. Throughout the algorithm, element.get(x) returns the 0-indexed x item in element (where element is a list object), element.add(y) adds item y to the end of element, and element.size() returns the number of items contained in element. The variables used throughout Algorithm 2 are defined in <ref type="table" target="#tab_2">Table 1</ref>. Remember that although the ki(t) ad hoc agents are located at many arbitrary locations, the mi(t) flocking agents are located at a single position pi and begin with identical orientations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>if the orientation the flocking agents should be oriented towards on the next time step targetReachable whether target is reachable from current (line 6), and necessary ad hoc orientations are added to the currentAHPlan and targets are added to the currentFSeq until it is reachable or the plan size becomes larger than maxSteps. The currentFSeq and currentAHPlan become the bestFSeq and bestAHPlan (lines 25-27) only if they use less steps to reach ¦È * than the current bestFSeq and bestAHPlan. Line 25 will not be reached until all border orientation targets for a particular set of ad hoc agent combinations have been considered and ¦È * has been reached or the plan size becomes larger than maxSteps. Hence, since the best possible ad hoc agent combinations are guaranteed to be considered and the number of steps required will not be larger than maxSteps, we are guaranteed that the bestAHPlan that is returned by Algorithm 2 is the least-step plan possible. Algorithm 2 has been implemented and tested in our customdesigned simulator FlockSim. Results from experiments using FlockSim are given in Section 5.</p><p>In the worst case, line 1 will be executed 2 numAH times, line 4 will execute numAH + 1 times, and line 6 will execute maxSteps times. Hence, lines 7-24 are executed at most (2 numAH )(numAH + 1)(maxSteps) times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">NON-STATIONARY AD HOC AGENTS</head><p>Theorem 6. Given ¦È * and assuming the mi(t) flocking agents are influenced only by the ki(t) ad hoc agents and the mi(t) flocking agents at time t, then if ¦È * is reachable, the ad hoc agents are guaranteed to lead the flocking agents to ¦È * in the least number of time steps possible when the ad hoc agents determine their plan based on Algorithm 2 and the number of steps required is not larger than maxSteps.</p><p>Proof. There are exactly 2 numAH possible ad hoc agent combinations. Hence, by line 1, Algorithm 2 is guaranteed to consider each possible ad hoc agent combination.</p><p>Each border influence orientation target is considered until it is reachable or the plan size becomes larger than maxSteps In this section we consider the case in which there are mi(t) flocking agents that are all located at position pi with identical initial orientations. These flocking agents will remain at position pi forever, but may change orientation if influenced by at least one ad hoc agent. In order to facilitate this, there are ad hoc agents located at arbitrary locations in the environment that can each travel with some constant velocity.</p><p>In the stationary ad hoc agents section, the main decision for each ad hoc agent was whether to influence the flocking agents to turn maximally towards ¦È * or to influence the flocking agents to turn such that one of the ad hoc agents becomes a border agent. However, determining exactly how non-stationary ad hoc agents should behave is a more difficult problem. Hence, in this preliminary work we consider some heuristic approaches for how non-stationary ad hoc agents should behave.</p><p>In the stationary ad hoc agents case, it did not matter how the ad hoc agents that were not within any flocking agent visibility cones behaved because they had no influence over any flocking agents. However, non-stationary ad hoc agents travel in the direction they are facing, so it does matter what orientation they face even when they are not within the visibility cone of any flocking agents. Hence, in this work we present two heuristic behaviors for ad hoc agents that are not within the visibility cone of any flocking agents.</p><p>Towards Flocking Agent Orient towards the position of the flocking agent.</p><p>Towards Visibility Cone Orient towards the closest point on the flocking agents' visibility cone from the ad hoc agent's current position.</p><p>instead use a simpler, more efficient heuristic approach that finds an orientation close to the exact orientation that would be found by the binary search such that the ad hoc agent is still within the flocking agents' visibility cone after moving. Non-stationary ad hoc agents clearly have more influence than stationary ad hoc agents. In some situations, convergence of the flocking agents to ¦È * is able to occur quicker. In other situations, non-stationary ad hoc agents are able to lead the flocking agents to converge to ¦È * in cases where stationary ad hoc agents would be unable to. There are situations in which an ad hoc agent can travel into the flocking agent's visibility cone and influence when it would have been unable to influence if it were stationary. In fact, stationary flocking agents can always be influenced to reach ¦È * eventually when non-stationary ad hoc agents are utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Empirical Evaluation</head><p>The performance of each of these behaviors is studied empirically later in this section and reported on in <ref type="figure">Figure 7</ref>. Although one of these behaviors must currently be chosen by the user for each trial, the optimal behavior likely consists of some combination of these behaviors and perhaps other behaviors. The exact situations in which each behavior should be utilized have not yet been determined. However, there are some situations where each behavior may be best. Moving towards the visibility cone may be ideal when no ad hoc agents are currently in the visibility cone to influence the flocking agent, as the flocking agent will not be able to be influenced until at least one ad hoc agent moves within its' visibility cone. On the other hand, moving towards the flocking agent may be ideal when there are ad hoc agents currently within the flocking agents' visibility cone, as moving closer to the flocking agent now will decrease the number of time steps required for the ad hoc agent to enter the flocking agents' visibility cone in future time steps.</p><p>The general behavior for non-stationary ad hoc agents that are inside a flocking agent's visibility cone is similar to the behavior of stationary ad hoc agents. Specifically, the non-stationary ad hoc agents will either influence the flocking agents to turn maximally or they will influence the flocking agents to turn such that an ad hoc agent is at the edge of the visibility cone (and hence a border agent). The main difference between the stationary ad hoc agents behavior and the non-stationary ad hoc agents behavior is that now the border agent must be on the edge of the visibility cone after updating its location. There are exactly two orientations at which a non-stationary ad hoc agent can orient and be a border agent. One of these orientations results in the ad hoc agent becoming a border agent on the left hand side of the visibility cone, while the other orientation results in the ad hoc agent becoming a border agent on the right hand side of the visibility cone. There must be exactly two orientations at which a non-stationary ad hoc agent can orient and be a border agent because any other orientations will result in either the flocking agents being influenced to turn farther and the ad hoc agent no longer moving enough to move into the visibility cone or in the flocking agents not being influenced to turn as much and the ad hoc agent being too far inside the visibility cone to be a border agent. We could find the exact orientation at which a non-stationary ad hoc agent can orient and be a border agent by performing a binary search for the exact orientation. However, we All of the heuristic behaviors discussed in this section have been implemented and tested in FlockSim. Earlier in this section we presented two heuristic behaviors for ad hoc agents that are located outside of the flocking agents' visibility cone. Now we examine each of these behaviors in FlockSim, and study <ref type="formula">(1)</ref> is there a significant difference in the number of steps required for the flocking agents to orient to ¦È * with each heuristic behavior and (2) how well do our ad hoc agents perform when compared with the naive method used by others (e.g. <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12]</ref>) in which the controllable agents orient towards ¦È * such that the flock slowly converges to ¦È * ? <ref type="figure">Figure 7</ref>: Results obtained using FlockSim on three different team configurations over 1000 trials.</p><p>The results of our experiments are presented in <ref type="figure">Figure 7</ref>. For these experiment, v = 50 for the ad hoc agents, ¦Á = 90</p><formula xml:id="formula_34">? , ¦È * = 270</formula><p>? , the initial flocking orientation was 90</p><p>? , and the ad hoc agents and flocking agents were placed randomly in a 950 by 500 environment. Each of the runs within the three possible team configurations used the same randomization seed. maxSteps was set to 100, such that no trials stopped due to the plan size exceeding maxSteps. When run with teams composed of one to four non-stationary ad hoc agents and one to four stationary flocking agents on a Dell Precision-360 desktop computer, an optimal plan is found in 0.00368103 seconds on average.</p><p>As clearly seen in <ref type="figure">Figure 7</ref>, Towards Visibility Cone performs better than Towards Flocking Agent in all the configurations utilizing ad hoc agents. In order to determine whether there is a significant difference in the number of steps required for the flocking agents to orient to ¦È * , we ran a Student's t-test on the step counts from the 1000 runs for each pair of heuristic behaviors. For each of the three pairs, we found the difference to be statistically significant at p = 0.05. Towards Visibility Cone likely performed better because getting into the visibility cone faster allows the ad hoc agent to influence the flocking agent sooner. <ref type="figure">Figure 7</ref> also clearly shows that our ad hoc agent algorithms perform significantly better than the naive method in which the controllable agents orient towards ¦È * . Our ad hoc agent algorithms performed better because we purposely orient the ad hoc agents past ¦È * in order to orient the flocking agents exactly to ¦È * quickly. It is important to note that in this experiment we relaxed the definition of 'reaching' ¦È * for the naive method. Due to the way in which the naive method slowly converges, under our strict definition of 'reaching', the naive methods would very rarely converge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RELATED WORK</head><p>Although there has been much work in the field of multiagent teamwork, there has been relatively little work towards getting agents to collaborate towards a common goal without pre-coordination. Most prior multiagent teamwork research requires explicit coordination protocols or communication protocols (e.g. SharedPlans, STEAM, and GPGP) <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b3">4]</ref>. However, our work is different in that we do not assume that any protocol is known by all agents.</p><p>Han, Li and Guo study how one agent can influence the direction in which an entire flock of agents is moving <ref type="bibr" target="#b5">[6]</ref>. Similarly to our work, in their work each agent follows a simple control rule based on its neighbors. However, unlike our work they only consider one ad hoc agent with unlimited, non-constant velocity. This allows their ad hoc agent to move to any position in the environment within one time step, which is unrealistic.</p><p>Reynolds introduced the original flocking model when he presented three flocking behaviors -collision avoidance, velocity matching, and flock centering <ref type="bibr" target="#b8">[9]</ref>. His work was focused on creating graphical models that looked and behaved like real flocks, and hence did not consider adding controllable agents to the flock like we do.</p><p>Vicsek et al. considered just the flock centering aspect of Reynolds' model <ref type="bibr" target="#b13">[14]</ref>. Hence, they use a model where all of the particles move at a constant velocity and adopt the average direction of the particles in their neighborhood. However, like Reynolds' work, they were only concerned with simulating flock behavior and not with adding controllable agents to the flock. Jadbabaie, Lin, and Morse build on Vicsek et al.'s work <ref type="bibr" target="#b6">[7]</ref>. They use a simpler direction update than Vicsek et al. and they show that a flock with a controllable agent will eventually converge to the controllable agent's heading. Like us, they show that a controllable agent can be used to influence the behavior of the other agents in a flock. However, they are only concerned with getting the flock to converge eventually, whereas we attempt to do so as quickly as possible. Su, Wang, and Lin also present work that is concerned with using a controllable agent to make the flock converge eventually <ref type="bibr" target="#b11">[12]</ref>.</p><p>Jones et al. perform an empirical study of dynamically formed teams of heterogeneous robots in a multirobot treasure hunt domain <ref type="bibr" target="#b7">[8]</ref>. They assume that all of the robots know they are working as a team and that all of the robots can communicate with one another, whereas in our work we do not assume that the teammates realize they are working on a team with the ad hoc agents.</p><p>In this paper, we consider the problem of leading a flock of agents to a desired orientation using a subset of ad hoc agents. This paper's major contributions are (1) a specification for the flocking problem as a new scenario for studying ad hoc teamwork and (2) an initial theoretical and empirical analysis of this problem. We first set bounds on the extent of influence the ad hoc agents can have on the team when all the agents are stationary, and then we subsequently examine the more complicated problem of orienting a stationary team using a set of non-stationary ad hoc agents.</p><p>Although we begin to consider the non-stationary ad hoc agent case in this work, it is just an initial step towards solving the general case of non-stationary ad hoc and flocking agents. As such, we plan to extend the work presented here towards this general case in the near future. Additionally, as this paper introduces flocking from the ad hoc perspective, there are many exciting directions for future work, such as exploring different neighborhood models, and determining if there is an optimal behavior for non-stationary ad hoc agents that are outside the flocking agents' visibility cone.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Appears in:</head><label></label><figDesc>Proceedings of the 12th International Confer- ence on Autonomous Agents and Multiagent Systems (AA- MAS 2013), Ito, Jonker, Gini, and Shehory (eds.), May, 6-10, 2013, Saint Paul, Minnesota, USA. Copyright c 2013, International Foundation for Autonomous Agents and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Angle ¦Á defines the visibility cone for agent a i . Agent a j is in a i 's neighborhood since angle ¦Â j (i) ¡Ü ¦Á 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>x</head><label></label><figDesc>= (¦Èi(0), ¦Èi(1), . . . , ¦Èi(x ? 1)) is the set of orienta- tions for agent ai. The performance error E(¦Ðx) of an x-step plan ¦Ðx is the sum of the differences between each flocking agent's final orientation after x steps and ¦È * , formally n?1 1 Videos of our FlockSim simulator are available at http://aamas13.blogspot.com/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: An example with two flocking agents located at the same position with identical initial orientations and four ad hoc agents located at different locations within the visibility cone of the flocking agents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: An example of a border agent (a 0 ) and the resulting border influence orientation of the flocking agent (a 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Lemma 3 .</head><label>3</label><figDesc>ki(t) ad hoc agents within the neighborhood of mi(t) flocking agents can influence the mi(t) flocking agents to turn min(¦Âj(i) + ¦Á 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Option 1 :</head><label>1</label><figDesc>Turn to border agent a0 Option 2: Turn to border agent a1 Theorem 5. If alignment is possible, Initial orientation a0 a1 Z = 1 + ? min( ¦Ð 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>a2 k i (t)¦Ð m i (t)+k i (t) Option 3: Turn maximally ? ? on each of the first Z ¡ä ? 2 time steps, by ¦Âj(i) + ¦Èi(t) ? ¦Èi(t + 1) + ¦Á 2 on the Z ¡ä ? 1 time step, and by at most</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table>Variables used in Algorithm 2. 

</table></figure>

			<note place="foot">Multiagent Systems (www.ifaamas.org). All rights reserved.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">ACKNOWLEDGEMENTS</head><p>This work has taken place in the Learning Agents Research Group (LARG) at UT Austin. LARG research is supported in part by NSF (IIS-0917122), ONR (N00014-09-1-0658), and the FHWA (DTFH61-07-H-00030).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Leading ad hoc agents in joint action settings with multiple teammates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Agmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAMAS&apos;12</title>
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Statistical mechanics for natural flocks of birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bialeka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavagnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Giardinab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Morad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Silvestrib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vialeb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Walczak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Some causes of the variable shape of flocks of birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Charlotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hemelrijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Readings in agents. chapter Designing a family of coordination algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Lesser</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="450" to="457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Collaborative plans for complex group action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="357" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Soft control on collective behavior of a group of autonomous agents by a shill agent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Systems Science and Complexity</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="54" to="62" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Coordination of groups of mobile autonomous agents using nearest neighbor rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jadbabaie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="988" to="1001" />
			<date type="published" when="2003-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dynamically formed heterogeneous robot teams performing tightly-coordinated tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Browning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Argall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Veloso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Stentz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA&apos;06</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="570" to="575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Reynolds</surname></persName>
		</author>
		<title level="m">Flocks, herds and schools: A distributed behavioral model. SIGGRAPH</title>
		<imprint>
			<date type="published" when="1987-08" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="25" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ad hoc autonomous agent teams: Collaboration without pre-coordination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Kaminka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenschein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI&apos;10</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Leading a best-response teammate in an ad hoc team</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Kaminka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenschein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Agent-Mediated Electronic Commerce: Designing Trading Strategies and Mechanisms for Electronic Markets</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="132" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Flocking of multi-agents with a virtual leader</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="293" to="307" />
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tambe</surname></persName>
		</author>
		<title level="m">Towards flexible teamwork. JAIR</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="83" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Novel type of phase transition in a system of self-driven particles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vicsek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Czirok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ben-Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sochet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PHYS REV LETT</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page">1226</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
