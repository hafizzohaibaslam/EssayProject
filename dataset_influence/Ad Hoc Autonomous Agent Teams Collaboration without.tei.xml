<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 D:\grobid-master\grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.1-SNAPSHOT" ident="GROBID" when="2018-07-16T23:46+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination. Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-05-18">18 May 2016. July 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
							<email>pstone@cs.utexas.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Texas at Austin</orgName>
								<orgName type="laboratory">Bar-Ilan U. &amp; U. of Maryland</orgName>
								<orgName type="institution">University of Texas at Austin Bar Ilan University</orgName>
								<address>
									<settlement>Bar-Ilan U</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Kaminka</surname></persName>
							<email>galk@cs.biu.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Texas at Austin</orgName>
								<orgName type="laboratory">Bar-Ilan U. &amp; U. of Maryland</orgName>
								<orgName type="institution">University of Texas at Austin Bar Ilan University</orgName>
								<address>
									<settlement>Bar-Ilan U</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Stone</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Texas at Austin</orgName>
								<orgName type="laboratory">Bar-Ilan U. &amp; U. of Maryland</orgName>
								<orgName type="institution">University of Texas at Austin Bar Ilan University</orgName>
								<address>
									<settlement>Bar-Ilan U</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><forename type="middle">A</forename><surname>Kaminka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Texas at Austin</orgName>
								<orgName type="laboratory">Bar-Ilan U. &amp; U. of Maryland</orgName>
								<orgName type="institution">University of Texas at Austin Bar Ilan University</orgName>
								<address>
									<settlement>Bar-Ilan U</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarit</forename><surname>Kraus</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Texas at Austin</orgName>
								<orgName type="laboratory">Bar-Ilan U. &amp; U. of Maryland</orgName>
								<orgName type="institution">University of Texas at Austin Bar Ilan University</orgName>
								<address>
									<settlement>Bar-Ilan U</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">S</forename><surname>Rosenschein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Texas at Austin</orgName>
								<orgName type="laboratory">Bar-Ilan U. &amp; U. of Maryland</orgName>
								<orgName type="institution">University of Texas at Austin Bar Ilan University</orgName>
								<address>
									<settlement>Bar-Ilan U</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination. Ad Hoc Autonomous Agent Teams: Collaboration without Pre-Coordination</title>
					</analytic>
					<monogr>
						<title level="m">The Twenty-Fourth Conference on Artificial Intelligence (AAAI)</title>
						<imprint>
							<date type="published" when="2016-05-18">18 May 2016. July 2010</date>
						</imprint>
					</monogr>
					<note>See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/221605178 Conference Paper ¡¤ Source: DBLP CITATIONS READS 36 124 4 authors: 190 PUBLICATIONS 5,009 CITATIONS 216 PUBLICATIONS 2,870 CITATIONS SEE PROFILE SEE PROFILE Sarit Kraus Jeffrey S. Rosenschein Bar Ilan University Hebrew University of Jerusalem 419 PUBLICATIONS 11,991 CITATIONS 251 PUBLICATIONS 6,146 CITATIONS SEE PROFILE SEE PROFILE All in-text references underlined in blue are linked to publications on ResearchGate, letting you access and read them immediately.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>As autonomous agents proliferate in the real world, both in software and robotic settings, they will increasingly need to band together for cooperative activities with previously unfamiliar teammates. In such ad hoc team settings, team strategies cannot be developed a priori. Rather, an agent must be prepared to cooperate with many types of teammates: it must collaborate without pre-coordination. This paper challenges the AI community to develop theory and to implement prototypes of ad hoc team agents. It defines the concept of ad hoc team agents, specifies an evaluation paradigm, and provides examples of possible theoretical and empirical approaches to challenge. The goal is to encourage progress towards this ambitious, newly realistic, and increasingly important research goal.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Imagine that you are in a foreign country where you do not speak the language, walking alone through a park. You see somebody fall off of his bicycle and injure himself badly; there are a few other people in the area, and all of you rush to help the victim. There are several things that need to be done. Somebody should call an ambulance, someone should check that the victim is still breathing, and someone should try to find a nearby doctor or policeman. However, none of you know one another, and thus you do not know who has a mobile phone, who is trained in first aid, who can run fast, and so forth. Furthermore, not all of you speak the same language. Nonetheless, it is essential that you quickly coordinate towards your common goal of maximizing the victim's chances of timely treatment and survival.</p><p>This scenario is an example of what we call an ad hoc team setting. Multiple agents (in this case humans) with different knowledge and capabilities find themselves in a situation such that their goals and utilities are perfectly aligned (effectively, everyone's sole interest is to help the victim), yet they have had no prior opportunity to coordinate. In addition to the emergency setting described above, ad hoc teams may arise among robots or software agents that have been programmed by different groups and/or at different times such that it was not known at development time that they would need to coordinate. For example, rescue robots may be brought to an earthquake site from different parts of the world, or an e-commerce agent may need to coordinate with other legacy agents that can no longer be altered. Note that in this latter example, the agents may need to coordinate repeatedly on the same or similar tasks.</p><p>In order to be a good "ad hoc team player," an agent must be adept at assessing the capabilities of other agents, especially in relation to its own capabilities. If you are trained in first aid, you may be the best person to examine the fallen bicyclist. But if one of the other people is a doctor, you should take on a different role. Similarly, a good team player must also be adept at assessing the other agents' knowledge states (does anybody know the right phone number?). Furthermore, it must be proficient at estimating the effects of its actions on the other agents. How will the others react if you immediately run away, if you pull out a mobile phone, if you start screaming, or if you calmly measure the victim's pulse?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ad Hoc Human Teams</head><p>The concept of ad hoc human teams has arisen recently in military and industrial settings, especially with the rise of outsourcing. There have also been autonomous agents developed to help support human ad hoc team formation <ref type="bibr" target="#b7">(Just, Cornwell, &amp; Huhns 2004;</ref><ref type="bibr" target="#b8">Kildare 2004</ref>). But ad hoc autonomous agent teams have not been relevant in the past because autonomous agents, especially robots, have tended to be deployed only for short times, and teams have been developed by cohesive development groups. As a result, it has typically been possible (and usually necessary) to adjust and tune the agents' behaviors so that they interact well with one another.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ad Hoc Autonomous Agent Teams</head><p>Copyright c 2010, American Association for Artificial Intelligence (www.aaai.org). All rights reserved.</p><p>As the field progresses towards long-lasting autonomy, however, reasoning on the fly about interactions with other agents will become increasingly essential. Unlike most team settings considered so far (e.g., <ref type="bibr" target="#b16">(Stone &amp; Veloso 1999;</ref><ref type="bibr" target="#b13">Rosenfeld et al. 2008)</ref>), agents in ad hoc team settings are not all programmed by the same people, and may not all have the same communication protocols or world models. Furthermore, they are likely to have heterogeneous sensing and acting capabilities that may not be fully known to one another. As a result, team strategies cannot be developed a priori. Rather, an agent that is to succeed in such an ad hoc team setting must be prepared to adjust its behavior to interact as well as possible with many types of teammates: those with which it can communicate and those with which it cannot; those that are more mobile and those that are less mobile; those with better sensing capabilities and those with worse capabilities. A good team player's best actions are likely to differ significantly depending on the characteristics of its teammates. The fact that humans are routinely called upon to coordinate in an ad hoc fashion strongly motivates the challenge of constructing autonomous agents of similar flexibility. achievement, joint discounted reward over a fixed time, number of goals scored, or any other objective measure. Note that s may be a stochastic function.</p><p>Let there be a pool of potential teammates A = {a 2 , . . . , a n }, each of which has some competency in domain D. Specifically, we say that agent a ¡Ê A is competent if there is some subset B ? A such that a ¡Ê B, and the team comprised of the agents in B is able to achieve a minimal threshold expected performance, s min , on all tasks in D: <ref type="bibr">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Challenge</head><p>Our challenge to the community identifies a specific, novel, high-risk, but high-payoff research area. Specifically, we call for theoretical treatments and concrete implementations of robust, autonomous agents that are good ad hoc team players.</p><p>That is, we challenge the community:</p><p>To create an autonomous agent that is able to efficiently and robustly collaborate with previously unknown teammates on tasks to which they are all individually capable of contributing as team members.</p><p>The remainder of this paper is organized as follows. First, Section 2 gives further insight into the details of the challenge via a specification of how potential solutions can be evaluated. Then, Sections 3 and 4 discuss possible theoretical and empirical approaches to the challenge, respectively. Section 5 expands on the ways in which the challenge can be decomposed and/or the scope of the challenge can be gradually increased, Section 6 touches on prior research most related to the challenge, and Section 7 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation</head><p>?a ¡Ê A, ?d ¡Ê D, ?B ? A s.t. a ¡Ê B ¡Ä E[s(B, d)] ¡Ý s min Note that it may be possible for an individual agent to achieve s min , for instance in a domain such as foraging where having teammates is helpful but not essential; or D may be a fundamentally multiagent domain in which agent teams are needed to perform the task at all, such as pushing heavy boxes. Note further that the agents in A need not be themselves aware that they are acting as teammates; indeed when they are "team aware" the interactions among the agents can become considerably more complex.</p><p>We propose comparing agents a 0 and a 1 as potential ad hoc teammates of the agents in set A in domain D according to the following procedure.</p><formula xml:id="formula_0">Evaluate(a 0 , a 1 , A, D)</formula><p>? Initialize performance (reward) counters r 0 and r 1 for agents a 0 and a 1 respectively to r 0 = r 1 = 0.</p><p>? Repeat:</p><p>-Sample a task d from D. -Randomly draw a subset of agents B, |B| ¡Ý 2, from A such that E[s(B, d)] ¡Ý s min . -Randomly select one agent b ¡Ê B to remove from the team to create the team</p><formula xml:id="formula_1">B ? . -increment r 0 by s({a 0 } ¡È B ? , d) -increment r 1 by s({a 1 } ¡È B ? , d)</formula><p>? If r 0 &gt; r 1 then we conclude that a 0 is a better adhoc team player than a 1 in domain D over the set of possible teammates A.</p><p>Though there is plenty of room for theoretical treatment of the problem (see Section 3), the challenge introduced in Section 1 is ultimately an empirical challenge. Additionally, though it pertains to teamwork, it is fundamentally a challenge pertaining to building a single autonomous agent. In this section, we shed further light on the intention of the challenge by specifying a way in which potential solutions can be evaluated.</p><p>Let a 0 and a 1 be two ad hoc teammates whose performance is to be compared in domain D, from which tasks d can be sampled. For example, D may be a multiagent planning domain with each task having different initial conditions and/or goals; or D may be robot soccer, with each task being a match against a particular opponent team. It may also be the case that there is only one task in the domain that is repeatedly "sampled."</p><p>Assume that there is some quantitative performance measure, or "score" s(B, d), that results when a set of agents B performs task d once, such as time to goal Note that there is a lot of potential variability both in the breadth of the domain D (how different the tasks can be) and especially in the breadth of teammate capabilities in A. We address these issues in more detail in Section 5. Note that we assume that agents a 0 and a 1 are aware of the domain D and the set of potential teammates A. But A may have infinite cardinality, in effect just placing bounds on teammate characteristics, such as the teammate will not be able to move faster than 2 m/s. In addition, even if A is finite, on each iteration the set B ? is initially unknown to the ad hoc team agents being evaluated.</p><p>This evaluation paradigm serves to emphasize that an ad hoc team agent is fundamentally an individual agent. To be successful, it must perform well with any set of teammates with which it is presented.</p><p>Although our challenge is ultimately empirical, there is also ample room for theoretical analysis of components of the full problem. For example, aspects of ad hoc teamwork can be usefully studied within the framework of game theory <ref type="bibr">(Leyton-Brown &amp; Shoham 2008)</ref>. Specifically, a good ad hoc team agent should be able to learn to interact with a previously unknown teammate in a fully cooperative (common payoff) iterative normal form game. If the teammate plays a fixed (possibly stochastic) strategy, the ad hoc team agent should simply learn what that strategy is and play the best response. But even in this simplest of scenarios, the problem can become quite intricate to analyze if the teammate may itself be adaptive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collaborative Multi-Armed Bandits</head><p>As an initial theoretical analysis of an aspect of ad hoc teamwork, <ref type="bibr" target="#b15">Stone and Kraus (2010)</ref> consider a situation in which the ad hoc team player interacts repeatedly in a stochastic environment with a teammate that is both less capable and less knowledgeable than itself. Specifically, the teammate can only execute a subset of the actions that the ad hoc team agent can execute, and, unlike the ad hoc team agent, it is unaware of the relative utilities of the various actions. It is also unaware that it is acting as a part of a team. They formalize this situation as an instance of the well-studied k-armed bandit problem <ref type="bibr" target="#b12">(Robbins 1952)</ref>.</p><p>The basic setting of the k-armed bandit problem is as follows. At each time step, a learning agent selects one of the k arms to pull. The arm returns a payoff according to a fixed, but generally unknown, distribution. The agent's goal is to maximize the sum of the payoffs it receives over time. The setting is well-suited for studying exploration vs. exploitation: at any given time, the agent could greedily select the arm that has paid off the best so far, or it could select a different arm in order to gather more information about its distribution. Though k-armed bandits are often used for this purpose, the authors were the first to consider a multiagent cooperative setting in which the agents have different knowledge states and action capabilities.</p><p>In order to study the ad hoc team problem, the authors extend the standard setting to include two distinct agents, known as the teacher and the learner, who select arms alternately, starting with the teacher. They initially consider a bandit with just three arms such that the teacher is able to select from any of the three arms, while the learner is only able to select from among the two arms with the lower expected payoffs. The authors consider the fully cooperative case such that the teacher's goal is to maximize the expected sum of the payoffs received by the two agents over time (the teacher is risk neutral). Specifically, the authors make the following assumptions:</p><p>? The payoff distributions of all arms are fully known to the teacher, but unknown to the learner.</p><p>? The learner can only select from among the two arms with the lower expected payoffs.</p><p>? The results of all actions are fully observable (to both agents).</p><p>? The number of rounds (actions per agent) remaining is finite and known to the teacher.</p><p>? The learner's behavior is fixed and known: it acts greedily, always selecting the arm with the highest observed sample average so far. If there are any previously unseen arms, the learner selects one of them randomly (optimistic initialization). The teacher must then decide whether to do what is best in the short term, namely pull the arm with the highest expected payoff; or whether to increase the information available to its teammate, the learner, by pulling a different arm. Note that if the teacher were acting alone, trivially its optimal action would be to always pull the arm with highest expected payoff.</p><p>By these assumptions, the learner is both less capable and less knowledgeable than the teacher, and it does not understand direct communication from the teacher. It is tempting to think that we should begin by improving the learner. But in the ad hoc team setting, that is not an option. The learner "is what it is" either because it is a legacy agent, or because it has been programmed by others. Our task is to determine the teacher's best actions given such learner behavior.</p><p>This setting is only a limited representation of the full ad hoc team setting from Section 1. However it retains the most essential property, namely that a single agent in our control must interact with a teammate without the advance coordination. Nonetheless, even this initial scenario presents some interesting mathematical challenges. Specifically, Stone and Kraus prove several theoretical results pertaining to which arms the teacher should consider pulling, and under what conditions (including for the natural generalization with more than three arms). Furthermore, when the payoffs from the arms are discrete, they present a polynomial algorithm for the teacher to find the optimal arm to pull. <ref type="bibr" target="#b15">(Stone &amp; Kraus 2010)</ref>.</p><p>The study of collaborative k-armed bandits described in this section serves as a starting point for the theoretical analysis of ad hoc teams. However it leaves open many directions for extensions: situations in which the teacher does not have full knowledge, the learner is "team aware," the number of iterations is not known, and/or the learner's behavior is not known a priori to the teacher, among others. We hope that this ad hoc teamwork challenge will inspire many new and challenging problems in the theoretical analysis of optimal control and optimal teamwork.</p><p>are also likely to be aspects of ad hoc teamwork that are not easily analyzable at all. In such aspects of the problem, there will be plenty of room for useful empirical analyses. In this section, we illustrate a possible empirical approach using the domain of robot soccer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Soccer</head><p>Human soccer is a perfect example of the ad hoc team setting. When given the opportunity, teams of human soccer players train together and hone their interactions so as to refine their ability to cooperate with one another. However individual soccer players are also able to join "pick-up" games with players that they've never met before, let alone played with. They can even do so in foreign countries where they don't know the language, leaving no way to communicate with their ad hoc teammates other than mutual observation and experimentation. A talented human player is able to make quick judgments about how she will best fit into her ad hoc team. When playing with worse players, she is likely to play in the center of the field; when playing with better players she may look for a supporting role that limits responsibility. Furthermore, at the beginning of the game, it may be useful in this situation to take actions that highlight one's particular strengths, such as kicking with the left foot, or passing the ball precisely, so as to teach one's teammates how best to incorporate the newcomer into the team. it should notice and adopt that role; if it is placed on a team with worse players, it should actively go to the ball more often, and so on.</p><p>The essential aspect is that the ad hoc team player should be able to deal with whatever teammates it might come across, and without any foreknowledge of the teammates' actual behaviors on the part of the agents or the programmers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Controlling the Scope: Task and Teammate Breadth</head><p>An ad hoc team player must be prepared to collaborate with all types of teammates. Thus one possible view of the process of creating a fully capable ad hoc team player is that it is akin to equipping it with a toolbox, each tool being useful for interacting with a class of possible teammates, as well as with a method for identifying to which class the current teammates belong.</p><p>From this perspective, in order to create an ad hoc team player, one will need to address three high-level technical challenges. 1. Identify the full range of possible teamwork situations that a complete ad hoc team player needs to be capable of addressing.</p><p>2. For each such situation, find theoretically optimal and/or empirically effective algorithms for behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robot Soccer</head><p>Similarly, robot soccer teams at the international RoboCup competitions are typically developed as cohesive units with communication protocols and sophisticated methods for distributing the players on the field into complementary positions <ref type="bibr" target="#b16">(Stone &amp; Veloso 1999</ref>). However, it is also possible to consider a "pick-up" game in which the players are not able to pre-coordinate.</p><p>As an instantiation of the bandit example in Section 3, one could consider a center midfielder, who can pass to any of three forwards, teaching an outside midfielder, who can only pass to two of them. If the outside midfielder is new to the team and still learning about the forwards' capabilities, we find ourselves in an instantiation of exactly the abstract k-armed bandit scenario. Just as in the abstract setting, it is naturally extensible to model sophisticated learners, partial teacher knowledge, unknown learner behavior, and so on.</p><p>Eventually, one can imagine staging field tests of ad hoc team agents at the annual RoboCup competitions. Several participants with robots of varying strengths could be invited to participate in a robot soccer "pickup game." That is, the robots would be placed on the field as a team without any prior coordination among the human programmers.</p><p>A successful ad hoc team player will be able to quickly evaluate whether it is playing with forwards or defenders, whether it is playing with more skillful players or with less skillful players, etc., and adjust its play accordingly. If it is placed on a team with no goalie, then 3. Develop methods for identifying and classifying which type of teamwork situation the agent is currently in, in an online fashion. Challenges 2 and 3 are the core technical aspects of the challenge. But the first can also be seen as a sort of knob, which can be used to incrementally increase the difficulty of the challenge.</p><p>For this purpose, we start from the literature on ad hoc human team formation <ref type="bibr" target="#b8">(Kildare 2004</ref>) to organize teamwork situations along three dimensions: Teammate characteristics: features of the individual teammates such as action capabilities, sensing capabilities, decision making and learning capabilities, whether they can communicate directly, and prior knowledge.</p><p>Team characteristics: features of the collection of team members such as whether they are homogeneous or heterogeneous, how many teammates are on the team, and whether they can observe each other's actions.</p><p>Task characteristics: features of the cooperative task to be performed such as the goal, the time horizon, whether it is turn-taking, and how closely coordinated the agents need to be in their actions. Can they divide the task at a high level and then act independently, or do they need to coordinate low-level actions? By initially limiting teammate, team, and task characteristics (A and D from Section 2), we can render the challenge approachable even though the full-blown version is quite ambitious. For example, Stone and Kraus's k-armed bandit scenario summarized in Section 3 is appropriate for situations in which the teammates have limited action capabilities, perfect sensing, greedy decision making, no direct communication, and prior knowledge limited to their own observations; the team is heterogeneous, consists of two agents, and can fully observe each other's actions; and the task 's goal is to maximize the sum of discrete action utilities over a finite horizon where the agents act individually in a turn-taking fashion. In that work, the authors found the theoretically optimal action for the ad hoc team player, thus taking a first step towards research challenge 2.</p><p>We expect that the initial responses to this challenge will address subproblems by similarly limiting the scopes of A and D. Indeed, most of the examples given in this paper consider sets A such that the potential teammates are not even necessarily aware that they are a part of an ad hoc team; this case is the simplest to consider. However, it will be an important aspect of the challenge to consider sets A that include other agents that are aware that they are on an ad hoc team. Eventually, there will be opportunities to generalize and/or combine these subproblems into a more complete ad hoc team agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Related Work</head><p>This challenge is predicated on the assumption that software agents and robots will soon be able to be deployed for extended periods of time in the real world. That is, their usefulness will outlive our ability to easily change their behaviors. Such a phenomenon has already occurred with conventional computer programs, as became apparent when the world was worried about the "Y2K bug." COBOL programmers were called out of retirement to try to reprogram computers that were essential to business processes and vital infrastructure, but that were black boxes to everyone who used them.</p><p>Were autonomous agents to become similarly longlived, it would be a huge landmark in their robustness and reliability. However it would also expose us to the problem that this challenge addresses. Namely, a new agent may need to collaborate with older agents whose behavior is already fixed and not easily changeable.</p><p>Ad hoc teams are also already needed for environments where agents with diverse capabilities and no common framework must quickly work as a team. As presented in Section 1, one example is when robots from different developers come together on a common rescue mission. A second example arises when software agents, programmed in isolation, must act within a team setting. These agents might need to analyze scheduling data from different people to help coordinate meetings on their behalf, or they might need to coordinate with legacy agents that can no longer be altered.</p><p>The main focus of this research challenge is ad hoc teams in which teammates need to work together without any prior coordination. This perspective is at odds with most prior treatments of teamwork, such as SharedPlans ( <ref type="bibr" target="#b6">Grosz &amp; Kraus 1996</ref>), STEAM (Tambe 1997), and GPGP <ref type="bibr" target="#b5">(Decker &amp; Lesser 1995</ref>) which define explicit coordination protocols, languages, and/or shared assumptions about which the agents are mutually aware. In applications such as the annual RoboCup robot soccer competitions, entire teams of agents are designed in unison, enabling explicit pre-coordination via structures such as "locker room agreements" <ref type="bibr" target="#b16">(Stone &amp; Veloso 1999</ref>).</p><p>Other than the multi-armed bandit work previously described, the work that we are aware of that takes a perspective most similar to ad hoc teams is that of <ref type="bibr" target="#b0">Brafman and Tennenholtz (Brafman &amp; Tennenholtz 1996</ref>) in which they consider a teacher agent and a learner agent repeatedly engaging in a joint activity. While the learner has no prior knowledge of this activity, the teacher understands its dynamics. However they mainly consider a situation in which teaching is not costly: the goal of their teacher is to maximize the number of times that the learner chooses the "right" action. Thus in some sense, the teacher is not "embedded" in the environment as a real teammate.</p><p>Although the complete challenge put forth in this paper is very ambitious and likely to take many years to meet in a fully satisfactory way, there are numerous existing techniques that may be useful starting points for certain aspects of the challenge (e.g., for certain properties of A and D). The remainder of this section provides a small sampling of such existing techniques.</p><p>? As mentioned in Section 3, game theory <ref type="bibr">(Leyton- Brown &amp; Shoham 2008</ref>) provides a useful theoretical foundation for multiagent interaction. Though originally intended as a model for human encounters (or those of human institutions), it has become much more broadly applied over the last several decades.</p><p>? A good ad hoc team player may need to make an explicit assumption that its teammates are observing and reacting to its actions (that they are "team aware"). In doing so, the agent is actually planning its actions intending for them to be observed and interpreted. Intended plan recognition (in contrast to keyhole recognition) is the term used when the observed agent knows that it is being observed, and is acting under the constraints imposed by this knowledge <ref type="bibr" target="#b2">(Carrbery 2001)</ref>. Much of the work on planning for intended recognition settings has focused on natural language dialogue systems <ref type="bibr" target="#b14">(Sidner 1985;</ref><ref type="bibr" target="#b9">Lochbaum 1991</ref>).</p><p>? An important aspect of the ad hoc team challenge is recognizing, or "modeling" the capabilities of one's teammates. For this purpose, work from the opponent modeling literature (e.g., <ref type="bibr" target="#b1">(Carmel &amp; Markovitch 1995;</ref><ref type="bibr" target="#b18">Stone, Riley, &amp; Veloso 2000;</ref><ref type="bibr" target="#b10">Oshrat, Lin, &amp; Kraus 2009)</ref>) may be readily adaptable to similarly model teammates.</p><p>In addition, a good ad hoc team agent must recognize the possibility that, while it is attempting to model its teammates, the teammates may be simultaneously modeling it. In such a case, the agent is engaged in a recursive modeling setting <ref type="bibr" target="#b21">(Vidal &amp; Durfee 1995)</ref>.</p><p>? Claus and Boutilier <ref type="bibr" target="#b4">(Claus &amp; Boutilier 1998)</ref> show how reinforcement learning can provide a robust method for agents to learn how to coordinate their actions. This work is one of many approaches for cooperative multiagent learning (see surveys at <ref type="bibr" target="#b11">Panait &amp; Luke 2005)</ref>). In addition to existing AI methods, as mentioned in Section 1, previous work has examined the use of agents to support the formation of human ad hoc teams <ref type="bibr" target="#b7">(Just, Cornwell, &amp; Huhns 2004;</ref><ref type="bibr" target="#b8">Kildare 2004</ref>). This work relies on an analysis of the sources of team variability, including member characteristics, team characteristics, and task characteristics <ref type="bibr" target="#b8">(Kildare 2004</ref>), which we borrow as a structure for classifying types of autonomous teammates in Section 5. In addition, software agents have been used to support the operation of human teams <ref type="bibr" target="#b3">(Chalupsky et al. 2001)</ref>, and for distributed information gathering from distinct, otherwise independent information sources ( <ref type="bibr" target="#b19">Sycara et al. 1996</ref>). But we are not aware of any such work that enables an autonomous agent to itself act as an ad hoc teammate with previously unknown teammates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper presents the concept of ad hoc autonomous agent teams and challenges the community to develop novel theoretical and empirical approaches to creating effective ad hoc teammates. Though today most agent teams are developed as a unit, we believe that it will not be long before autonomous agents, both in software and robotic settings, will very often need to band together on the fly (possibly with humans on their teams as well!). We hope that this challenge will encourage the research necessary to ensure that agents will be able to do so effectively when that time arrives.</p></div>
			<note place="foot" n="1"> For notational convenience, we assume that larger performance values indicate better task performance.</note>

			<note place="foot" n="4"> Example Empirical Approach While theoretical analyses are likely to be able to identify some situations in which optimal decision-making is possible, they are also likely to identify aspects of ad hoc teamwork that are not tractably solvable. There</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Thanks to the UT Austin Learning Agents Research Group for useful comments and suggestions. This work was partially supported by grants from NSF (IIS-0917122, IIS-0705587), DARPA (FA8650-08-C-7812), ONR (N00014-09-1-0658), FHWA (DTFH61-07-H-00030), Army Research Lab (W911NF-08-1-0144), ISF (1357/07, 898/05), and the Fulbright and Guggenheim Foundations.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On partially controlled multi-agent systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Brafman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tennenholtz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="477" to="507" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Opponent modeling in a multi-agent system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI-95 Workshop on Adaptation and Learning in Multiagent Systems</title>
		<editor>Sen, S., ed.</editor>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="8" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Techniques for plan recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carrbery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="31" to="48" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Electric elves: Applying agent technology to support human organizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chalupsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Knoblock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pynadath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Russ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tambe</surname></persName>
		</author>
		<idno>IAAI-01</idno>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The dynamics of reinforcement learning in cooperative multiagent systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Claus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Boutilier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI-98</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="746" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Designing a family of coordination algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Lesser</surname></persName>
		</author>
		<idno>73-80</idno>
	</analytic>
	<monogr>
		<title level="m">ICMAS-95</title>
		<meeting><address><addrLine>Menlo Park, California</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Collaborative plans for complex group actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Grosz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="269" to="358" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Agents for establishing ad hoc cross-organizational teams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cornwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huhns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/WIC/ACM International Conference on Intelligent Agent Technology</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="526" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ad-hoc online teams as complex systems: agents that cater for team interaction rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">; K</forename><surname>Kildare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shoham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Asia-Pacific Conference on Complex Systems. Leyton-Brown</title>
		<meeting>the 7th Asia-Pacific Conference on Complex Systems. Leyton-Brown</meeting>
		<imprint>
			<publisher>Morgan and Claypool Publishers</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Essentials of Game Theory: A Concise, Multidisciplinary Introduction</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An algorithm for plan recognition in collaborative discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Lochbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="33" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Facing the challenge of human-agent negotiations via effective general opponent modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Oshrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAMAS-09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cooperative multi-agent learning: The state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Panait</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAMAS-05</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="387" to="434" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Some aspects of the sequential design of experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Robbins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bulletin American Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="527" to="535" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A study of mechanisms for improving robotic group performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Kaminka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shehory</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">6-7</biblScope>
			<biblScope unit="page" from="633" to="655" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Plan parsing for intended response recognition in discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Sidner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">To teach or not to teach? decision making under uncertainty in ad hoc teams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kraus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAMAS-10. International Foundation for Autonomous Agents and Multiagent Systems</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Task decomposition, dynamic role assignment, and low-bandwidth communication for real-time strategic teamwork</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="273" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multiagent systems: A survey from a machine learning perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Autonomous Robots</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="383" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Defining and using ideal teammate and opponent models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
		<idno>IAAI-00</idno>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Distributed intelligent agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sycara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pannu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Expert</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Towards flexible teamwork</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tambe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAIR</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="81" to="124" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Recursive agent modeling using limited rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Durfee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMAS-95</title>
		<imprint>
			<publisher>AAAI/MIT press</publisher>
			<date type="published" when="1995" />
			<biblScope unit="page" from="125" to="132" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
