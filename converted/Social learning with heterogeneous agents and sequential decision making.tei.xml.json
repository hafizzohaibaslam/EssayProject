[
     {
          "head": {
               "n": "0",
               "text": "abstract",
               "type": "abstract"
          },
          "paragraphs": [
               "In this paper, we consider the problem of social learning in a network of agents where the agents make decisions sequentially by choosing one of two hypotheses on the state of nature. Each agent observes a signal generated according to one of the hypotheses and knows the decisions of all the previous agents in the network. The network contains two types of agents: rational and irrational. A rational agent makes a decision by not only using its private observation but also the decisions of each of the agents which already made decisions. To that end, the agent employs Bayesian theory. An irrational agent makes a decision by ignoring the available information and by randomly choosing the hypothesis. We analyze the asymptotic performance of a system with rational and irrational agents where we study rational agents that use either a deterministic or random decision making policies. We propose a specific random decision making policy that is based on the social belief and the private signals of the agents. We prove that under mild conditions the expected social belief in the true state of nature tends to one if the rational agents use the proposed random policy. In a network with rational agents that use deterministic policy, the conditions for convergence are stricter. We provide simulation results on the studied systems and compare their performance."
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 0,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "n": "1.",
               "text": "Introduction",
               "type": "introduction"
          },
          "paragraphs": [
               "An important issue in social learning is how agents make decisions and learn from the decisions of other agents. When agents make decisions based on private and imperfect information, it is natural that they also use information in the decisions of other agents made in a similar situation. In this work, we consider agents that make their decisions on one of two hypotheses H 0 and H 1 one at a time in a sequential manner. When an agent makes its own decision, it broadcasts it to all the agents that will subsequently be making decisions. The graph that describes our system is a directed graph shown in . We note that the motivation for studying this network is understanding some basics of social learning with random decision making rather than a particular application of signal processing.",
               "Applications of sequential decision making can be found in many fields including distributed detection in wireless sensor networks. There, the need for low-cost and low-power devices forces every sensor to aggregate all its information into a one bit decision . In , a comprehensive introduction to this problem was provided. Another major application is the understanding of social learning in multi-agent systems. In these systems, the agents make decisions not only from their private observations, but also from the decisions made by others . As indicated in , the study of social learning addresses the problems of modeling the interaction of the agents in the network while learning takes place.",
               "In social learning systems, an agent can learn from the decisions of agents that already made them by using either nonBayesian approaches or the Bayesian methodology. For example, in , non-Bayesian social learning methods were studied. In , the agents had Bayesian social learning strategies in obtaining information from previous decisions. Although the Bayesian learning methods provide a fast convergence rate to one of the hypotheses, the agents that employ the Bayesian machinery may ignore their private observations and herd on the wrong decision. Some work on this issue can be found in , where the interest was in studying herding behavior and information cascades. In , the authors provided the sufficient conditions for asymptotic learning in Bayesian social learning systems. In , the author studied this problem from the perspective of quickest time change detection. Recently, random decision making was addressed in . In , the authors considered the effect of the decisions of subsequent agents on the utility of a current agent by using a Chinese restaurant game model. They proposed an optimal strat-egy for decision making. This approach was applied to cognitive radio networks . Another extension of this problem was a scenario with noisy links , where the decisions were broadcasted through a noisy channel and thereby the decisions could be randomly flipped or erased. An overview of models and techniques for studying social learning can be found in . In this paper, our study is within the framework of Bayesian social learning.",
               "In the analysis of social learning systems, one typical question is the following: Does the probability of error in decision making converge to zero as the number of agents goes to infinity? The answer depends on (a) whether the log-likelihood ratio of private observations is bounded and (b) whether the memories of the agents are finite (the size of the memory of an agent is the number of decisions of other agents available to the agent). In , the problem with finite memory was addressed. In , a system where each agent could only observe the decision of its immediate previous agent was investigated. It was shown that if the likelihood ratio test is employed for decision making, the error probability does not converge to zero if the ratio is bounded. In , social learning with sampling of past decisions was addressed. There, each agent made inference by the Bayesian method and using very few samples from the decision history of the agents. In the case of bounded log-likelihood ratios, a non-Bayesian decision policy was proposed whose probability of decision error converges to zero . In , the agents had infinite memory, and the conditions for asymptotic learning were listed.",
               "In the literature, it is common to assume that the agents know the decision making policy of the other agents, or that the policy is identical for every agent (e.g., ). In this work, we address the problem of social learning in a system of heterogeneous agents. The agents can be either rational or irrational and they make the decisions sequentially, one at a time. A rational agent makes a decision according to the posterior of the hypotheses (conditioned on the decisions of the previous agents and its private observation). By contrast, an irrational agent simply ignores all its available information and makes a decision by flipping a fair coin. The agents do not know which of them are rational and irrational but they know the percentage of irrational agents in the network.",
               "More related work on social learning with heterogeneous agents can be found in . In , the problem of misinformation spread was addressed, where the social system was modeled by a random network and the agents used a gossip style method to update their beliefs from the exchanged information. In , with a binary voter model, the authors studied the effect of stubborn agents in social systems. There, the stubborn agents are agents that never change their beliefs. In , the authors discussed the relationship between the convergence rate of an average-based learning method and the homophily of the multitype random networks. In all of these papers, however, there is no randomness in the decisions making.",
               "In this paper, we study two cases. In the first, the rational agents for decision making use a deterministic policy whereas in the second, they employ a random policy. In , we proposed a random decision making policy and compared it to the deterministic policy. In that comparison, all the agents were rational. We showed that with the deterministic policy, the probability of decision error may fail to converge to zero due to an information cascade. On the contrary, with the random policy, the probability of decision error is guaranteed to converge to zero. In this work, because of the presence of irrational agents, this probability does not converge to zero. However, if an agent is rational, its probability of a decision error converges to zero. Furthermore, if the social belief is defined by the posterior on the true state of nature conditioned on all the known decisions, then we show that it always converges to one in probability if the rational agents adopt the random decision making policy. This is not the case when they . Social learning in a sequential decision making system. The symbol y n is the private signal of agent A n , andn is the decision of this agent.",
               "use the deterministic policy. In summary, the main contributions of this paper are (1) a proof that the presence of irrational agents does not affect the asymptotic probability of the rational agents if they adopt random policy and (2) a proof that in a system with random agents herding does not take place.",
               "The paper is organized as follows. In the next section we describe the models of the sequential system and explain the social learning process. In Section 3, we introduce both the deterministic and the random decision making policies. The analyses of the convergence of the social belief and the probability of decision error are provided in Section 4. Simulation results are presented in Section 5, and concluding remarks in Section 6."
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 1,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "n": "2.",
               "text": "Problem formulation",
               "type": "modelling"
          },
          "paragraphs": [
               "The process of social learning is illustrated in . We consider the decision making problem in networks of agents A n , nN + , where the agents make decisions and broadcast them sequentially one at a time to all the subsequent agents. Mathematically, each agent A n receives an independent private observation y n that is generated according to one of the following two hypotheses:",
               "wherek (y n ) denotes the distribution of observation y n under H k , ?k{0, 1}. We assume that these two distributions are known to all the agents and that each agent has noninformative prior probabilities on the hypotheses. Thus, we have p(",
               "be the log-likelihood ratio (LLR) of the hypotheses. We discriminate two types of LLRs, bounded and unbounded. An LLR is bounded if there exist two finite real numbers m and",
               "In the network, there is a positive probability that an agent A n behaves irrationally. An irrational agent A n , makes its decision by drawing from a Bernoulli distribution with parameter(0, 1),",
               "wheren denotes the decision made by A n andnA = {0, 1}.",
               "Let I n be an indicator function taking a value of one if the agent A n is irrational; otherwise, it is zero. Then we set that p(I n = 1) =< 1, ?nN + . In the rest part of this paper, we assume that bothandare known by all the agents in the network.",
               "Here we remark that the model in (2) is just one possible formulation of irrational behavior. In our work, an irrational agent is an agent that ignores all the available information to it and makes decision randomly according to a certain law. The simplicity of this irrational behavior model notwithstanding, allows us to demonstrate very interesting asymptotical properties of the studied system, which are of primary interest here.",
               "The rational agents, on the other hand, make their decisions by not only using their private observations, but also learning from where q k denotes the probability that a rational agent A n makes a decision one given that H k is true, i.e.,",
               "others' decisions. Let1:n be the decision sequence from agent A 1to agent A n . Then the agent A n can formulate its private belief in H 1 ,n = p(H 1 |1:n?1 , y n ), by using Bayes' rule given by the following equation, ?nN + :",
               "where we definen to be the social belief in H 1 conditioned on In the proposed system, an irrational agent A n is active only when it is its turn to make a decision, which is made according to . On the other hand, a rational agent A n behaves as follows. While it is following the decisions of the previous agents, it calculates the action likelihoods l (1) t and l t (t < n) and updates the the action sequence until and including agent A n , i.e., social belieft?1 tot by (5). When t = n, A n observes y n , and",
               "with0 being defined by 1/2. We note that the private beliefn it calculates its private belief by (3). Finally, it makes its decision according to . This sequential learning algorithm of the rational agents belongs to the class of \"social learning filters\" .",
               "represents the posterior on H 1 conditioned on all the information available to A n . Furthermore, the social beliefn?1 serves as the Algorithm 1: The behavior of a rational agent A n .",
               "prior knowledge of A n before it receives its private observation y n .",
               "Initialize0 = 0.5.",
               "In this system, once A n makes its decisionn , all the following agents should update the social belief by Bayes' rule fromn?1 ton . Recall that the studied network is composed of heterogeneous agents, and therefore when the decisionn is broadcasted, the folwhile tn do if t < n then A n observes the decision made by agent A t ;",
               "A n calculates the action likelihoods l A n updates the social belieft?1 tot by (5);",
               "lowing agents do not know if the decision is made by a rational or an irrational agent. Thus, in updating the social belief, this has to be taken into consideration, which is done by marginalizing the hidden random variable I n . By the definition in (4), we have that the social belief is updated according to else A n calculates its private belief by (3) after observing y n ; A n makes its decision according to ;",
               ",",
               "n where depending on the actionn (zero or one), the updatedn",
               "In this paper, we address two decision making policies of rational agents and analyze the asymptotic performance of systems with such agents. Namely, we study heterogeneous systems composed of rational and irrational agents, where the rational agents follow either deterministic or random decision making policies.",
               "is either equal to the first or second factor, respectively. In both cases, we have that ?k{0, 1},",
               "A common deterministic decision making policy of an agent A n is defined by ",
               "denotes the probability of agent A n making decisionn = 1 given the decision sequence up ton?1 and the true state of nature being H k . As in , we refer to l (k) n as action likelihood. Due to the possibility that one decision can be made by an irrational agent, the action likelihood is obtained by using the total probability theIf we set the reward to one when the agent makes a decision identical to the true hypothesis, and zero otherwise, by the above rule, the expected utility of A n is maximized . We call this policy deterministic because once the private beliefn has been formed, the orem. For n = 1, we set l (k) decisionn is made deterministically. In the literature, such agents",
               "are called myopic.",
               "A rational agent A n , after obtaining its private belief by the Bayes' rule in (3), makes a decision according to some policy. We"
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 2,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "n": "3.2.",
               "text": "Random policy",
               "type": "modelling"
          },
          "paragraphs": [
               "describe the policy as a random map of the private beliefn to the action space A = {0, 1}. Mathematically, the agent makes its decision from a certain distribution conditioned onn , i.e.,n ? p(n |n )."
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 3,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "text": "(7)",
               "type": "modelling"
          },
          "paragraphs": [
               "An alternative to the deterministic policy is a random policy. In , we defined a random policy where the decision of the agent is drawn from a Bernoulli distribution defined by We note that, both the deterministic and random decision making can formally be described by .",
               "Given the decision making policy p(n |n ) and the known value of, the agents can obtain the action likelihood by marginalThus, the decisionn of A n is a Bernoulli random variable parameterized by the A n 's private beliefn . In social systems, the actions izing out y n . It is given by of the agents are sometimes naturally or by design random. Although these agents do not maximize an explicit utility function, we still call them rational.",
               "In the proposed social learning system,n (1:n ) = p(H 1 |1:n ), that isn is a function defined by the action sequence1:n (there is a deterministic mapping from1:n ton ). In the analysis that",
               "Noting thatn[0, 1], and l",
               "follows, without loss of generality, we assume that the true hypothesis is H 1 . We will also simplify the notation and will express n[0, 1], then it can be shown that (1:n )0.",
               "Because p(1:n?1 |H 1 )0, ?1:n?1A n?1 , we have provedn (1:n ) asn . Considering that1:n is random due to the random observations and the random policy if it is applied,n is a discrete random process. Sincen reflects the performance of the system that the expected social belief is non-decreasing. 2",
               "Considering the symmetric structure of the proposed system, at n, we want to describe it in statistical terms. To that end we use En , which is given by we can make a similar claim about the behavior of En when H 0 is true. Then, the sequence En is monotonically non-increasing.",
               "One can prove this by repeating the same process as in the above proof with a few notational changes.",
               "n By Theorem 1 and the fact that En is bounded, we can read-=n p(1:n ).",
               "1:nA n ily show that the expected social belief must converge. We next will analyze the limit of this sequence when the deterministic and random policies are used.",
               "Since the agents use the Bayesian method to learn from the decision sequence, it can be shown that their average performance cannot decrease if more information becomes available to the system. Mathematically, in the following we present a theorem that states the relationship between the action likelihood and the"
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 4,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "n": "4.1.",
               "text": "Deterministic policy",
               "type": "modelling"
          },
          "paragraphs": [
               "We start our analysis with the definition of information cascade from . It is defined as follows: an information cascade occurs monotonic property of the En : at timn if the public belief stops evolving after agent An , i.e.,",
               "In the proposed sequential decision making system, when the true state of nature is H 1 , the expected value of social belief is monotonic, i.e., ?tN + , n. As is shown in , if the LLR of the social learning system with deterministic policy is bounded, the probability that information cascade occurs converges to one. Instead of repeating the proof here, we briefly sketch it as follows.",
               "Then by (10), we get that if the social beliefn < u orn > U , the agent A n will make its",
               "Proof. By (12), we can write decision without using its private information even if it is rational, ? p(n |1:n?1 , H 1 )n ? , n , meaning that the social belief does not change after the decisionn is made, i.e.,n =n?1 . Moreover, once the social belief leaves ",
               "is strictly positive. This is because if all the agents after A n make decisions as one or as zero, then the social belief will evolve to the range or in finite time, respectively. Noting that the1:n?1A n?1 probability for this event is strictly positive, the above statement where (1:n ) is a function of the action sequence1:n , which is is true. Then we have that there exists0N + and a p 0 > 0 such that ?n[u, U ], p given by,",
               "> p 0 , where0 is the upper bound of all thes and p 0 is the lower bound of all the",
               "s. With the above arguments, we get that the probability of ab-",
               "sence of information cascade after0 is smaller than 1 ? p 0 . From Noting thatn is updated fromn?1 according to and that p(n |1:n?1 , H 1 ) can be expressed by the action likelihood in (9), we can rewrite (1:n ) in the following form: the chain rule of probability theory, it follows that the probability of absence of information cascade will converge to zero exponentially as time goes to infinity.",
               "On the other hand, (6) also implies that if l",
               "n ,n =n?1 .",
               "2 Therefore if l",
               "n for arbitraryn?1 , information cascade will",
               "With the following lemma, we show that when the LLR is unbounded, information cascade cannot occur.",
               "n Lemma 1. With the deterministic policy, if (a) the two distributions0",
               "From the above equation, one can derive that and1 are not identical everywhere, (b) 0 <n?1 < 1, and (c) the LLR is unbounded, then l",
               "Proof. By , we have where Z is the multiplication of the two denominators in (16) and is given by",
               "Then it is sufficient to show q 1 = q 0 , ? 0 <n?1 < 1."
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 5,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "text": "��",
               "type": "modelling"
          },
          "paragraphs": [
               "By the deterministic policy defined in (10), the decision region",
               "forn = 1 denoted by S 1 can be written as",
               "andThen it follows that p(n = 1|1:n?1 , y n , I n = 0) equals to one if y nS 1 and zero otherwise. Therefore from (9), if the deterministic",
               "?policy is used, we have that",
               "dy n = 0, we have that I 1 + I 2 = 0. Assuming that I 1 = 0, then we must have I 2 = 0. This, however, is contradicted by the following equation:",
               "Given that 0 <n?1 < 1 and that the LLR is unbounded, both",
               "S 1 and its complimentary set S 0 must be nonempty. Next, we",
               "show that q 1 ? q 0 > 0 by considering the following two cases. If",
               "2 does not equal to zero for all y n .",
               "Hence we conclude that for arbitrary distributions0 and1 , the above lemma holds. 2 y nS 1 because ?y nS 1 ,1 (y n ) >0 (y n ). Otherwise,n?10.5 shows that ?y nS 0 ,1 (y n ) <0 (y n ). Then we have Lemma 2 indicates the difference between the deterministic and random policies. When the random policy is adopted, the social belief will not stop evolving regardless of the LLR.",
               "y nS 0",
               "With and , the proof of Lemma 1 is completed. 2",
               "With the above lemmas, we can now get the limits of the expected social belief. Also we show when the probability for a rational agent making an error decision converges to zero. With the next theorem, we first show the limit of the expected social belief.",
               "We point out that the result in Lemma 1 shows that information cascade cannot occur when the LLR is unbounded in the studied system. In , a similar result can be found except that there all the agents are rational.",
               "Theorem 2. Suppose that the agents implement the deterministic policy in (10) with an unbounded LLR or the random decision policy in . Let In contrast to the deterministic policy, the random policy in shows that even if the LLR is bounded, the social belief still can evolve after it becomes greater than U or smaller than u. With the following lemma, we show that the information cascade can be prevented by using the random policy.",
               "Proof. Here we only prove . The proof of is similar. First by theorem one, noting thatn is bounded, we have that the limit Lemma 2. With the random policy, if the two distributions0 and1 are of (15) must be zero, i.e., not identical everywhere and if 0 <n?1 < 1, it holds that l",
               "Proof. Again, we prove the lemma by showing q 1 ? q 0 = 0 for any nn?1 . From (9), we have that which implies that ?1:n?1A n?1 , lim np(1:n?1 |H 1 )",
               "(1:n?1 ) = 0. By Lemmas 1 and 2, we have that (l",
               "?",
               "only whenn = 0 orn = 1. Then Eq. shows that (1:n?1 ) = 0 if and only ifn = 0 orn = 1. Therefore, for arbitrary1:n?1 , it must hold that either lim np(1:n?1 |H 1 )(1 ?n?1 ) = 0 or Noting thatn?1 = 0, we have lim np(1:n?1 |H 1 )n?1 = 0. By (5),n?1 converges to zero only when every agent herds onH 0 after a certain agent. Since an information cascade cannot hap-",
               "?pen and given H 1 is true, we have that the probability ofn?1 = 0 converges to zero. Namely, for any decision sequence1:n?1 for whichn?1 converges to zero, we must have",
               "represents the ratio of social beliefs in H 0 and H 1 .",
               "We now prove that q 1 = q 0 by contradiction. Define",
               "By summarizing the two cases, for an arbitrary decision sequence n?1 , we write q 0 by",
               "Hence, we have lim np(1:n?1 |H 1 )(1 ?n?1 ) = 0.",
               "(34)",
               "Then by (12), we show that the limit of En is one, given by",
               "Considering that the rational agents are using Bayes' rule to formulate their private beliefs, it can be shown that given H 1 is true, the expected private belief is no smaller than the expected social belief. Then the expected private belief for rational agents also converges to one. Symmetrically, under H 0 , the expected private belief will converge to zero. In summary, we have that ",
               "where H s is the true state of nature.",
               "Considering the decision policies in and , the result in (36) suggests that the probability of decision error for a rational agent can converge to zero when the deterministic policy with unbounded LLR or the random policy (independently of the condition on boundedness of the LLR) are applied. Given H s is the true state of nature, we get that lim np(n = s|I n = 0) = 1, ?s{0, 1}."
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 6,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "text": "(37)",
               "type": "modelling"
          },
          "paragraphs": [
               "Therefore, as n goes to infinity, the probability for one agent to make a right decision is given by lim 1 ?,",
               "where, we recall,is the probability that an agent in the network is irrational. Note that in the above derivation,can take any value between zero and one. We remark that asymptotic learning can be achieved by random policy with any 0 << 1. However, as we show in the next section, the convergence speed decreases asgrows.",
               "given by the average social belief from all the 2000 trials. From the figure, we see that the expected social beliefs kept increasing when the agents used the random policy, whereas, as expected, it leveled off when they employed the deterministic policy. We also"
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 7,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "n": "5.",
               "text": "Simulations",
               "type": "modelling"
          },
          "paragraphs": [
               "observe that a largerresulted in a lower convergence speed of In this section, we present simulation results on the evolution of social beliefs in sequential decision making systems along with some numerical comparisons between different decision policies.",
               "In the first experiment, we applied the methods for a binomial data model given by the expected social belief.",
               "Another performance metric of interest is the proportion of agents that made the right decision. The results of its investigation are plotted in . As shown in the with the random policy, the probability for agents to make correct decision converged to 0.95 and 0.85 when= 0.1 and= 0.3, respectively.",
               "where B(m, p) represents a binomial distribution parameterized by m and p. It can be shown that the LLR of this model is bounded.",
               "We verified the analytical result of the expected social belief by Monte Carlo methods, which were conducted with 2000 trials.",
               "Recall that this probability converged to 0.85 and 0.95, respectively, instead of 1 because both the rational and irrational agents are counted in the calculation. Also, the figure indicates that the probability of decision error for the rational agents with random policy converged to zero. By contrast, if the deterministic policy was used, it can be seen that the right decision probability stopped increasing because of information cascade. Again, we observe thatcan In each trial, we set the number of agents to be N = 1500, and they observed data generated from the data model listed in and parameterized by m = 6, p 0 = 0.6, and p 1 = 0.7. We tested the system with= 0.5 and with two values of,= 0.1 and= 0.3. The private signals of the agents were generated according to H 1 .",
               "We show the results of the deterministic and random policies in . On the abscissa, we plotted the agent index and on the ordinate the estimate of the expected social belief, which was decrease the speed of learning.",
               "As shown in Section 4, when the deterministic policy is adopted, herding occurs in finite time with probability one. In , for each agent A n , we plotted the proportion of trials with herding already started before A n . In other words, we plotted the empirical cumulative distribution function (c.d.f.) of the starting time of herding when the deterministic policy is used. There, the two curves represent the performance of the studied system with= 0.1 and= 0.3, respectively. It can be seen that the herding starts earlier when there is a larger proportion of rational agents.  With each of the settings, the random policy was implemented 2000 times. On the left side of , we plotted the evolution of the expected social belief. It can be seen that the evolution of the expected social belief is insensitive to the value of. This is because the decisions of the irrational agents provide no information to the other agents, irrespective of the decision rule they use.",
               "Thus, we can see thathas little effect on the decision making of the rational agents. On the right side of , we plotted how the proportion of agents making the correct decision evolves for different values of. There we observe that the converged values are In , we plotted the evolution of social belief with the Gaussian model. We observe that the expected social beliefs increase for both policies. Unlike with the binomial data model, information cascade did not occur.",
               "In , we plotted the proportion of agents making correct decision. As shown in the figure, the agents applying both policies had a trend of making the right decision asymptotically. This shows that asymptotic learning can be achieved with both policies. As opposed to the result from experiment one, we observed that the probability for correct decision kept increasing at all times. As we have proved in Theorem 2, because of the unbounded LLR, even with the deterministic policy, the proportion of agents making the as predicted by (38), which are 0.97, 0.85, and 0.73, respectively.",
               "In the third experiment, we let the data be generated by a Gaussian data model given by correct decision will converge to 0.95 when= 0.1 and to 0.85 when= 0.3. In , it is also shown that the irrational agents can slow down the learning in the system. Namely, there was a sig-H 1 : y n ? N (,2 nificant decrease of convergence speed whenwas changed from= 0.1 to= 0.3. We also observe that the deterministic policy w ), H 0 :",
               "has a faster speed in the short run, while the random policy converges faster in the long run.",
               "where y n was a Gaussian random variable, and the parameters"
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 8,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     },
     {
          "head": {
               "n": "6.",
               "text": "Conclusions",
               "type": "conclusion"
          },
          "paragraphs": [
               "andw were known by the agents. Compared with the binomial data model, we have proved that the expected social belief will converge with both policies since the LLR is now unbounded.",
               "We conducted the second experiment by repeating the same process of experiment one. The sequential decision making was In this paper we presented a sequential learning system constituted by rational and irrational agents. The rational agents made their decisions by using the Bayesian methodology whereas the irrational agents made decisions arbitrarily. The rational agents can exploit the information from previous decisions by Bayesian learning. We applied two policies to the system and showed their asymptotical properties by investigating the convergence of the expected social belief in the system. In analyzing the deterministic policy, we proved that information cascade takes place with probability one if the data model entails a bounded log-likelihood ratio. By contrast, with the random policy, information cascade does not occur and the probability of decision error of the rational agents converges to zero. We demonstrated the performance of the proposed method by Monte Carlo simulations. We showed that the expected social belief converged to one with the random policy even with a bounded LLR, whereas the expected social belief stopped evolving with the deterministic policy."
          ],
          "paper_id": "23e4d3a0-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 9,
          "fromPaper": "Social learning with heterogeneous agents and sequential decision making"
     }
]