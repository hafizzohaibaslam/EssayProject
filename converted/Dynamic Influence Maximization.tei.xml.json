[
     {
          "head": {
               "n": "0",
               "text": "abstract",
               "type": "abstract"
          },
          "paragraphs": [
               "Influence maximization is a problem of maximizing the aggregate adoption of products, technologies, or even beliefs. Most past algorithms leveraged an assumption of submod-ularity that captures diminishing returns to scale. While submodularity is natural in many domains, early stages of innovation adoption are often better characterized by con-vexity, which is evident for renewable technologies, such as rooftop solar. We formulate a dynamic influence maximiza-tion problem under increasing returns to scale over a finite time horizon, in which the decision maker faces a budget constraint. We propose a simple algorithm in this model which chooses the best time period to use up the entire budget (called Best-Stage), and prove that this policy is optimal in a very general setting. We also propose a heuristic algorithm for this problem of which Best-Stage decision is a special case. Additionally, we experimentally verify that the proposed \"best-time\" algorithm remains quite effective even as we relax the assumptions under which optimality can be proved. However, we find that when we add a \"learning-by-doing\" effect, in which the adoption costs decrease not as a function of time, but as a function of aggregate adoption, the \"best-time\" policy becomes suboptimal, and is significantly outperformed by our more general heuristic."
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 0,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "n": "1.",
               "text": "INTRODUCTION",
               "type": "introduction"
          },
          "paragraphs": [
               "One of the important algorithmic questions in marketing on social networks is how one should leverage network effects in promoting products so as to maximize long-term product uptake. Indeed, a similar question arises in political science, if framed in terms of maximizing uptake of beliefs and attitudes, leading to particular voting behavior. Crucial to such problems is a model of social influence on networks, and a number of such models have been proposed . Some of the prominent models give rise to global influence functions (capturing the expected number of adopters as a function of a subset of initially targeted individuals) that are submodular, that is, possess a natural diminishing returns property: targeting a greater number of individuals yields a lower marginal increase in the outcome. Submodularity is a powerful property for algorithm design; in particular, a simple greedy heuristic has a prov- able approximation guarantee, and is typically very close to optimal in experiments . Submodularity as typically defined is only helpful in a static setting, that is, when we choose individuals to target in a single shot. But an extension, termed adaptive submodularity, was proposed to make use of greedy heuristics in dynamic environments where individuals can be targeted over time . The diminishing returns feature naturally arises in many settings. However, early adoption trends can exhibit the opposite property of increasing returns to scale. For example, in the classic Bass model the early portion of the famous \"S-curve\" is convex, and if one uses logistic regression to model individual adoption choice-a natural model that was used in recent work by the authors that learned individual rooftop solar adoption behavior -the model is convex when probabilities are small. Arguably, early adoption settings are most significant for the development of effective product promotion strategies, since overall uptake is quite critical to the ultimate success of the product line. This is an especially acute concern in the \"green energy\" sector, where renewable energy technologies, such as rooftop solar, are only at a very early stage of overall adoption-indeed, adoption has been negligible except in a few states, such as California and Arizona.",
               "We consider the problem of influence maximization with network effects by aggregating a social network into an \"aggregate\" adoption function which takes as input the number of adopters at a given time t and outputs the number of adopters at time t + 1. Our main theoretical result is that when this function is convex and marketing budget can be reinvested at a fixed interest rate(equivalently, marketing or \"seeding\" costs decrease exponentially over time), influence over a finite time period can be maximized by using up the entire targeted marketing budget at a single time point (rather than splitting up the budget among multiple time periods); we refer to the resulting simple algorithm as the Best-Stage algorithm.",
               "We study the degree to which the theoretical optimality of the best-time algorithm holds in practice, using real data of rooftop solar adoption in San Diego county . As a baseline, we develop a more general heuristic algorithm that splits the budget equally over a set of consecutive months, with the size of this set and the starting month allowed to vary. We find that investing the whole budget in a single month is indeed (almost) optimal under a variety of simplified seeding cost functions (exponential, polynomial, or even linear with time), despite a number of gaps between the theory and the experimental setup -suggesting that the theoretical model is somewhat robust.",
               "In contrast, the best-time algorithm becomes suboptimal in an \"ideal\" model that was previously validated to confirm its predictive efficacy . Through careful analysis, we find that this is the result of \"learning-by-doing\" effects, where marketing costs (for example, when actual products are given away for free) depend on the total product uptake in the marketplace. assumptions on the nature of the diffusion function f :",
               "1. f is strictly convex (capturing increasing returns to scale), 2. f is strictly monotonically increasing, and"
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 1,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "n": "1.1",
               "text": "Related Work",
               "type": "relatedwork"
          },
          "paragraphs": [
               "We builds on the extensive literature of economics of diffusion with network effects . Largely, however, this literature is concerned with equilibria that arise, rather than algorithmic considerations. The latter are extensively studied in the literature on influence maximization on social networks. A number of models have been proposed to quantify influence diffusion on a network, perhaps the most prominent of which are linear threshold and independent cascade models . These and many related models give rise to a submodular \"expected adoption\" function. Many past approaches to \"one-shot\" influence maximization take advantage of this property in algorithmic development; in particular, a simple greedy algorithm is highly effective in practice, and offers a constant-factor approximation guarantee relative to a globally optimal solution to the associated combinatorial optimization problem .",
               "While one-shot influence maximization on social networks has received much attention, significantly less work addresses the problem of dynamic influence maximization, where individuals can be seeded in sequence. In an important effort in this vein, Golovin and Krause show that when dynamics (and uncertainty) satisfy the property of adaptive submodularity, a natural dynamic greedy heuristic is guaranteed to be only a constant factor worse than the optimal clairvoyant algorithm . Our problem is distinct from this effort in several ways. The first, and key, distinction is that we are concerned with increasing returns to scale. The second is that we capture network effects simply in terms of total numbers of all past adoptions (thus, the social network is completely connected for our purposes). The third is that we introduce another key element of tension into the problem by supposing that there is a fixed total budget allocated for seeding, and either this budget (or any portion of it) can be set aside to collect interest, or the costs of seeding fall over time (commonly, costs of products are expected to fall over time as a result of learning-by-doing, or supply-side network effects where better processes and technology reduce production costs with increasing product uptake and experience in the marketplace). To our knowledge, we are the first to consider the algorithmic problem of dynamic influence maximization in such a context.",
               "Assumptions and ensure that aggregate adoption increases over time (i.e., with every application of f ); note that they are not redundant. Assumption (1) of increasing returns to scale captures a common model of early adoption dynamics (the convex portion of the \"S-curve\" , or the logistic regression model of adoption over a low-probability region discussed in our experiments below). We suppose that at time 0 (that is, initial decision time), there is some initial number of adopters in the population, D 00. As stated, the problem poses no algorithmic tension: if one had a fixed budget for stimulating adoption, the entire budget should be used up immediately, as it would then take maximal advantage of network effects. We now introduce the principal source of such tension: an exponentially increasing budget. Specifically, suppose an agent is initially given a budget B 0 and any remaining budget will accrue by a factor of. For example, we can decide to invest residual budget at an interest rate. Alternatively, if we are giving away a product, its cost may decrease over time as technology matures, a process often referred to as \"learning-by-doing\" . Such learning-by-doing effects are paramount when we consider technology evolution in its early stages, which is arguably the setting where we would be most interested in promoting the product by giving it away to a subset of the individuals in a population. Notice that either saving some of the budget at a fixed interest rate, or costs of seeding decreasing at a constant rate, both give rise to exponentially increasing purchasing power of the budget over time. This gives rise to a non-trivial tension between seeding early so as to maximally leverage network effects and seeding later so as to maximize the number of individuals seeded (as well as subsequent network effects). The algorithmic question we pose is: how should we use a given budget B over a fixed time horizon T so as to maximize the total number of adopters at time T ? For simplicity, we assume unit cost for every seed; in other words, any budget B will create exactly B new adopters. This assumption will be relaxed in our experiments below.",
               "Given the deterministic T -stage diffusion model and the budget accrual process described above, as well as an initial budget B 0 and aggregate adoption D 0 , we can define a \"seeding\" policyas a sequence of fractions of the budget allocated in each stage, that is",
               "We consider a problem of adoption diffusion with network externalities. Our model of network externalities is simplified to consider only the aggregate adoption, which we denote by D. Specifically, we assume that the diffusion takes place in discrete time, and the aggregate adoption at time t, Dt, is a function only of adoption by the previous time step,",
               ". In other words, adoption dynamics are deterministic and first-order Markovian. We make three",
               "The dynamic influence maximization problem aspires to compute a policy* which leads to the maximum number of adopters based on the diffusion model f starting with initial adoption D 0 , an initial budget B 0 , and a budget growth rate. If we define the total number of adopters at time T as the utility of a policy, the problem can be written as",
               "To solve the dynamic maximization problem, it is convenient to view it as a T -stage decision process illustrated in ."
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 2,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "text": "Figure 1: T Stage Decision Process",
               "type": "relatedwork"
          },
          "paragraphs": [
               "At any stage t, we consider two types of actions for an agent: spending all of the remaining budget (= 1) and fraction (or none) of budget (0t < 1). Particularly, as long as one choosest = 1, the decision process is terminated and the utility can be obtained in terms of the number of final users. Otherwise, one should proceed until the budget is exhausted. Note that an agent will always spend whatever budget is left at t = T ? 1 (since there is no utility from keeping a fraction of it intact thereafter).",
               "In principle, one can solve the dynamic influence maximization problem using backward induction. For a T -stage decision problem, backward induction starts with considering optimal decisions at the last stage (i.e. t = T ? 1) for all possible realizations of D and B, then considers optimal choices at the second-to-last stage (i.e. t = T ? 2) using the optimal decisions in the final stage, and so on. The process proceeds until the very first decision node (i.e. t = 0) is reached, and finally an optimal policy can be returned. However, such an approach quickly becomes intractable when the evaluation of f is very time consuming (for example, as in the instance described below, f corresponds to an agent-based simulation of individual adoption decisions). For example, if we suppose that each simulation takes only 1 second, our population involves 10,000 individuals, the budget can seed only 20 individuals, and our time horizon is 20 stages (e.g., 20 months), dynamic programming would take over 1000 hours, or about 1.5 months. Our primary goal is to develop algorithmic approaches which are orders of magnitude faster. agent will have utility",
               "where notation f (m) () stands for applying f repeatedly for m stages. If some fraction 0t < 1 of the budget is used at stage t, there will be",
               "adopters and",
               "available budget in the next stage t+1. Let* be an optimal policy, and* t the fraction of budget allocated to seeding under* in stage t. Our next series of results characterize the properties that* (and fractions* t ) must have, by virtue of its optimality.",
               "Lemma 3.2. Suppose that at some stage t the optimal policy has* t = 0. Further, suppose that there is some t * > t with* * * t * = 1 andt = 0 for all t < t < t * . Thent?1 = 1 cannot be optimal.",
               "Proof. Let*"
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 3,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "n": "4.",
               "text": "EXPERIMENTS",
               "type": "experiment"
          },
          "paragraphs": [
               "To verify the efficacy of our proposed algorithm, we utilize an agent-based simulation introduced by which forecasts rooftop solar adoption in a representative zip code in San Diego county. This simulation has several features of relevance to us. First, it utilizes agent models which were learned from actual adoption, as well as auxiliary data, using a logistic regression model. Second, the model includes network effects: aggregate adoption is one of the variables that has a significant impact on individual adoption decisions. Third, the solar market is still very much in its developing stages, even in San Diego county, and consequently the relevant region of the logistic regression model is convex in the network effects variable. Fourth, while in the policy context of this model the budget remains fixed over the Tstage time horizon, costs decrease over time. In particular, in the previously validated version of the model , costs actually decrease as a function of \"learning-by-doing\", modeled as aggregate adoption in San Diego county (which in turn increases over time). Moreover, the costs decrease linearly, rather than exponentially. As a result, the cost in this simulation does not satisfy the assumptions that guarantee the optimality of the Best-Stage algorithm.",
               "An additional deviation from the idealized model we consider above is that the system cost enters the consideration in two ways: first, decreasing cost translates into an effectively increasing budget, and second, cost enters the adoption model directly as a part of economic considerations in rooftop solar adoption. A final important imperfection is that the budget need not be perfectly divisible by cost. In this section, we systematically investigate the extent to which these deviations from the \"ideal\" modeled above impact the optimality of the Best-Stage algorithm.",
               "Throughout, time is discretized in months, and we fix our time horizon at 24 months (that is, 24 stages). We use the Best-K-Stages as our benchmark, observing in each case below expected adoption at horizon T as a function of K. Thus, when we find K = 1 yields an optimal or a nearoptimal solution, we conclude that the deviation from model assumptions is not significant, while optimal K > 1 suggests the converse. We used the budget allocated by the California Solar Initiative (CSI) to the San Diego county incentive program as our baseline, and consider amplifications of this budget, denoted by \"BX\". For example, 50X budget means that 50 times the CSI budget was used in an experiment. Moreover, we explored the impact of the magnitude of the peer effect variable in the model by considering as a baseline the network effect coefficient produced by learning the adoption model from data, as well as its amplifications, denoted by \"PX\"; for example \"2X\" network effect means that we doubled the network effect coefficient. andin this model (see ). The new cost model was then \"injected\" into the otherwise unmodified agent-based model.  "
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 4,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "n": "4.1",
               "text": "Exponential Cost",
               "type": "experiment"
          },
          "paragraphs": [
               "Our hypothesis is that the primary consideration is the nature of the cost model, with the remaining \"imperfections\" introduced by the complex considerations of the agent-based model in question being significantly less important. To investigate, we replace the cost model in the original model with a much simpler cost function which decreases exponentially with time t (equivalently, the budget is exponentially increasing over time): C(t) = C0et , or, equivalently, log(C) = log(C0) +t. We used the rooftop solar cost data for San Diego county to estimate the parameters log(C0)",
               "The maximum expected adoption of seeding policies over different lengths (values of K in Best-K-Stages) is illustrated in . The results suggest that seeding in a single stage tends to be a better policy than splitting the budget over multiple stages. Moreover, for length-1 policies we find that in this case seeding at very end (i.e., in stage T ? 1) is optimal, as shown in , where the horizontal axis is the seeding month. This is likely because benefit of the exponential cost decay in this variation of the model exceeds the gains from seeding early due to network effects. As the importance of network effects increases, we expect that seeding earlier would become more beneficial. To investigate, we manually varied the coefficient of network effects in the adoption model, multiplying it by a factor of 1.75 and 2, and comparing the outcomes. Seeding in a single stage is still quite effective the jagged nature of the plots is likely due to the indivisibilities discussed above), but the optimal month to seed shifts earlier, as shown in    "
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 5,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "paragraphs": [
               "As shown in the previous section, the Best-Stage algorithm performs impressively despite a number of imperfections in the agent-based model of aggregate rooftop solar adoption. Next, we test its effectiveness in the context of an \"ideal\" model that was previously thoroughly validated in forecasting solar adoption. Significantly, the cost function used in this model includes a number of relevant parameters (such as system size), and in place of explicit dependence on time, it is a decreasing function of the overall uptake of solar systems in San Diego county (see ). Finally, the cost function is modeled as linear in its parameters (with a fixed lower bound at zero).  The exponential cost function, or exponentially increasing budget, seems quite dramatic. What if we slow this growth in budget buying power to be polynomial?",
               "We formulate the following simple model of polynomial cost: C(t) = C0t, where t is time variable, and C0 andare parameters. This function is equivalent to log(C(t)) = log(C0) +log(t), which we can fit using linear regression. The resulting coefficients are given in . The results in are surprising: the Best-Stage algorithm performs significantly worse than policies that split budget over a relatively long contiguous series of months (K > 5). further reveals that we optimally wish to push the initial month of this contiguous sequence rather late in the period; in other words, network effects are relatively weak. The key question is: what goes wrong? The observations in the previous section strongly suggest that it is the form of the cost function that is at the heart of the issue. We therefore proceed to carefully investigate what, precisely, about the nature of the cost function in this model is the cause of this qualitative change relative to our stylized model in Section 2. Specifically, we start with a simplified model of solar adoption that conforms to the assumptions of our main result (i.e., using only time as a variable), and incrementally relax it to bring it closer to the cost function actually used in the original simulation environment. In particular, we begin with a polynomial cost function, proceed to investigate a linear cost model (in time only), and finally consider a linear cost function that depends on aggregate product uptake (learning-by-doing) rather than time.",
               "Parameter Coefficient log(C0) 10.70 log(t) -0.098",
               "Figures 6a, 6b, and 7a suggest that Best-Stage is still a very good policy here, albeit the jagged nature of the plots (likely due to indivisibilities) makes this observation somewhat equivocal when network effects are very weak. However, as the magnitude of network effects increases, the advantage of Best-Stage over alternatives becomes more pronounced. On balance, it seems clear that the polynomial vs. exponential nature of the cost function does not give rise to a qualitative difference in the effectiveness of our underlying model."
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "head": {
               "type": "experiment"
          },
          "paragraphNo": 6,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "n": "4.4",
               "text": "Linear Cost",
               "type": "experiment"
          },
          "paragraphs": [
               "Given that the polynomial cost model did not appear to bring about a substantial difference, we proceed to relax to a linear cost model, inching even closer to the \"ideal\" model used in the simulation. Our linear cost model has linear dependence on time, implying a slower decay rate than   the polynomial cost function: C(t) = a + bt. As before, parameters a and b are estimated using solar system cost data for San Diego county, with the results given in ."
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 7,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "n": "4.3",
               "text": "Polynomial Cost",
               "type": "experiment"
          },
          "paragraphs": [
               "the magnitude of network effects increases and 9b). The key distinction from the idealized model is that learning-by-doing makes the temporal benefit of waiting endogenous: now seeding earlier will directly reduce future seeding costs and, consequently, the effectiveness of residual budget. As a result, we observe what amounts to an \"interior\" optimum in budget allocation, with some of the budget used in seeding in order to make residual budget more valuable later. As before, we ran the experiments by \"plugging in\" this cost model into the simulation environment (retraining the individual adoption propensities). Our experiments show that seeding in a single month is, again, more effective than seeding in multiple consecutive stages (See and 8b), even as we vary the importance of network effects."
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 8,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     },
     {
          "head": {
               "n": "4.5",
               "text": "Linear Cost with Learning-by-Doing",
               "type": "experiment"
          },
          "paragraphs": [
               "Both \"ideal\" cost model and linear cost model are linear in their features. The key difference is that the ideal cost function depends on cumulative adoption, whereas the latter only depends on time. We now move yet closer to the ideal model, replacing the linear dependence on time with linear dependence on aggregate solar system uptake in San Diego county: C(t) = c + dy(t), where y(t) is number of solar adoption up to time t. The parameters c and d are estimated via linear regression, and are given in .",
               "Remarkably, the results now echo our observations in the \"ideal\" model ): Best-Stage is decidedly suboptimal, and policies that split the budget among K = 5 or more consecutive stages perform significantly better. Additionally, we can see that the \"optimal\" number of stages to seed (at least in our heuristic algorithm) increases as We formulate a novel dynamic influence maximization problem under increasing returns to scale and prove that the optimal policy must use up budget at a single stage, giving rise to a simple Best-Stage search algorithm. In addition, we propose a heuristic algorithm, Best-K-Stages, that includes Best-Stage as a special case. We experimentally verify that the proposed Best-Stage algorithm remains quite effective even as we relax the assumptions to different time-involved cost dynamics, i.e., polynomial and linear cost. On the other hand, we find that when we replace the time dependency of the cost function by cumulative adoption (learning-bydoing), Best-K-Stages significantly outperforms Best-Stage.",
               "Looking forward, there are several possible directions we would like to pursue in the future. First, it is clear that there must exist even better policies remaining unexplored for the \"ideal\" cost model with learning-by-doing. Our heuristic search algorithm only covers a special subset of policies. Design of more efficient algorithms to find optimal solutions in such a realistic setting can be a meaningful extension to our current work. Second, the dynamic influence maximization problem proposed in this paper assumes seeding does not discriminate among individuals. This is a very strong assumption, but enables us to make significant progress. Seeding in a social network with heterogeneous individuals has been shown to be N P -hard even for \"one-shot\" decisions and a simple submodular diffusion model . A relaxation to individual heterogeneity is sure to create further algorithmic challenges."
          ],
          "paper_id": "21edbe90-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 9,
          "fromPaper": "Dynamic Influence Maximization Under Increasing Returns to Scale"
     }
]