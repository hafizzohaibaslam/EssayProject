[
     {
          "head": {
               "text": "Problem Definiton",
               "type": "introduction"
          },
          "paragraphs": [
               "We are given an unweighted, undirected graph G = V,E representing the topological structure of a social network in which each edge e = u,vE represents an interaction between u and v that took place at a particular time t(e). For two times t and t> t, let G[t,t] denote the subgraph of G consisting of all edges with a timestamp between t and t. Let t 0 , t0 , t 1 , and t1 be four times, where t 0 < t0t 1 < tTo generate this list, we use heuristic algorithms which assign a similarity matrix S whose real entry s xy is the score between x and y. This score can http://be.amazd.com/link?prediction/ 1/9",
               "be viewed as a measure of similarity between nodes x and y. For each pair Also, for a node x,(x) represents the set of neighbors of x. degree(x) is the of nodes, x, yV, generally s xy = s yx . All the nonexistent links are sorted size of the(x).",
               "in decreasing order according to their scores, and the links at the top are most likely to exist .",
               "Since we can't actually predict the future, to test the algorithm's accuracy, a fraction of the observed links E (lets say 90% of the whole) of some known interaction dataset is randomly singled out as a training set, ET, the remaining links (10% of the whole) are used as the probe set, EP,",
               "to be predicted and no information in this set is allowed to be used for prediction. Clearly, E=ETEP and ETEP=?. The prediction quality is evaluated by a standard metric, the area under the receiver operating characteristic curve (AUC). This metric can be interpreted as the probability that randomly chosen missing link (a link in EP) is given a higher score than a randomly chosen nonexistent link (a link in U but not in E, where U denotes the universal set) . Among n independent comparisons, if there are noccurrences of missing links having a higher score and noccurrences of missing links and nonexistent link having the same score, we define the accuracy as:",
               "If all the scores are generated from an independent and identical distribution, the accuracy should be about 0.5. Therefore, the degree to which the accuracy exceeds 0.5 indicates how much better the algorithm performs than pure chance.",
               "Given a snapshot of a social network at time t (or network evolution between t 1 and t 2 ), we seek to accurately predict the edges that will be added to the network during the interval from time t (or t 2 ) to a given future time t'."
          ],
          "paper_id": "22a61210-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 0
     },
     {
          "head": {
               "text": "Helpful Shortcuts",
               "type": "introduction"
          },
          "paragraphs": [
               "Social networks are defined by structures whose nodes represent people or other entities embedded in a social context, and whose edges represent interaction, collaboration, or influence between entities. As such, these networks have several well?known characteristics, such as the power law degree distribution , the small world phenomenon , and the community structure (clustering effect) .",
               "The small world effect refers to the phenomenon that the average distance in the network is very small compared to the size of the network. The clustering effect refers to the phenomenon that there is a circle of http://be.amazd.com/link?prediction/ 2/9 friends, acquaintances, rings, and other small groups in social network.",
               "Each member of the small group knows each other. This phenomenon can also be described by the concept of triadic closure: that there is many fully connected subgraphs in social network."
          ],
          "paper_id": "22a61210-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 1
     },
     {
          "head": {
               "text": "Why it's a hard problem",
               "type": "introduction"
          },
          "paragraphs": [
               "For a social network G(V,E), there are VV -E possible edges to choose",
               "In the DBLP dataset, in the year 2000, the ratio of actual and possible link from, if we were picking a random edge to predict for our existing social is as low as  "
          ],
          "paper_id": "22a61210-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 2
     },
     {
          "head": {
               "text": "Similarity Metrics",
               "type": "experiment"
          },
          "paragraphs": [
               "Graph Distance Perhaps the most direct metric for quantifying how close two nodes are is the graph distance. It is defined as the negative of the shortest?path distance from x to y.",
               "Note that it is inefficient to apply Dijkstra's algorithm to compute shortest path distance from x to y when G has millions of nodes. Instead, we exploit the small?world property of the social network and apply expanded ring search to compute the shortest path distance from x to y.",
               "Specifically, we initialize S = {x} and D = {y}. In each step we either expand",
               "The measure follows the notion that social networks are small worlds, in set S to include its members' neighbors (i.e., S = S{v|u, vEuwhich individuals are related through short chains. The use of negated (instead of original) shortest?path distance ensures that the proximity measure GD(x,y) increases as x and y get closer.",
               "Common Neighbors The common?neighbors predictor captures the notion that two strangers who have a common friend may be introduced by that friend. This introduction has the effect of \"closing a triangle\" in the graph and feels like a common mechanism in real life. Newman has computed this quantity in the context of collaboration networks, verifying a positive correlation between the number of common neighbors of x and y at time t, and the probability that x and y will collaborate at some time after t. http://be.amazd.com/link?prediction/ 5/9",
               "Hitting Time A random walk starts at a node x and iteratively moves to a neighbor of x chosen uniformly at random. The hitting time H x,y from x to y is the expected number of steps required for a random walk starting at x to reach y.",
               "One difficulty with hitting time as a measure of proximity is that H x,y is quite small whenever y is a node with a large stationary probabilityy , regardless of the identity of x (That is, for a node y at which the random walk spends a considerable amount of time in the limit, the random walk will soon arrive at y, almost no matter where it starts. Thus the predictions made based upon H x,y tend to include only a few distinct nodes y) To counter?balance this phenomenon, we also consider normalized versions of the hitting and commute times, by defining score(x, y) = ?H x,yy",
               "Rooted PageRank Another difficulty with using the measures based on hitting time and commute time is their sensitive dependence to parts of the graph far away from x and y, even when x and y are connected by very short paths. A way of counteracting this difficulty is to allow the random walk from x to y to periodically \"reset,\" returning to x with a fixed probabilityat each step? in this way, distant parts of the graph will almost never be explored.",
               "Random resets form the basis of the PageRank measure for web pages, and we can adapt it for link prediction. Similar approaches have been considered for personalized PageRank, in which one wishes to rank web pages based both on overall \"importance\" (the core of PageRank) and relevance to a particular topic or individual, by biasing the random resets towards topically relevant or bookmarked pages",
               "Other metrics Another metric that can be used is the Friends?measure. "
          ],
          "paper_id": "22a61210-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 3
     },
     {
          "head": {
               "text": "Results on datasets",
               "type": "experiment"
          },
          "paragraphs": [
               "Generally, the link prediction algorithms based on network topologies are designed according to the measures of the structural similarity of nodes,",
               "http://be.amazd.com/link?prediction/ 6/9 which can be classified as local and global methods. Overall they can be classified as such:",
               "Network evolution model The same community metric calculates the intuition that people who belong to the same community will probably be linked.",
               "Or considering the time characteristics of the network, social network graph can be divided into different graph sequences in accordance with a certain time step. The moving average is the average of an heuristics value for an edge in a certain period time . By looking at this average over many generations of evolution, one can make very accurate link predictions.",
               "http://be.amazd.com/link?prediction/ 8/9",
               "Moreover, link prediction problem is studied in the supervised learning framework by treating it as an instance of binary classification These methods use the topological and semantic measures defined between nodes as features for learning classifiers. Given a snapshot of the social network at time t for training, they consider all the links present at time t as positive examples and consider a large sample of absent links (pair of nodes which are not connected) at time t as negative examples. The learned classifiers performed consistently across all the datasets unlike heuristic methods which were inconsistent, although the accuracy of prediction is still very low .",
               "There are several reasons for this low prediction accuracy. One of the main reasons is the huge class skew associated with link prediction. In Actors in the same tightly?knit group often exhibit structural equivalence, large networks, it's not uncommon for the prior link probability on the i.e., they have the same connections to all other nodes. Using the original order of 10^?4 or less, which makes the prediction problem very hard, network (a), and a structural equivalence assumption, one can construct a resulting in poor performance. In addition, as networks evolve over time, network with new predicted links (b). the negative links grow quadratically whereas positive links grow only linearly with new nodes.",
               "This page was created as a class project for COMP 260: Advanced Algorithms"
          ],
          "paper_id": "22a61210-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 4
     }
]