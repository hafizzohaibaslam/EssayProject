[
     {
          "head": {
               "n": "0",
               "text": "abstract",
               "type": "abstract"
          },
          "paragraphs": [
               "Ant colonies, and more generally social insect societies, are distributed systems that, in spite of the simplicity of their individuals, present a highly structured social organization. As a result of this organization, ant colonies can accomplish complex tasks that in some cases far exceed the individual capacities of a single ant. The study of ant colonies behavior and of their self-organizing capacities is interesting for computer scientists because it provides models of distributed organization which are useful to solve difficult optimization and distributed control problems. In this paper we overview some models derived from the observation of real ants, emphasizing the role played by stigmergy as distributed communication paradigm, and we show how these models have inspired a number of novel algorithms for the solution of distributed optimization and distributed control problems."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 0,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "1.",
               "text": "Introduction",
               "type": "introduction"
          },
          "paragraphs": [
               "Ant colonies have always fascinated human beings. Books on ants, ranging from pure literature to detailed scientific accounts of all the aspects of their life , have often met extraordinary public success. What particularly strikes the occasional observer as well as the scientist is the high degree of societal organization that these insects can achieve in spite of very limited individual capabilities. Ants appeared on the earth some 100 millions of years ago, and their current population is estimated to be around 10 16 individuals . An approximate computation tells us that their total weight is the same order of magnitude as the total weight of human beings; like human beings, they can be found virtually everywhere on the earth. Ants are undoubtedly one of the most successful species on the earth today, and they have been so for the last 100 million years. It is therefore not surprising that computer scientists have taken inspiration from studies of the behavior of ant colonies, and more generally of social insects, to design algorithms for the control of multi-agent systems.",
               "A particularly interesting body of work is the one that focuses on the concept of stigmergy, a particular form of indirect communication used by social insects to coordinate their activities. By exploiting the stigmergic approach to coordination, researchers have been able to design a number of successful algorithms in such diverse application fields as combinatorial optimization, routing in communication networks, task allocation in a multi-robot system, exploratory data analysis, graph drawing and partitioning, and so on .",
               "The term stigmergy was introduced by to describe a form of indirect communication mediated by modifications of the environment that he observed in two species of termites: Bellicositermes Natalensis and Cubitermes. Grass's original definition of stigmergy was:",
               "\"Stimulation of workers 1 by the performance they have achieved\". Although Grassfirst introduced the term stigmergy to explain the behavior of termites societies, the same term has later been used to indicate indirect communication mediated by modifications of the environment that can be observed also in other social insects .",
               "Nest building in termites is the typical example of stigmergy, and is also the original example used by Grassto introduce the concept. Termite workers use soil pellets, which they impregnate with pheromone (i.e., a diffusing chemical substance) to build pillars. Two successive phases take place during nest reconstruction . First, a non-coordinated phase occurs which is characterized by a random deposition of pellets. This phase lasts until one of the deposits reaches a critical size . Then, a coordination phase starts if the group of builders is sufficiently large and pillars emerge. The existence of an initial deposit of soil pellets stimulates workers to accumulate more material through a positive feedback mechanism, since the accumulation of material reinforces the attractivity of deposits through the diffusing pheromone emitted by the pellets . This autocatalytic snowball effect leads to the coordinated phase. If the density of builders is too small, the pheromone disappears between two successive passages by the workers, and the amplification mechanism cannot work, which leads to a non-coordinated behavior. The system undergoes a bifurcation at this critical density: no pillar emerges below it, but pillars can emerge above it. This example therefore illustrates positive feedback (the snowball effect), negative feedback (pheromone decay), the amplification of fluctuations (pillars could emerge anywhere), multiple interactions (through the environment), the emergence of structure (i.e., pillars) out of an initially homogenous medium (i.e., a random spatial distribution of soil pellets), multistability (again, pillars 1. An example of stigmergic process as it appears in the construction of pillars in termites. Assume that the architecture reaches state S 0 , which triggers response R 0 from worker I . S 0 is modified by the action of I (e.g., I may drop a soil pellet), and transformed into a new stimulating configuration S 1 that may in turn trigger a new response R 1 from I or any other worker I n and so forth. The successive responses R 1 , R 2 , . . . , R n may be produced by any worker carrying a soil pellet. Each worker creates new stimuli in response to existing stimulating configurations. These new stimuli then act on the same termite or on any other worker in the colony. Such a process, where the only relevant interactions taking place among the agents are indirect, through the environment which is modified by the other agents, is also called sematectonic communication . . Four simulation steps showing the temporal evolution of the structure built by termites in a 2D system. This simulation shows the evolution of the density of building material (on the z-axis) used by termites to build their nest obtained from Deneubourg's model . The simulation begins with a random distribution of building material in space (step 1) and the regularity of the inter-pillar spacing emerges progressively over time (steps 2, 3 and 4). (From ; reprinted by permission of Birkh?vser Verlag.) may emerge anywhere) and bifurcation which make up the signatures of self-organized phenomena. From the experimental observations, Deneubourg designed a chemotaxis-based reaction-diffusion model that exhibits the desired properties for appropriate parameter values. shows the two-dimensional spatial distribution of pillars obtained with his model. In this model, coordination emerges out of indirect (stigmergic) interactions among workers.",
               "In this paper an ant algorithm is informally defined as a multi-agent system inspired by the observation of some real ant colony behavior exploiting stigmergy. In ant algorithms the agents are called artificial ants, or often simply ants, and coordination among ants is achieved by exploiting the stigmergic communication mechanism.",
               "The implementation of ant algorithms is made possible by the use of so-called stigmergic variables, i.e., variables that contain the information used by artificial ants to indirectly communicate. In some cases, as discussed, e.g., in Section 2, the stigmergic variable is a specifically defined variable used by ants to adaptively change the way they build solutions to the considered problem. In other cases, as discussed in Sections 3 and 4, the stigmergic variable is one of the problem variables: in this case a change in its value determines not only a change in the way a solution to the problem is built, but also a direct change in the solution of the problem itself.",
               "In the rest of this article we provide a number of examples of ant algorithms and for each example we highlight the role played by stigmergy. Each section deals with a particular behavior observed in ant colonies: foraging (Section 2), division of labor (Section 3), and clustering (Section 4). The first part of each section provides a brief description of the observed phenomenon followed by a description of models developed by ethologists to understand the phenomenon; engineering-oriented applications, that make use of the emergent behavior of ant colonies, are then presented. It is worth noting that not all kinds of ant algorithms are equally advanced: some of them are among the best available approaches for selected problems, while others are just proofs of concept and further work needs to be done to fully evaluate their potentialities. Therefore, the various sections of this review article may emphasize different aspects, the biology or the engineering side. Sections that emphasize applications are useful because they show very clearly the way our understanding of how ants collectively solve problems can be applied to design algorithms and distributed problem-solving devices; those emphasizing the biology are useful because, we believe, they provide new ideas to design new types of algorithms and distributed artificial devices. "
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 1,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "2.1.",
               "text": "Foraging in ants",
               "type": "introduction"
          },
          "paragraphs": [
               "A lot of ant species have a trail-laying/trailfollowing behavior when foraging : individual ants deposit pheromone while walking and foragers follow pheromone trails with some probability. Deneubourg et al. have shown with an ingenious experiment, run with ants of the species Linepithema humile, that this behavior can explain how ants find the shortest path between their nest and a food source. The experimental setup is the following.",
               "A food source is connected to an ant nest by a bridge with two equally long branches . When the experiment starts the ants select randomly, with equal probability, one of the branches. Because of statistical fluctuations one of the two branches is chosen by a few more ants than the other and therefore is marked by a slightly higher amount of pheromone. The greater amount of pheromone on this branch stimulates more ants to choose it, and so on . This autocatalytic process leads very soon the ant colony to converge towards the use of only one of the two branches.",
               "The experiment can also be run using a bridge with two branches of different length. In this case, the first ants coming back to the nest are those that took the shortest path twice (to go from the nest to the source and to return to the nest), so that more pheromone is present on the short branch than on the long branch immediately after these ants have returned, stimulating nestmates to choose the short branch . This has been called differential length effect and explains how ants in the long run end up choosing the shortest of the two paths without using any global knowledge about their environment. Differential length effect and pheromone based autocatalysis are at the earth of some successful ant algorithms for discrete optimization, in which an artificial pheromone plays the role of stig- Distribution of the percentage of ants that selected the shorter branch over n experiments. The longer branch is r times longer than the short branch. The second graph (n = 18, r = 2) corresponds to an experiment in which the short branch is presented to the colony 30 min after the long branch: the short branch is not selected, and the colony remains trapped on the long branch. Modified from Goss et al. . mergic variable, as explained in the following section. It is also interesting to note that in some ant species the amount of pheromone deposited is proportional to the quality of the food source found: paths that lead to better food sources receive a higher amount of pheromone. Similarly, in the ant algorithms presented in this section artificial ants deposit a quantity of pheromone proportional to the quality of the solution they found."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 2,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "2.2.",
               "text": "Ant System and the Traveling Salesman Problem",
               "type": "introduction"
          },
          "paragraphs": [
               "Ant System (AS) was the first algorithm inspired by the trail-following behavior of ants to be applied to a discrete optimization problem. The problem chosen for the first experiments was the Traveling Salesman Problem (TSP). In the TSP, one has to find a closed tour of minimal length connecting n given cities. Each city must be visited once and only once. Let d ij be the distance between cities c i and c j . The problem can either be defined in Euclidean space (in which case d ij is simply the Euclidean distance between cities i and j ), or can be more generally defined on a graph G = (V , E), where the cities are the vertices (V ) and the connections between the cities are the edges of the graph (E). Note that the graph need not be fully connected and the distance matrix need not be symmetric: if it is asymmetric the corresponding problem is called the asymmetric TSP.",
               "In AS the ants build solutions in parallel by visiting sequentially the cities of the graph. On each edge (i, j ) of the TSP graph an artificial pheromone trailij (t) is maintained. The valuesij (t) are used by ants to direct the way they build tours. They are updated by means of a reinforcement procedure: once an ant has completed a tour it updates the edges it has crossed by adding a quantity of pheromone proportional to the goodness of the tour.",
               "More formally, at iteration 2 t, after completing its tour T k (t), the kth ant lays a quantity of pheromonek ij (t) on each edge (i, j ) belonging to T k (t);k ij (t) is a function of the length L k of tour T k (t):",
               "where Q is an adjustable parameter. Ants build solutions using a probabilistic transition rule. The probability p k ij (t) with which an ant k in city i at iteration t chooses the next city j to move to is a function of the following:",
               "? Whether or not city j has already been visited. For each ant, a list is maintained that contains all the cities that the ant has already visited in order to prevent cities from being visited more than once; the list grows within one tour until it is full, and is then emptied at the end of the iteration; we call J k (i) the set of cities that remain to be visited by ant k when ant k is in city i.",
               "? An heuristic measureij of the desirability of adding edge (i, j ) to the solution under construction. In the TSP a reasonable heuristic isij = 1/d ij , i.e., the inverse of the distance between cities i and j .",
               "? The amountij (t) of artificial pheromone on the edge connecting i and j . Formally p k ij (t) is given by ple starting points since ants are initially randomly distributed on the cities). If on the contrary= 0, only pheromone amplification is at work: this method will lead the system to a stagnation situation, i.e., to a situation in which all the ants generate a same, sub-optimal tour . The trade-off between edge length and trail intensity therefore appears to be necessary. Finally, AS could not perform well without pheromone evaporation. In fact, because the initial exploration of the search space is mostly random, the values of the pheromone trails in the initial phases are not very informative and it is therefore necessary that the system slowly forgets these initial values to allow the ants to move towards better solutions. Pheromone decay is implemented by introducing a coefficient of evaporation, 0 <1, such that",
               "whereandare two adjustable parameters that control the relative influences of pheromone trailij (t) and heuristic desirabilityij . If= 0, the closest cities are more likely to be selected: this corresponds to a classical stochastic greedy algorithm (with multiwhereij (t) = m k=1k ij (t) and m is the number of ants.",
               "The initial amount of pheromone on edges is assumed to be a small positive constant c (i.e., there is an homogeneous distribution of pheromone at t = 0). The total number m of ants (assumed constant over time) is an important parameter. Too few ants will not produce the expected synergistic effects of cooperation 3 because of the (otherwise necessary) process of pheromone evaporation. On the contrary, too many ants result in a less efficient computational system: the quality of the results produced after a given number of iterations does not improve significantly, but, due to the higher number of ants, it takes longer to perform an algorithm iteration. Dorigo suggests that m = n, i.e., as many ants as there are cities in the problem, provides a good trade-off.",
               "Ant System has been tested on several relatively small problems. The experimentally optimized value of the parameters has been set to= 1,= 5,= 0.5 and Q = 100. Although the results obtained were not state-of-the-art on the TSP , AS compared well with other general purpose metaheuristic methods, like simulated annealing, evolutionary computation, and tabu search. But, most important, AS gave rise to a whole set of successful applications and extensions which have recently been unified in a novel metaheuristic called Ant Colony Optimization (ACO)."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 3,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "2.3.",
               "text": "The ACO metaheuristic",
               "type": "introduction"
          },
          "paragraphs": [
               "The ACO metaheuristic is a novel metaheuristic obtained a posteriori after a careful analysis of the characteristics of a number of ant algorithms inspired by the foraging behavior of ants (most of these algorithms were strongly inspired by AS). ACO algorithms, i.e., heuristic algorithms obtained as instances of the ACO metaheuristic, can be used to find feasible minimum cost paths over a graph G = (C, L, W ), where feasibility is defined with respect to a set of constraints. The graph G = (C, L, W ) and the constraints are defined as follows: C = {c 1 , c 2 , . . . , c n } is a finite set of problem components, L = {l c i c j |c i , c jC} a finite set of possible connections among the elements of C, W a set of weights associated either to the components C or to the connections L or to both, and L,) is a finite set of constraints assigned over the elements of C and L (indicates that the set of constraints can change over time). For example, in the TSP defined in Section 2.2, C is the set of cities, L the set of edges connecting cities, W the length of the edges in L, and the constraints impose that in any feasible solution each city appears once and only once. A feasible path over G is called a solutionand a minimum cost path is an optimal solution and is indicated by* ; f () is the cost of solution, and f (* ) the cost of the optimal solution. In the TSP a solutionis an Hamiltonian circuit and* the shortest feasible Hamiltonian circuit.",
               "In ACO algorithms a colony of ants concurrently, asynchronously and incrementally build solutions of the problem defined by G and . Each ant k starts with a partial solutionk (1) consisting of one element (one of the components in C) and adds components tok (h) till a complete feasible solutionis built, where h is the step counter. Components to be added tok (h) are stochastically chosen in an appropriately defined neighborhood of the last component added tok (h). The ants stochastic choice is made by applying a stochastic local decision policy that makes use of local information available at the visited vertices/components. Once an ant has built a solution, or while the solution is being built, the ant evaluates the (partial) solution and adds pheromone, i.e., information about the quality of the (partial) solution, on the components and/or the connections it used. This pheromone information will direct the search of the ants in the following iterations.",
               "Besides ants' activity, an ACO algorithm includes a pheromone evaporation() procedure and an optional daemon actions() procedure. Pheromone evaporation, as it was the case in AS, is the process by which the pheromone trail automatically decreases over time. \"Daemon\" actions can be used to implement centralized actions which cannot be performed by single ants. Examples are the activation of a local optimization procedure, or the collection of global information that can be used to decide whether it is useful or not to deposit additional pheromone to bias the search process from a non-local perspective. As a practical example, the daemon can observe the path found by each ant in the colony and choose to deposit extra pheromone on the edges used by the ant that made the shortest path. In most applications to combinatorial optimization problems the ants activity(), pheromone evaporation() and daemon actions() procedures (see ) are scheduled sequentially. Nevertheless, the schedule activities construct of the ACO metaheuristic ) leaves the decision on how these three procedures must be synchronized to the user, that is left free to match synchronization policies to the considered problems (e.g., in the applications to routing in telecommunication networks the execution of the three procedures is often interleaved).",
               "The ACO metaheuristic, which has been introduced in where the interested reader can find a more detailed formal definition, has been successfully applied to many discrete optimization problems, as listed in . Among the most studied problems there are the traveling salesman, the quadratic assignment and routing in telecommunication networks. When applied to these problems ACO algorithms result to be competitive with the best available heuristic approaches.",
               "In particular we observe the following:",
               "? Results obtained by the application of ACO algorithms to the TSP are very encouraging (ACO algorithms for the TSP are overviewed in ): they are often better than those obtained using other general purpose heuristics like evolutionary computation or simulated annealing. Also, when adding to ACO algorithms local search procedures based on 3-opt , the quality of the results obtained is close to that obtainable by other state-of-the-art methods.",
               "? ACO algorithms are currently one of the best performing heuristics available for the particularly important class of quadratic assignment problems which model real world problems .",
               "? AntNet , an ACO algorithm for routing in packet switched networks, outperformed a number of state-of-the-art routing algorithms for a set of benchmark problems. AntNet-FA, an extension of AntNet for connection oriented network routing problems, also shows competitive performance .",
               "? HAS-SOP, an ACO algorithm coupled to a local search routine, has improved many of the best known results on a wide set of benchmark instances of the sequential ordering problem (SOP) , i.e., the problem of finding the shortest Hamiltonian path on a graph which satisfies a set of precedence constraints on the order in which cities are visited. ACO algorithms have also been applied to a number of other discrete optimization problems like the shortest common supersequence problem, the vehicle routing problem, the multiple knapsack, single machine total tardiness, and others (see ), with very promising results. among individuals in the frequency and sequence of task performance: one may therefore speak of behavioral castes, to describe groups of individuals that perform the same set of tasks in a given period.",
               "One of the most striking aspects of division of labor is plasticity, a property achieved through the workers' behavioral flexibility: the ratios of workers performing the different tasks that maintain the colony's viability and reproductive success can vary (i.e., workers switch tasks) in response to internal perturbations or external challenges. An important question is to understand how this flexibility is implemented at the level of individual workers, which do not possess any global representation of the colony's needs."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 4,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "3.1.",
               "text": "Division of labor in ant colonies",
               "type": "introduction"
          },
          "paragraphs": [
               "Division of labor is an important and widespread feature of life in ant colonies, and in social insects in general (for a review, see, e.g., ). Social insects are all characterized by one fundamental type of division of labor, reproductive division of labor, a main ingredient in the definition of eusociality. Beyond this primary form of division of labor between reproductive and worker castes, there most often exists a further division of labor among workers, who tend to perform specific tasks for some amount of time, rather than to be generalists who perform various tasks all the time. Workers are divided into age or morphological subcastes. Age subcastes correspond to individuals of the same age that tend to perform identical tasks: this phenomenon is called temporal polyethism. In some species, workers can have different morphologies: workers that belong to different morphological castes tend to perform different tasks. But even within an age or morphological caste, there may be differences Bonabeau et al. have developed a simple model for task allocation in ants based on the notion of response threshold : individuals start to become engaged in task performance when the level of the task-associated stimuli, which plays the role of stigmergic variable, exceeds their threshold. Differences in response thresholds may either reflect actual differences in behavioral responses, or differences in the way task-related stimuli are perceived. When specialized individuals performing a given task are withdrawn (they have low response thresholds with respect to stimuli related to this task), the associated task demand increases and so does the intensity of the stimulus, until it eventually reaches the higher characteristic response thresholds of the remaining individuals that are not initially specialized into that task; the increase of stimulus intensity beyond threshold has the effect of stimulating these individuals into performing the task. This is exactly what was observed by Wilson in experiments where he artificially reduced the minor/major (minor and major are two ant castes) ratio to below 1 and observed a change in the rate of activity within 1 hour of the ratio change: for small ratios, majors engage in tasks usually performed by minors and efficiently replace the missing minors (the results of one of these experiments are shown in ).",
               "What is a response threshold? Let s be the intensity of a stimulus associated with a particular task: s can be a number of encounters, a chemical concentration, or any quantitative cue sensed by individuals. A response threshold, expressed in units of stimulus intensity, An inactive individual starts performing the task with a probability P per unit time: The probability that an individual will perform a task depends on s, the magnitude of the task-associated stimulus, that affects the probability of being exposed to it, and oni , the probability of responding to task-related stimuli .",
               "An active individual gives up task performance and becomes inactive with probability p per time unit (that we take identical for the two castes, i.e., p 1 = p 2 = p):",
               "is an internal variable that determines the tendency of an individual to respond to the stimulus s and perform the associated task. More precisely,is such that the probability of response is low for sand high for s. One family of response functions T(s) that can be parametrized with thresholds that satisfy this requirement is given by 1/p is the average time spent by an individual in task performance before giving up the task. It is assumed that p is fixed, and independent of the stimulus. Individuals give-up task performance after 1/p, but may become engaged again immediately if the stimulus is still large. Variations in stimulus intensity are due to task performance, which reduces stimulus intensity, and to the autonomous increase of demand, i.e., irrespective of whether or not the task is performed. The resulting equation for the evolution of stimulus intensity s is therefore (in discrete time)",
               "where n > 1 determines the steepness of the threshold. In the rest of the section, we use n = 2, but similar results can be obtained with other values of n > 1. The meaning ofis clear: for s, the probability of engaging in task performance is close to 0, and for s, this probability is close to 1; at s =, this probability is exactly 1/2. Therefore, individuals with a lower value ofare likely to respond to a lower level of stimulus. Assume that there are two castes and that only one task needs to be performed. This task is associated with a stimulus or demand, the level of which increases if it is not satisfied (because the task is not performed by enough individuals, or not performed with enough efficiency). Let S i be the state of an individual i (S i = 0 corresponds to inactivity, S i = 1 corresponds to performing the task), andi the response threshold of i, i = 1, 2. whereis the increase, supposed to be constant, in stimulus intensity per unit time, n act the number of active individuals, andis a scale factor measuring the decrease in stimulus intensity due to the activity of one individual, i.e., the efficiency of individual task performance. In Monte Carlo simulations , this simple fixed threshold model shows remarkable agreement with experimental results in the case where there are two castes characterized by two different values of the response threshold: when \"minors\", with low response thresholds, are removed from the simulated colony, \"majors\", with higher response thresholds, start to perform tasks usually performed by minors. shows the fraction of majors engaged in task performance as a function of the fraction of majors in the colony. This curve is very similar to the one observed by Wilson . This simple model with one task can be easily extended to the case where there are two or more Further experimentation is necessary to test the methodology on more complex tasks. tasks to perform. In this case, each individual has a set of thresholds, each threshold being associated to the stimulus of a specific task or group of tasks. The fixed threshold model described above has been used to organize a group of robots by Krieger and Billeter . They designed a group of Khepera robots (miniature mobile robots aimed at \"desktop\" experiments ) to collectively perform a puck-foraging task. In one of the experiments they performed, pucks spread in the environment are taken back by the robots to the \"nest\" where they are dropped in a basket. The available \"energy\" of the group, which plays the role of stigmergic variable, decreases regularly with time, but increases when pucks are dropped into the basket. More energy is consumed during foraging trips than when robots are immobile in the nest. Each robot has a foraging threshold: when the energy of the colony goes below the foraging threshold of a robot, the robot leaves the nest to look for pucks in the environment. Krieger and Billeter's experiment has shown the viability of the threshold-based stigmergic approach to self-organization in a rather simple environment."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 5,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "3.3.",
               "text": "Adaptive task allocation: the example of mail retrieval",
               "type": "introduction"
          },
          "paragraphs": [
               "The simple response threshold model, which assumes that each worker responds to a given stimulus when stimulus intensity exceeds the worker's threshold, can explain how flexibility at the colony level results from the workers' behavioral flexibility . But it has several limitations, because it assumes that workers' thresholds are fixed over the studied time-scale. In fact, it cannot account for the genesis of task allocation for it assumes that individuals are differentiated and roles preassigned, neither can it account for robust task specialization within (physical or temporal) castes. Finally, as a model of real ants behavior it is valid only over sufficiently short time-scales, where thresholds can be considered constant.",
               "In order to overcome these limitations, Theraulaz et al. have extended the fixed threshold model by allowing thresholds to vary in time, following a simple reinforcement process: a threshold decreases when the corresponding task is performed, and increases when the corresponding task is not performed. This idea had been previously introduced by , Deneubourg et al. , and Plowright and Plowright , who did not attempt to explore its consequences in detail, especially when several tasks need to be performed. It is this model with threshold reinforcement that has been applied by to a problem of adaptive mail retrieval.",
               "Imagine that a group of mailmen belonging to an express mail company have to pick-up letters in a city. Customers should not have to wait more than a given amount of time: the aim of the mail company is therefore to allocate the mailmen to the various demands that appear in the course of the day so as to keep the global demand as low as possible. The probability that mailman i, located in zone z i , respond to a demand intensity s j in zone j is given by whereij[min ,max ] is a response threshold of mailman i to a demand from zone j , d z i j the distance between z i and j (this distance can either be Euclidean or include factors such as one-ways, lights, traffic jams, etc.), andandare two parameters that modulate the respective influences ofand d. Each time a mailman allocates himself to zone j to retrieve mail, his response thresholds are updated in the following way:",
               "where n j is the set of zones surrounding j ,0 and1 are two learning coefficients corresponding to the new zone where that agent moved, andis the forgetting coefficient applied to response thresholds associated with other zones. Simulations have been performed with a grid of 55 zones (we consider four neighbors for the update of Eq. with periodic boundary conditions) and five mailmen; at every iteration, the demand increases in five randomly selected zones by an amount of 50,= 0.5,= 500,min = 0,max = 1000,0 = 150,1 = 70,= 10. Mailmen are swept in random order, and they decide to respond to the demand from a particular zone according to . If no mailman responds after five sweepings, the next iteration starts. If a mailman responds, this mailman will be unavailable for an amount of time that we take to be equal to the distance separating his current location from the zone where the demand comes from. Once the mailman decides to allocate himself to that zone, the associated demand in that zone is maintained at zero (since any demand emerging between the time of the mailman's response and his arrival in the zone will be satisfied by the same mailman). shows how the demand increases but is still kept under control when one mailman fails to perform his task. shows how the threshold of a mailman with respect to a single zone can vary as a function of time. A special behavior can be observed after the removal of a mailman specialist of a given zone: another mailman lowers his threshold with respect to that zone and becomes in turn a new specialist of that zone. This is what is observed in . However, because the workload may be too high to allow mailmen to settle into a given specialization, response thresholds may oscillate in time. All these features point to the flexibility and robustness of this algorithm.",
               "Although we have presented the performance of the algorithm on one specific example, it can certainly be modified to apply to virtually any kind of task allocation problem: the demand s j can be the abstract demand associated to some task j ,ij is a response threshold of actor i with respect to the task-associated stimulus s j . Finally, d z i j is an abstract distance between i and task j which can, e.g., represent the ability or lack of ability of i to deal with task j : if i is not the most efficient actor to perform task j , it will not respond preferentially to s j , but if no other actor is in a position to respond, it will eventually perform the task. It is certainly possible to design a scheme in which d can vary depending on the efficiency of i in performing task j ."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 6,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "4.1.",
               "text": "Cemetery organization",
               "type": "introduction"
          },
          "paragraphs": [
               "Chrtien has performed intensive experiments on the ant Lasius niger to study the organization of cemeteries. Other experiments on the ant Pheidole pallidula are also reported in , and it is now known that many species actually organize a cemetery. The phenomenon that is observed in these experiments is the aggregation of dead bodies by workers. If dead bodies, or more precisely items belonging to dead bodies, are randomly distributed in space at the beginning of the experiment, the workers will form clusters within a few hours (see ). If the experimental arena is not sufficiently large, or if it contains spatial heterogeneities, the clusters will be formed along the borders of the arena or more generally along the heterogeneities. The basic mechanism underlying this type of aggregation phenomenon is an attraction between dead items mediated by the ant workers: small clusters of items grow by attracting workers to deposit more items. It is this positive feedback that leads to the formation of larger and larger clusters. In this case it is therefore the distribution of the clusters in the environment that plays the role of stigmergic variable.",
               "Deneubourg et al. have proposed a model relying on biologically plausible assumptions to account for the above-mentioned phenomenon of dead body clustering in ants. The model, called in the following basic model (BM), relies on the general idea that isolated items should be picked-up and dropped at some other location where more items of that type are present. Let us assume that there is only one type of item in the environment. The probability for a randomly moving ant that is currently not carrying an item to pick-up an item is given by",
               "where f is the perceived fraction of items in the neighborhood of the ant and k 1 is the threshold constant: for f k 1 , p p is close to 1 (i.e., the probability of picking-up an item is high when there are not many items in the neighborhood), and p p is close to 0 if f k 1 (i.e., items are unlikely to be removed from dense clusters). The probability p d for a randomly moving loaded ant to deposit an item is given by where k 2 is another threshold constant: for f k 2 , p d is close to 0, whereas for f k 2 , p d is close to 1. As expected, the pick-up and deposit behaviors obey roughly opposite rules. The question is now to define how f is evaluated. Deneubourg et al. , having in mind a robotic implementation, moved away from biological plausibility and assumed that f is computed using a short-term memory that each ant possesses: an ant keeps track of the last T time units, and f is simply the number N of items encountered during these last T time units divided by the largest possible number of items that can be encountered during T time units. If one assumes that only zero or one object can be found within a time unit, then f = N/T . shows a simulation of this model: small evenly spaced clusters emerge within a relatively short time and then merge into fewer larger clusters. BM can be easily extended to the case in which there are more than one type of items. Consider, e.g., the case with two types show four successive pictures of the simulated circular arena (diameter=200 grid sites; total area=31 416 sites). From left to right and from up to down: the initial state, with 5000 items placed randomly in the arena, the arena at t = 50 000, t = 1 000 000 and t = 5 000 000. Parameters: T = 50, k 1 = 0.1, k 2 = 0.3, 10 ants. Modified from .",
               "a and b of items in the environment. The principle is the same as before, but now f is replaced by f a and f b , the respective fractions of items of types a and b encountered during the last T time units. shows a simulation of this sorting model with two items."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 7,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "4.2.",
               "text": "Exploratory data analysis",
               "type": "introduction"
          },
          "paragraphs": [
               "Lumer and Faieta have generalized Deneubourg et al.'s BM to apply it to exploratory data analysis. The idea here is to define a \"dissimilarity\" d (or distance) between objects in the space of object attributes: for instance, in BM, two objects o i and o j can only be either similar or different, so that a binary metric can be defined, where d(o i , o j ) = 0, if o i and o j are identical objects, and d(o i , o j ) = 1, otherwise. Obviously, the very same idea can be extended to include more complicated objects, i.e., objects with more attributes, and/or more complicated distances. It is classical in data analysis to have to deal with objects that can be described by a finite number n of real-valued attributes, so that objects can . Simulation of the sorting model. (a) Initial spatial distribution of 400 items of two types, denoted by ? and +, on a 100100 grid; (b) spatial distribution of items at t = 500 000; and (c) at t = 5 000 000. Parameters: T = 50, k 1 = 0.1, k 2 = 0.3, 10 ants. ; reprinted by permission of Oxford University Press.) be seen as points in R n and d(o i , o j ) is the Euclidean norm (or any other usual metric, such as . . .). The algorithm introduced by Lumer and Faieta (hereafter LF) consists in projecting the space of attributes onto some lower dimensional space, so as to make clusters appear with the following property: intra-cluster distances (i.e, attribute distances between objects within clusters) should be small with respect to inter-cluster distances (i.e., attribute distances between objects that belong to different clusters). Such a mapping should therefore keep some of the neighborhood relationships present in the higher-dimensional space (which is relatively easy since, for instance, any continuous mapping can do the job) without creating too many new neighbors in m dimensions, m < n, that would be false neighbors in n dimensions (which is much less trivial since projections tend to compress information and may map several well-separated points in the n-dimensional space onto one single point in the m-dimensional subspace).",
               "The LF algorithm works as follows. Let us assume that m = 2; instead of embedding the set of objects into R 2 , the LF algorithm approximates this embedding by considering a grid, i.e., a subspace of Z 2 . Ants can directly perceive a surrounding region of area s 2 ? 1 (a square Neigh ss of ss sites surrounding site r). Obviously, direct perception allows a more efficient evaluation of the state of the neighborhood than the memory-based procedure used in the BM: while the BM was aimed to a robotic implementation, the LF algorithm is to be implemented in a computer with many less practical constraints. Let d(o i , o j ) be the distance between two objects o i and o j in the space of attributes. Let us also assume that an ant is located at site r at time t, and finds an object o i at that site. The local density of objects similar to type o i at site r is given by mines when two items should or should not be located next to each other. For example, ifis too large, there is no enough discrimination between different items, leading to the formation of clusters composed of items which should not belong to the same cluster. If, on the other hand,is too small, distances between items in attribute space are amplified to the point where items which are relatively close in attribute space cannot be clustered together because discrimination is too high. define picking-up and dropping probabilities as follows:",
               "f (o i ) is a measure of the average similarity of object o i with the other objects o j present in its neighborhood: this expression replaces the fraction f of similar objects of the BM. The parameterdefines the scale for dissimilarity: its value is important for it deterwhere k 1 and k 2 are two constants that play a role similar to k 1 and k 2 in the BM.",
               "As an illustration, Lumer and Faieta have used a simple example where the attribute space is R 2 , and the values of the two attributes for each object correspond to its coordinates (x, y) in R 2 . Four clusters of 200 points each are generated in attribute space, with x and y distributed according to normal (or Gaussian) distributions (see for the scatter of points in attribute space). The data points were then assigned random locations on a 100100 grid, and the clustering algorithm was run with 10 ants. shows the system at t = 0, t = 500 000 and t = 1 000 000 (at each iteration, indexed by the counter t, all ants have made a random move and possibly performed an action). Objects that are clustered together belong to the same initial distribution, and objects that do not belong to the same initial distribution are found in different clusters.",
               "Because there are generally more clusters in the projected system than in the initial distribution, Lumer and Faieta have added three features to their systems that help to solve this problem:",
               "? Ants with different moving speeds. Let the speed v of an ant be distributed uniformly in (v is the number of grid units walked per time unit by an ant along a given grid axis; the simulations use v max = 6). The speed v influences the tendency of an ant to either pick-up or drop an object through the function f (o i ): ",
               "Fast moving ants are not as selective as slow ants in their estimation of the average similarity of an object to its neighbors. The diversity of ants allows to form the clusters over various scales simultaneously: fast ants form coarse clusters on large scales, i.e., drop items approximately in the right coarsegrained region, while slow ants take over at smaller scales by placing objects with more accuracy.",
               "? A short-term memory. Ants can remember the last m items they have dropped along with their locations. Each time an item is picked up, the ant compares the properties of the item with those of the m memorized items and goes toward the location of the most similar item instead of moving randomly. This behavior leads to a reduction in the number of statistically equivalent clusters, since similar items have a lower probability of initiating independent clusters.",
               "? Behavioral switches. Ants can start to destroy clusters if they have not performed any pick up or deposit actions for a given number of time steps. This procedure allows to \"heat-up\" the system to escape local non-optimal configurations. , which should be compared with , shows the system at t = 1 000 000 in the case of ants with different speeds and short term memory. The effects of behavioral switches, not included here, can be found in .",
               "Lumer and Faieta suggest that their algorithm is halfway between a cluster analysis -insofar as elements belonging to different concentration areas in their n-dimensional space end up in different clusters -and a multi-dimensional scaling, in which an intracluster structure is constructed. Note that in the present example, the exact locations of the various clusters on the two-dimensional space are arbitrary, whereas they usually have a meaning in classical factorial analysis. In a lot of cases, information about the locations of the clusters is not necessary or useful (especially in the context of textual databases), and relaxing the global positioning constraints allows to speed-up the clustering process significantly.",
               "Finally, we mention that the LF algorithm has been successfully extended by so that it can be applied to a variety of graph drawing and graph partitioning problems. In this case the objects moved around by the artificial ants are projections on a space R n of the vertices of the graph, and the ants goal is to find configurations of these objects that either minimize some objective function (in the graph partitioning applications) or please the observer's eye (in the graph drawing applications). In this paper we informally defined an ant algorithm to be a multi-agent system inspired by the observation of some real ant colony behavior exploiting the stigmergic communication paradigm. In ant algorithms stigmergic communication is implemented by means of a stigmergic variable which takes different forms in the different applications: artificial pheromone trail in shortest path problems, level of nest energy in puck-foraging, level of customer demand in the mailmen example, puck distribution in robotic clustering, and the distribution of objects in the lower-dimensional space in exploratory data analysis. Ant algorithms exhibit a number of interesting properties like flexibility (a colony responds to internal perturbations and external challenges), robustness (tasks are completed even if some individuals fail), decentralization (there exists no central control) and self-organization (solutions to problems faced by a colony are emergent rather than predefined), which make them well suited for the solution of problems that are distributed in nature, dynamically changing, and require built-in fault-tolerance."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 8,
          "fromPaper": "Ant algorithms and stigmergy"
     },
     {
          "head": {
               "n": "5.",
               "text": "Conclusions",
               "type": "conclusion"
          },
          "paragraphs": [
               "Notwithstanding the number of interesting applications presented, a number of open problems need to be addressed and solved before that of ant algorithms becomes a mature field. For example, it would be interesting to give an answer to the following questions: How can we define \"methodologies\" to program ant algorithms? How do we define \"artificial ants\"? How complex should they be? Should they all be identical? What basic capabilities should they be given? Should they be able to learn? Should they be purely reactive? How local should their environment knowledge be? Should they be able to communicate directly? If yes, what type of information should they communicate?",
               "What is also missing, similarly to what happens with many other adaptive systems, is a theory that allows to predict the system behavior as a function of its parameters and of the characteristics of the application domain. On this aspect, let us mention a couple of recent and intriguing results: Gutjahr has recently proved (see this special issue ) convergence to the optimal solution for a particular version of AS, while (see this special issue ) have proved an upper bound to the time necessary to an ant-like agent to cover static and dynamic graphs.",
               "international Journals and conference proceedings. Dr. Dorigo is an Associate Editor for the IEEE Transactions on Systems, Man, and Cybernetics, the IEEE Transactions on Evolutionary Computation, the Journal of Heuristics, and the Journal of Cognitive Systems Research. He is a member of the Editorial Board of the Evolutionary Computation journal, the Adaptive Behavior journal, and the Journal of Genetic Programming and Evolvable Machines. He was awarded the 1996 Italian Prize for Artificial Intelligence.",
               "Marco Dorigo was born in Milan, Italy, in 1961. He received his Ph.D. degree in information and systems electronic engineering in 1992 from Politecnico di Milano, Milan, Italy, and the title of Agrgde l'Enseignement Suprieur in Artificial Intelligence, from the UniversitLibre he was a research fellow at the International Computer Science Institute of Berkeley, CA. In 1993 he was a NATO-CNR fellow, and from 1994 to 1996 a Marie Curie fellow at the IRIDIA laboratory of the UniversitLibre de Bruxelles. Since 1996 he holds a tenured research position in the same laboratory as a Research Associate of the FNRS, the Belgian National Fund for Scientific Research. His main current research interest is in ant algorithms, a novel research area initiated by his seminal doctoral work. Other research interests include evolutionary computation, autonomous robotics, and reinforcement learning. He is the author of a book on learning robots and of a book on swarm intelligence, the editor of three books on evolutionary computation and other modern heuristic techniques, and of more than 50 scientific articles published in Eric Bonabeau is the Managing Director of EuroBios, a Paris-based start-up company applying complexity science to business problems. Prior to this appointment, he was the Director of Research at France Telecom, R&D Engineer with Cadence Design Systems, and research fellow at the Santa Fe Institute. He received his Ph.D. in theoretical physics from the University of Orsay, France, and engineering degrees from Ecole Polytechnique and Ecole National Suprieure des Tl-communications (France). The Editor-in-Chief of Advances in Complex Systems, Dr. Bonabeau is the co-author of three books and a 100 scientific articles.",
               "Guy Theraulaz received an M.S. degree in behavioral neurosciences in 1986, and a Ph.D. in ethology in 1991 from the Provence University, Marseille, France. He is a Research Associate with the French CNRS, Centre National de la Recherche Scientifique, and is currently working at the Ethology and Animal Cognition Laboratory, Paul Sabatier University in Toulouse, where he is the Head of the Collective Intelligence in Social Insects and Artificial Systems group. His research interests are collective behaviors in animal societies, modeling collective phenomena and designing distributed adaptive algorithms inspired by social insects. In 1996 he was awarded the bronze medal of the CNRS for his work on Swarm Intelligence."
          ],
          "paper_id": "218f9900-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 9,
          "fromPaper": "Ant algorithms and stigmergy"
     }
]