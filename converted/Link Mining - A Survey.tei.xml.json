[
     {
          "head": {
               "n": "0",
               "text": "abstract",
               "type": "abstract"
          },
          "paragraphs": [
               "Many datasets of interest today are best described as a linked collection of interrelated objects. These may represent homogeneous networks, in which there is a single-object type and link type, or richer, heterogeneous networks, in which there may be multiple object and link types (and possibly other semantic information). Examples of homogeneous networks include single mode social networks, such as people connected by friendship links, or the WWW, a collection of linked web pages. Examples of heterogeneous networks include those in medical domains describing patients , diseases, treatments and contacts, or in bibliographic domains describing publications, authors, and venues. Link mining refers to data mining techniques that explicitly consider these links when building predictive or descriptive models of the linked data. Commonly addressed link mining tasks include object ranking, group detection, collective classification , link prediction and subgraph discovery. While network analysis has been studied in depth in particular areas such as social network analysis, hypertext mining, and web analysis, only recently has there been a cross-fertilization of ideas among these different communities. This is an exciting , rapidly expanding area. In this article, we review some of the common emerging themes."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 0,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "1.",
               "text": "INTRODUCTION",
               "type": "introduction"
          },
          "paragraphs": [
               "\"Links,\" or more generically relationships, among data instances are ubiquitous. These links often exhibit patterns that can indicate properties of the data instances such as the importance, rank, or category of the object. In some cases, not all links will be observed; therefore, we may be interested in predicting the existence of links between instances. In other domains, where the links are evolving over time, our goal may be to predict whether a link will exist in the future, given the previously observed links. By taking links into account, more complex patterns arise as well. This leads to other challenges focused on discovering substructures, such as communities, groups, or common subgraphs. Traditional data mining algorithms such as association rule mining, market basket analysis, and cluster analysis commonly attempt to find patterns in a dataset characterized by a collection of independent instances of a single relation. This is consistent with the classical statistical inference problem of trying to identify a model given a independent, identically distributed (IID) sample. One can think of this process as learning a model for the node attributes of a homogeneous graph while ignoring the links between the nodes. A key emerging challenge for data mining is tackling the problem of mining richly structured, heterogeneous datasets. These kinds of datasets are best described as networks or graphs. The domains often consist of a variety of object types; the objects can be linked in a variety of ways. Thus, the graph may have different node and edge (or hyperedge) types. Naively applying traditional statistical inference procedures, which assume that instances are independent, can lead to inappropriate conclusions about the data . Care must be taken that potential correlations due to links are handled appropriately. In fact, object linkage is knowledge that should be exploited. This information can be used to improve the predictive accuracy of the learned models: attributes of linked objects are often correlated, and links are more likely to exist between objects that have some commonality. In addition, the graph structure itself may be an important element to include in the model. Structural properties such as degree and connectivity can be important indicators. Link mining is a newly emerging research area that is at the intersection of the work in link analysis , hypertext and web mining , relational learning and inductive logic programming , and graph mining . We use the term link mining to put a special emphasis on the links-moving them up to first-class citizens in the data analysis endeavor. In recent years, there have been several workshop series devoted to topics related to link mining. One of the earliest workshops was the 1998 AAAI Fall Symposium on AI and Link Analysis . Other workshop series include the workshops on Statistical Relational , MultiRelational Data Mining , , Link Analysis, Counter-terrorism and Security , and Mining Graphs, . The objective of this survey is to provide a perspective on research within the relevant communities that are addressing current link mining challenges. Link mining encompasses a wide range of tasks; therefore, our review will cover the core challenges addressed by a majority of ongoing research in the field. We begin by describing some of the challenges in data representation for link mining. Then we progress through eight link mining tasks that can be broadly categorized as tasks that focus on objects, links, or graphs . Finally, we close with a discussion of areas that we believe have not yet received sufficient attention. : A taxonomy of common link mining tasks."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 1,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "1.",
               "text": "Object-Related Tasks",
               "type": "introduction"
          },
          "paragraphs": [
               "(a) Link-Based Object Ranking (b) Link-Based Object Classification that a data representation has been selected, that the designation of the objects or nodes in the graph has been made, and that the links or edges in the graph have been defined. However, when applying link mining to real world domains, one should not underestimate the effort required in choosing an appropriate representation. "
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 2,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "2.",
               "text": "DATA REPRESENTATION",
               "type": "introduction"
          },
          "paragraphs": [
               "While data representation and feature selection are significant issues for traditional machine learning algorithms, data representation for linked data is even more complex. Consider a simple example from Singh et al. of a social network describing actors and their participation in events. Such social networks are commonly called affiliation networks , and are easily represented by three tables representing the actors, the events, and the participation relationships. Even this simple structure can be represented as several distinct graphs. The most natural representation is a bipartite graph, with a set of actor nodes, a set of event nodes, and edges that represent an actor's participation in an event. Other representations may enable different insights and analysis. For example, we may construct a network in which the actors are nodes and edges correspond to actors who have participated in an event together. This representation allows us to perform a more actor-centric analysis. Alternatively, we may represent these relations as a graph in which the events are nodes, and events are linked if they have an actor in common. This representation may allow us to more easily see connections between events. This flexibility in the representation of a graph arises from a basic graph representation duality. This duality is illustrated by the following simple example: Consider a data set represented as a simple G = (0, L), where 0 is the set of objects (i.e., the nodes or vertices) and L is the set of links (i.e., the edges or hyperedges). The graph G(0, L) can be transformed into a new graph G (0 , L ), in which the links li, lj in G are objects in G and there exists an link between oi, oj0 if and only if li and lj share an object in G. This basic graph duality illustrates one kind of simple data representation transformation. For graphs with multiple node and edge types, the number of possible transformations becomes immense. Typically, these reformulations are not considered as part of the link mining process. However, the representation chosen can have a significant impact on the quality of the statistical inferences that can be made. Therefore, the choice of an appropriate representation is actually an important issue in effective link mining, and is often more complex than in the case where we have IID data instances. In the following sections, we will assume Perhaps the most well known link mining task is that of link-based object ranking (LBR), which is a primary focus of the link analysis community. The objective of LBR is to exploit the link structure of a graph to order or prioritize the set of objects within the graph. Much of this research focuses on graphs with a single object type and a single link type.",
               "In the context of web information retrieval, the PageRank and HITS algorithms are the most notable approaches to LBR. PageRank models web surfing as a random walk where the surfer randomly selects and follows links and occasionally jumps to a new web page to start another traversal of the link structure. The rank of a given web page in this context is the fraction of time that the random web surfer would spend at the page if the random process were iterated ad infinitum. This can be determined by computing the steady-state distribution of the random process. HITS assumes a slightly more complex process, modeling the web as being composed of two types of web pages: hubs and authorities. Hubs are web pages that link to many authoritative pages. Authorities are web pages that are linked to by many hubs. Each page in the web is assigned hub and authority scores. These scores are computed by an iterative algorithm that updates the scores of a page based on the scores of pages in its immediate neighborhood. This approach bears a relation to PageRank with two separate random walks-one with hub transitions and one with authority transitions-on a corresponding bipartite graph of hubs and authorities . The hub and authority scores are the steady-state distributions of the respective random processes. Since the introduction of PageRank and HITS, a number of algorithms have been proposed that are variations on these basic themes. Bharat and Henzinger and propose modifications to HITS that exploit web page content to weight pages and links based on relevance. Ng et al. analyze the stability of PageRank and HITS to small perturbations in the link structure and present modifications to HITS that yield more stable rankings. Haveliwala and Jeh and Widom propose topic-sensitive PageRank algorithms that identify topically authoritative web pages efficiently at query time. proposes a unified framework encompassing both PageRank and HITS and presents several new ranking algorithms within this algorithm class with closed-form solutions. Cohn and Chang introduce a probabilistic analogue to HITS based on probabilistic latent semantic indexing, where the model attempts to explain the link structure in terms of a small set of latent factors. Cohn and Hofmann and present probabilistic models inspired by HITS and PageRank, respectively, that incorporate both content and link structure. In the domain of social network analysis (SNA), LBR is a core analysis task. The objective is to rank order individu-als in a given social network in terms of a measure of their importance, referred to as centrality. Measures of centrality have been the subject of research in the SNA community for decades . These measures characterize some aspect of the local or global network structure as seen from a given individual's position in the network. They range in complexity from local measures such as degree centrality , which is simply the vertex degree, to global measures such as eigenvector/power centrality , which use spectral methods to characterize the importance of individuals based on their connectedness to other important individuals. In the above work, the common goal is a global ranking of objects in a static graph produced using a specified measure. Notable variations from this theme include approaches that rank objects relative to one or more relevant objects in the graph and methods that rank objects over time in dynamic graphs . Jeh and Widom propose a metric for assessing the similarity of two objects based on the degree to which they link to similar objects. The similarity between two objects in a directed or bipartite graph is computed using a random walk formulation. Sun et al. in this issue propose a related object ranking approach for relevance search and anomaly detection that combines random walks and graph partitioning to improve scalability. White and Smyth define and evaluate a host of metrics to compute the similarity between a given object and one or more reference objects in a graph. Ranking objects in dynamic graphs that capture event data such as email, telephone calls, or publications introduces new challenges. In contrast to ranking methods for static settings that produce a single rank, the goal is to track the changes in object rank over time as new events unfold. Static ranking methods can be applied to aggregated event data over various time intervals, but this aggregation removes the time ordering of events, and the sparse link structure over a given time interval limits the utility of the resulting ranks. O'Madadhain and Smyth and O'Madadhain et al. in this issue propose a series of desired algorithmic properties for dynamic object ranking, discuss the limitations of notable static ranking algorithms, and introduce a ranking algorithm based on potential flow that satisfies the specified requirements. aids classification, whereas exploiting features of related objects can actually harm classification accuracy. Oh et al. report similar results on a collection of encyclopedia articles: simply incorporating words from neighboring documents was not helpful, while making use of the predicted class of neighboring documents was helpful. Lafferty et al. introduce conditional random fields (CRF), which extend traditional maximum entropy models for LBC in the restricted case where the data graphs are chains. extend Lafferty et al.'s approach to the case where the data graphs are arbitrary graphs. Neville and Jensen propose simple LBC algorithms to classify corporate datasets with rich schemas that produce graphs with heterogeneous objects, each with its own distinct set of features. Lu and Getoor extend simple machine learning classifiers to perform LBC by introducing new features that measure the distribution of class labels in the Markov blanket of the object to be classified. In addition to the machine learning community, the computer vision and natural language communities have also studied the LBC problem. proposed relaxation labeling, an inference algorithm later used by to perform link-based classification. Hummel and Zucker present one of many approaches for exploring relaxation labeling theoretically. Lafferty et al. proposed CRFs for use in part-of-speech tagging, a task in natural language processing."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 3,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "4.",
               "text": "LINK-BASED OBJECT CLASSIFICATION",
               "type": "introduction"
          },
          "paragraphs": [
               "Traditional machine learning has focused on the classification of data consisting of identically structured objects that are typically assumed to be IID. Many real-world datasets, however, lack this homogeneity of structure. In the linkbased object classification (LBC) problem, a data graph G = (0, L) is composed of a set objects 0 connected to each other via a set of links L. The task is to label the members of 0 from a finite set of categorical values. The discerning feature of LBC that makes it different from traditional classification is that in many cases, the labels of related objects tend to be correlated. The challenge is to design algorithms for collective classification that exploit such correlations and jointly infer the categorical values associated with the objects in the graph. LBC has received considerable attention recently. Chakrabarti et al. consider the problem of classifying related news items in the Reuters dataset. They were among the first to notice that exploiting class labels of related objects A third object-centric task is group detection. The goal of group detection is to cluster the nodes in the graph into groups that share common characteristics. A range of techniques have been presented in various communities to address this general problem. In recent years, a central challenge has been to develop scalable methods that can exploit increasingly complex graphs to aid the knowledge discovery process. Consider first the case where the graph contains objects and links of a single type, without attributes. Many of the techniques for identifying groups in this scenario can be classified as either agglomerative or divisive clustering methods. The task of blockmodeling of social network analysis (SNA) involves partitioning social networks into sets of individuals, called positions, that exhibit similar sets of links to others in the network . A similarity measure is defined between link sets and agglomerative clustering is used to identify the positions. Spectral graph partitioning methods address the group detection problem by identifying an approximately minimal set of links to remove from the graph to achieve a given number of groups . In a related vein, Gibson et al. have shown that the dominant eigenvectors of the HITS authority matrix provide a natural decomposition of web community structure. Other recent approaches for group detection use a measure of edge betweenness, derived from Freeman's notion of betweenness centrality , to identify links connecting groups . Links with high edge betweenness are incrementally removed to partition the graph. In contrast to the above methods, where group assignments are deterministic, a number of approaches for group detection have been introduced that are based on the concept of stochastic blockmodeling from SNA. In stochastic blockmod-eling, the observed social network is assumed to be a realization from a pair-dependent stochastic blockmodel . Positions for the individuals in the network are treated as IID random variables, and relational links of a given type between two individuals are random variables dependent solely on the positions of the individuals they link. Nowicki and Snijders propose a general stochastic blockmodelling approach admitting directed, valued relations and an arbitrary number of positions. Gibbs sampling is used to infer the posterior distribution for positions. remove the need to specify the number of positions a priori; instead, the number of positions is inferred directly from the data. Wolfe and Jensen ",
               "introduce a scalable version of this approach that uses a method similar to k-means clustering to significantly accelerate group discovery, while retaining the underlying generative model. Most recently, propose a generalization of the general stochastic blockmodelling approach that allows joint inference of groups and topics based on observed relationships and their textual attributes. Such a model provides a mechanism to connect an observed relationship with its underlying context.",
               "The use of links for resolution was first explored in databases. Ananthakrishna et al. introduce a method for deduplication using links in data warehouse applications where there is a dimensional hierarchy over the link relations. More recently,enhance feature-based similarity between an ambiguous reference and the many entity choices for it with linkage analysis between the entities, such as affiliation and co-authorship. However, while these approaches consider links for entity resolution, only the attributes of linked references are considered and different resolution decisions are still taken independently. In contrast, collective entity resolution approaches have also been proposed in databases , where one resolution decision affects another if they are linked. Bhattacharya and Getoor propose different measures for linkage similarity in graphs and show how these can be combined with attribute similarity for collective entity resolution in collaboration graphs. Dong et al. collectively resolve entities of multiple types by propagating evidence over links in a dependency graph. In machine learning, probabilistic models that take into account interaction between different entity resolution decisions have been proposed for named entity recognition in natural language processing and for citation matching. Li et al. address the problem of disambiguating \"entity mentions,\" potentially of multiple types, in the context of unstructured textual documents. use the idea of merging evidence to allow the flow of reasoning between linked pair-wise decisions over multiple entity types. In addition, models have been proposed that explicitly consider links among references for collective resolution . Pasula et al. propose a generic probabilistic relational model framework for the citation matching problem. Culotta and McCallum construct a conditional random field model of deduplication that captures linked dependencies between references of multiple types. Bhattacharya et al. adapt the Latent Dirichlet model for documents and topics and extend it to propose a generative group model for unsupervised collective entity resolution."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 4,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "6.",
               "text": "ENTITY RESOLUTION",
               "type": "introduction"
          },
          "paragraphs": [
               "The final object-centric task is entity resolution, which involves identifying the set of objects in a domain. The goal of entity resolution is to determine which references in the data refer to the same real-world entity. Examples of this problem arise in databases (deduplication, data integration), natural language processing (co-reference resolution, object consolidation), personal information management, and other fields. The problem has been defined with many variations; in the most general form, neither the domain entities nor the number of such entities is assumed to be known. Traditionally, entity resolution has been viewed as a pair-wise resolution problem, where each pair of references is independently resolved as being co-referent or otherwise, depending on the similarity of their attributes. Recently, there has been significant interest in the use of links for improved entity resolution. The central idea is to consider, in addition to the attributes of the references to be resolved, the other references to which these are linked. These links may be, for example, co-author links between author references in bibliographic data, hierarchical links between spatial references in geo-spatial data, or co-occurrence links between name references in natural language documents."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 5,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "7.",
               "text": "LINK PREDICTION",
               "type": "introduction"
          },
          "paragraphs": [
               "We next turn to edge-related tasks. Link prediction is the problem of predicting the existence of a link between two entities, based on attributes of the objects and other observed links. Examples include predicting links among actors in social networks, such as predicting friendships; predicting the participation of actors in events , such as email, telephone calls and co-authorship; and predicting semantic relationships such as \"advisor-of\" based on web page links and content . Most often, some links are observed, and one is attempting to predict unobserved links, or there is a temporal aspect: a snapshot of the set of links at time t is given and the goal is to predict the links at time t + 1. This problem is often viewed as a simple binary classification problem: for any two potentially linked objects oi and oj , predict whether lijis1 or 0. One approach is to make this prediction entirely based on structural properties of the network. Liben-Nowell and Kleinberg present a survey of predictors based on different graph proximity measures. Other approaches make use of attribute information for link prediction. introduce a structured logistic regression model that can make use of relational features to predict the existence of links. The relational features are defined via database queries; the authors show how to search over the space of relational features. O'Madadhain et al. construct local conditional probability models, based on attribute and structural features. Link prediction is hard because most interesting linked data sets are sparse. As pointed out by many researchers , one of the difficulties in building statistical models for edge prediction is that the prior probability of a link is typically quite small. This causes difficulty both in model evaluation and, more importantly, in quantifying the level of confidence in the predictions. Rattigan and Jensen in this issue discuss some of these challenges. One way to improve the quality of the predictions is to make the predictions collectively. A number of approaches define a single probabilistic model over the entire link graph, labels, and edges. These joint models of network structure are often based on models such as Markov random fields . In the simplest case, where there is a set of objects O, with attributes X, and edges E among the objects, the MRF models a joint distribution over the set of edges E, P (E), or a distribution conditioned on the attributes of the nodes, P (E|X). Richer models, based on relational representations, are possible, such as Relational Markov Networks and, more recently, Markov Logic Networks . Models based on directed graphical models are also possible. Getoor et al. describe several approaches for handling link uncertainty in probabilistic relational models. A discerning feature of these latter approaches is that they perform probabilistic inference to make inferences about the links. This allows them to capture the correlations among the links. They can also be used for other tasks, such as linkbased classification. Ideally this makes for more accurate predictions. However, model-based probabilistic approaches have a computational price: exact inference is generally intractable, so approximate inference techniques are necessary.",
               "work of Dehaspe et al. , who applied techniques from inductive logic programming to finding frequent patterns in a toxicology domain. Another line of work focuses on efficient subgraph generation and compression-based heuristic search . Subdue , the earliest work in this area, uses an MDL-based heuristic to guide the search for subgraphs. Subdue has been used for both subgraph discovery and graph classification . As another example, Graph-Based Induction (GBI) compresses the input graph by chunking the vertex pairs that appear frequently . Both of these approaches use a greedy local approach in their search for frequent substructures. compare these approaches to ILP approaches."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 6,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "8.",
               "text": "SUBGRAPH DISCOVERY",
               "type": "introduction"
          },
          "paragraphs": [
               "An area of data mining that is related to link mining is the work on subgraph discovery. This work attempts to find interesting or commonly occurring subgraphs in a set of graphs. Discovery of these patterns may be the sole purpose of the systems, or the discovered patterns may be used for graph classification (Section 9). One line of work attempts to find frequent subgraphs . Many of these approaches exploit the Apriori property from frequent item set mining. Typically, there is a candidate generation phase followed by a matching phase. Naive matching requires a subgraph isomorphism test, so efficient algorithms are needed here as well. Inokuchi et al. describe AGM, an Apriori-based algorithm that finds all induced subgraphs in a graph database satisfying a minimum support.improve on AGM by using an adjacency representation of the graph data and describing new optimizations to candidate substructure generation. Yan et al. describe gSpan, which avoids the cost of candidate generation by first mapping each graph to a depth-first search code and lexicographically ordering these codes, then performing DFS on the search tree defined by this lexicographic ordering. Other approaches come from the inductive logic programming (ILP) community . One early success was the Unlike link-based object classification, which attempts to label nodes in a graph, graph classification is a supervised learning problem in which the goal is to categorize an entire graph as a positive or negative instance of a concept. This is one of the earliest tasks addressed within the context of applying machine learning and data mining techniques to graph data. Graph classification does not typically require collective inference, as is needed for classifying objects and edges, because the graphs are generally assumed to be independently generated. Three main approaches to graph classification have been explored. These are based on feature mining on graphs, inductive logic programming (ILP), and defining graph kernels. Feature mining on graphs uses methods related to those described in the previous section on subgraph discovery, Section 8. Feature mining on graphs is usually performed by finding all frequent or informative substructures in the graph instances. These substructures are used for transforming the graph data into data represented as a single table, and then traditional classifiers are used for classifying the instances. As an example of an ILP approach, King et al. first map the graph data describing mutagenesis into a relational representation. Their logical representation uses relations such as vertex(graphId,VertexId,VertexLabel, VertexAttributes) and edge(graphId,vertexId1,vertexId2,BondLabel), and then uses an ILP system to find a hypothesis in this space. Finding all frequent substructures is usually computationally prohibitive. An alternative approach makes use of kernel methods. Both G?rtner and Kashima describe graph kernels based on a measure of the walks on the graphs . counts walks with equal initial and terminal labels, whereas Kashimalooks at the probability of random walks with equal label sequences. A G?rtner surveys kernel methods for structured data."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 7,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "10.",
               "text": "GENERATIVE MODELS FOR GRAPHS",
               "type": "modelling"
          },
          "paragraphs": [
               "Generative models for a range of graph and dependency types have been studied extensively in the social network analysis community. For directed graphs with a single object and link type, there are several major classes of random graph distributions discussed in the literature: Bernoulli graph distributions, conditional uniform graph distributions, dyadic dependence distributions, and p * models. Bernoulli graphs (also known as Erd?s-Rnyi models or random graphs) are by far the simplest generative models. They assume that the random variables {lij } that indicate the existence of directed edges among the objects oi and oj are IID. When the probability of link existence equals 0.5, the distribution is often referred to as the uniform random graph distribution. Conditional uniform graph distributions define uniform distributions over sets of graphs with specified structural characteristics, such as a fixed number of links, out-degrees, or in-degrees. Dyadic dependence distributions assume that only the dyads (lij, lji) are dependent and define multinomial distributions over the dyad states. P * models assume that links sharing at least one object in common are dependent. Generative models admitting dependency structures that are more general than Markov graphs have been introduced as well, along with models for multiple object and link types and dynamic networks with a varying link structure and number of objects . In recent years, significant attention has focused on studying the structural properties of networks such as the World Wide Web, online social networks, communication networks, citation networks, and biological networks. Across these various networks, general patterns such as power law degree distributions, small graph diameters, and community structure are observed. These observations have motivated the search for general principles governing such networks . Airoldi et al. in this issue review sampling algorithms for a number of the common network types such as scale free networks , small-world networks , core-periphery , and cellular networks that exhibit such attributes. In contrast to the random process models from the social network analysis literature, many of these generative models are specified in procedural form, which is viewed as beneficial when the goal is to understand how power law degree distributions, for example, can naturally emerge in dynamic graphs over time. presents a taxonomy of recently proposed graph generators. Finally, we note several generative models of link structure presented in the machine learning community that address a variety of application contexts. introduces a generative model for observed links among individuals given their underlying group memberships. present a link generation model for link analysis and collaboration queries that admits different link types and temporal information. Getoor et al. introduce probabilistic relational models, which that provide a unified generative model for objects and link structure. Neville and Jensen define a probabilistic relational model that represents a joint distribution over objects, links and latent groups."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 8,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "11.",
               "text": "OPEN ISSUES AND PROMISING AREAS FOR FUTURE RESEARCH",
               "type": "modelling"
          },
          "paragraphs": [
               "In this survey, we have often described each link mining task in isolation. More generally, component link mining algorithms may be part of a larger knowledge discovery process.",
               "As we move from one domain to another, the processing requirements will change, but the need to compose the algorithms in a unified process will remain. Ideally, as we move from data conditioning to more complex inference tasks, we would like to propagate uncertainty throughout the process. One approach that solves this problem, in theory, is to define a full probabilistic model; this the approach taken by Getoor et al. and Taskar et al. . However, this approach is not always desirable or feasible. As argued by Senator in this issue, in addition to addressing specific link mining tasks, it is equally important to consider how to effectively compose link mining algorithms to address a spectrum of knowledge discovery tasks. Ultimately, system performance is determined by the interplay among the components; therefore, it is critical to investigate how these component dependencies will shape the overall performance. When considering the overall knowledge discovery process, it is important to keep in mind that many aspects of the process are dynamic. The dynamism, which can extend from the data to the user's needs, interests, and beliefs, implies that a number of link mining algorithms will be applied repeatedly and incrementally. We often envision applying link mining algorithms to the entire graph. While this is desirable in some applications, it does not make sense when a user is interested in only a small subgraph. Therefore, it is important to develop methods supporting focused, incremental application of link mining. One interesting research direction in this area is query-based classification using links. Most collective classification approaches consider the dataset in its entirety as one linked instance of objects, performing prediction/classification for all of these objects jointly. When a user is interested in classifying only a small subset of these objects, it is worthwhile to classify other objects only if they are helpful in correctly classifying the objects of interest via the link structure. Given this goal, a query-based collective inference technique needs to first extract the links and objects that are most relevant for answering the query approximately and then perform collective classification only on the extracted subgraph. Identification of relevant subgraphs can also be helpful for incremental classification when new objects and links are added to an existing graph with classified objects. Link mining often needs to be performed on data from multiple sources; therefore, information integration and reconciliation are important components of the link mining process. Furthermore, it is important to integrate the data (re)formulation more directly into the link process process. While there has been some work that integrates the statistical approaches to link mining with the meta-data discovery and mapping , there is much more to be done. Another promising arena in which to apply link mining is the Semantic Web. In this issue, Ramakrishnan et al. describe methods for discovering interesting subgraphs based on semantic information associated with the edges. There has been some other work in this area, for example Madche and Staab and Doan et al. , but there is much more to be done. As information extraction techniques continue to improve, one area for future research is combining information extraction with techniques from link mining to help to construct the Semantic Web, and another area for future research is how semantic and ontological information can help in link mining endeavors. As the amount of data grows and the number of sources expands, techniques from link mining can help us discover patterns and build useful prediction systems. Link mining research holds promise for many different areas, including commercial and business enterprises, personal information management, web search and retrieval, medicine and bioinformatics, and law and security enforcement. However, as cautioned by Sweeney , as we develop this technol-ogy, privacy and information-access control issues and policy must be considered, not just as an afterthought, but as an integral part of the solution.",
               "I. Bhattacharya and L. Getoor. Iterative record linkage for cleaning and integration. In SIGMOD 2004 Workshop on Research Issues on Data Mining and Knowledge Discovery, June 2004."
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 9,
          "fromPaper": "Link Mining: A Survey"
     },
     {
          "head": {
               "n": "12.",
               "text": "CONCLUSION",
               "type": "conclusion"
          },
          "paragraphs": [
               "More and more domains of interest today are best described as a linked collection or network of interrelated heterogeneous objects. Data mining algorithms have typically addressed the discovery of patterns in collections of IID instances. Link mining is an emerging area within data mining that is focused on finding patterns in data by exploiting and explicitly modeling the links among the data instances.",
               "We have surveyed several of the more well studied link mining tasks: link-based object ranking, link-based object classification, group detection, entity resolution, link prediction, subgraph discovery, graph classification, and generative models for graphs. These represent some of the common threads emerging from a variety of fields that are exploring this exciting and rapidly expanding field.",
               "I. Bhattacharya and L. Getoor. Entity resolution in graphs. Technical Report 4758, Computer Science Department, University of Maryland, 2005.",
               "I. Bhattacharya and L. Getoor. A Latent dirichlet model for unsupervised entity resolution. In SIAM International Conference on Data . To Appear.",
               "P. Bonacich. Power and centrality: A family of measures. American Journal of Sociology, 92(5):1170-1182, 1987.",
               "S. P. Borgatti and M. G. Everett. Models of core / periphery structures. "
          ],
          "paper_id": "22a1a540-97d4-11e8-9580-1f0eb29018a9",
          "paragraphNo": 10,
          "fromPaper": "Link Mining: A Survey"
     }
]